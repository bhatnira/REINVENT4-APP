#!/usr/bin/env python3
"""
REINVENT4 Streamlit Web Application
A comprehensive GUI for molecule generation, optimization, and analysis using REINVENT4.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import sys
import tempfile
import json
import time
from datetime import datetime
import toml
import time
from pathlib import Path
from typing import Dict, List, Optional, Any
import plotly.express as px
import plotly.graph_objects as go
from io import StringIO, BytesIO
import base64

# Try to import torch for GPU checking
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# Add the parent directory to sys.path to import reinvent modules
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# Page configuration - must be first Streamlit command
st.set_page_config(
    page_title="REINVENT4 Web Interface",
    page_icon="üß™",
    layout="wide",
    initial_sidebar_state="expanded"
)

try:
    from reinvent.Reinvent import main
    from reinvent.utils.config_parse import read_config
    from reinvent.validation import ReinventConfig
    from reinvent import version
    REINVENT_AVAILABLE = True
    REINVENT_VERSION = version.__version__
except ImportError as e:
    REINVENT_AVAILABLE = False
    REINVENT_VERSION = "Not available"
    print(f"REINVENT import error: {e}")

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #ff7f0e;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .info-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #1f77b4;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #28a745;
        margin: 1rem 0;
    }
    .error-box {
        background-color: #f8d7da;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #dc3545;
        margin: 1rem 0;
    }
    .stButton > button {
        background-color: #1f77b4;
        color: white;
        border-radius: 0.5rem;
        border: none;
        padding: 0.5rem 1rem;
        font-weight: bold;
    }
    .stButton > button:hover {
        background-color: #145a9e;
    }
</style>
""", unsafe_allow_html=True)

def main():
    """Main application entry point"""
    
    # Header
    st.markdown('<div class="main-header">üß™ REINVENT4 Web Interface</div>', unsafe_allow_html=True)
    
    if not REINVENT_AVAILABLE:
        st.error("‚ùå REINVENT4 modules not available. Please check the installation.")
        st.info("üí° This could be due to missing dependencies or installation issues.")
        st.info("üîß Try running: pip install -r requirements.txt")
        
        # Show a simplified interface for demonstration
        st.warning("‚ö†Ô∏è Running in limited mode without REINVENT4 functionality.")
    else:
        st.success("‚úÖ REINVENT4 is fully loaded and ready to use!")
        st.info(f"üöÄ Running REINVENT4 version {REINVENT_VERSION}")
        
    # Display version information
    try:
        if REINVENT_AVAILABLE:
            st.markdown(f"<div class='success-box'>üéâ REINVENT4 version {REINVENT_VERSION} is active and ready!</div>", unsafe_allow_html=True)
        else:
            st.markdown("<div class='error-box'>‚ö†Ô∏è REINVENT4 modules not loaded - limited functionality available</div>", unsafe_allow_html=True)
    except:
        st.markdown("<div class='error-box'>‚ö†Ô∏è Unable to determine REINVENT4 status</div>", unsafe_allow_html=True)
    
    # Sidebar navigation
    st.sidebar.title("Navigation")
    
    pages = {
        "üè† Home": "home",
        "üî¨ De Novo Generation": "denovo",
        "üß¨ Scaffold Hopping": "scaffold",
        "üîó Linker Design": "linker",
        "‚öóÔ∏è R-Group Replacement": "rgroup",
        "üìà Molecule Optimization": "optimization",
        " Documentation": "docs"
    }
    
    selected_page = st.sidebar.radio("Select Page:", list(pages.keys()))
    page_key = pages[selected_page]
    
    # Initialize session state
    if 'results' not in st.session_state:
        st.session_state.results = {}
    if 'config_history' not in st.session_state:
        st.session_state.config_history = []
    
    # Route to appropriate page
    if page_key == "home":
        show_home_page()
    elif page_key == "denovo":
        show_denovo_page()
    elif page_key == "scaffold":
        show_scaffold_page()
    elif page_key == "linker":
        show_linker_page()
    elif page_key == "rgroup":
        show_rgroup_page()
    elif page_key == "optimization":
        show_optimization_page()
    elif page_key == "docs":
        show_documentation_page()

def show_home_page():
    """Display the home page with overview and quick start"""
    
    st.markdown('<div class="sub-header">Welcome to REINVENT4</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    REINVENT4 is a comprehensive platform for de novo molecular design and optimization.
    This web interface provides an intuitive way to access all REINVENT4 capabilities.
    </div>
    """, unsafe_allow_html=True)
    
    # Status notice
    if REINVENT_AVAILABLE:
        st.markdown("""
        <div class="success-box">
        ‚úÖ <strong>REINVENT4 Active:</strong> All molecular generation and optimization features are fully functional! 
        Ready for real molecular design workflows.
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="error-box">
        ‚ùå <strong>REINVENT4 Not Available:</strong> Please install REINVENT4 dependencies to enable full functionality.
        </div>
        """, unsafe_allow_html=True)
    
    # Quick overview cards
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### üî¨ Generation Modes")
        st.markdown("""
        - **Reinvent**: Pure de novo generation
        - **Libinvent**: Scaffold decoration
        - **Linkinvent**: Fragment linking
        - **Mol2Mol**: Molecule optimization
        """)
    
    with col2:
        st.markdown("### üìà Optimization Strategies")
        st.markdown("""
        - **Transfer Learning**: Model fine-tuning
        - **Reinforcement Learning**: Score optimization
        - **Curriculum Learning**: Staged optimization
        - **Multi-objective**: Complex scoring
        """)
    
    with col3:
        st.markdown("### üéØ Key Features")
        st.markdown("""
        - **Custom Scoring**: Multi-component functions
        - **Real-time Monitoring**: TensorBoard integration
        - **Batch Processing**: High-throughput generation
        - **Export Options**: Multiple formats
        """)
    
    # Quick start section
    st.markdown('<div class="sub-header">Quick Start Guide</div>', unsafe_allow_html=True)
    
    with st.expander("üöÄ Getting Started", expanded=True):
        st.markdown("""
        1. **Choose a Generation Mode**: Select from the sidebar based on your needs
        2. **Configure Parameters**: Set up model files, scoring functions, and output options
        3. **Run Generation**: Execute the selected mode with your configuration
        4. **Analyze Results**: View generated molecules and their properties
        5. **Export Data**: Download results in CSV, SDF, or other formats
        """)
    
    # System status
    st.markdown('<div class="sub-header">System Status</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üñ•Ô∏è Compute Resources")
        # Check CUDA availability
        try:
            if TORCH_AVAILABLE and torch.cuda.is_available():
                device_count = torch.cuda.device_count()
                current_device = torch.cuda.current_device()
                device_name = torch.cuda.get_device_name(current_device)
                free_mem, total_mem = torch.cuda.mem_get_info()
                
                st.success(f"‚úÖ CUDA Available: {device_count} device(s)")
                st.info(f"Current: {device_name}")
                st.info(f"Memory: {free_mem//1024**2} MB free / {total_mem//1024**2} MB total")
            elif TORCH_AVAILABLE:
                st.warning("‚ö†Ô∏è CUDA not available, using CPU")
            else:
                st.info("‚ÑπÔ∏è PyTorch not installed - GPU status unknown")
        except Exception as e:
            st.error(f"‚ùå Could not check CUDA status: {e}")
    
    with col2:
        st.markdown("#### üìÅ File System")
        # Check for model files
        prior_dir = Path("../priors")
        if prior_dir.exists():
            priors = list(prior_dir.glob("*.prior"))
            st.success(f"‚úÖ Found {len(priors)} prior model(s)")
            for prior in priors[:5]:  # Show first 5
                st.info(f"üìÑ {prior.name}")
            if len(priors) > 5:
                st.info(f"... and {len(priors) - 5} more")
        else:
            st.warning("‚ö†Ô∏è No prior models directory found")

def show_denovo_page():
    """De novo molecule generation pipeline with complete workflow"""
    
    st.markdown('<div class="sub-header">üî¨ De Novo Generation Pipeline</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    Complete de novo molecular design pipeline: Training ‚Üí Generation ‚Üí Optimization ‚Üí Library Design
    </div>
    """, unsafe_allow_html=True)
    
    # Pipeline tabs for complete workflow
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìù 1. Input & Training", 
        "üéØ 2. Scoring Functions", 
        "üöÄ 3. Generation", 
        "üìà 4. Optimization", 
        "üìö 5. Library Design"
    ])
    
    with tab1:
        show_denovo_input_training()
    
    with tab2:
        show_denovo_scoring_config()
    
    with tab3:
        show_denovo_generation()
    
    with tab4:
        show_denovo_optimization()
    
    with tab5:
        show_denovo_library_design()

def show_denovo_input_training():
    """Step 1: Input molecules and training configuration"""
    
    st.subheader("üìù Input Data & Model Training")
    
    # Input molecules section
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üíä Input Molecules")
        
        input_method = st.radio(
            "Input Method:",
            ["Upload Dataset", "Text Input", "Example Dataset"],
            key="denovo_input_method"
        )
        
        molecules = []
        
        if input_method == "Upload Dataset":
            uploaded_file = st.file_uploader(
                "Upload Training Dataset",
                type=['smi', 'csv', 'sdf', 'txt'],
                help="Upload molecules for training/fine-tuning",
                key="denovo_upload"
            )
            
            if uploaded_file:
                content = uploaded_file.read().decode('utf-8')
                molecules = [line.strip().split()[0] for line in content.split('\n') if line.strip()]
                st.success(f"‚úÖ Loaded {len(molecules)} molecules")
        
        elif input_method == "Text Input":
            molecules_text = st.text_area(
                "Enter SMILES (one per line)",
                placeholder="CCO\nc1ccccc1\nCC(=O)O\n...",
                height=150,
                key="denovo_text_input"
            )
            
            if molecules_text:
                molecules = [line.strip() for line in molecules_text.split('\n') if line.strip()]
        
        else:  # Example Dataset
            dataset_choice = st.selectbox(
                "Select Example Dataset:",
                ["ChEMBL Drug-like", "Natural Products", "Kinase Inhibitors", "GPCR Ligands"],
                key="denovo_example_dataset"
            )
            
            # Simulate loading example dataset
            if st.button("Load Example Dataset", key="load_example_denovo"):
                molecules = simulate_example_dataset(dataset_choice)
                st.session_state.denovo_input_molecules = molecules
                st.success(f"‚úÖ Loaded {len(molecules)} example molecules")
        
        # Store molecules in session state
        if molecules:
            st.session_state.denovo_input_molecules = molecules
    
    with col2:
        st.markdown("#### üéì Training Configuration")
        
        training_mode = st.radio(
            "Training Approach:",
            ["Pre-trained Model", "Transfer Learning", "Curriculum Learning", "Fine-tuning"],
            key="denovo_training_mode"
        )
        
        if training_mode == "Pre-trained Model":
            model_file = st.selectbox(
                "Select Pre-trained Model:",
                ["priors/reinvent.prior", "priors/pubchem_ecfp4_with_count_with_rank_reinvent4_dict_voc.prior"],
                key="denovo_pretrained_model"
            )
            
            st.info("üí° Using pre-trained model without additional training")
        
        elif training_mode == "Transfer Learning":
            st.markdown("**Transfer Learning Settings:**")
            
            base_model = st.selectbox(
                "Base Model:",
                ["priors/reinvent.prior", "priors/pubchem_ecfp4_with_count_with_rank_reinvent4_dict_voc.prior"],
                key="denovo_base_model"
            )
            
            learning_rate = st.number_input(
                "Learning Rate:", 
                min_value=1e-6, 
                max_value=1e-2, 
                value=1e-4, 
                format="%.6f",
                key="denovo_lr"
            )
            
            epochs = st.number_input(
                "Training Epochs:", 
                min_value=1, 
                max_value=100, 
                value=10,
                key="denovo_epochs"
            )
            
            batch_size = st.number_input(
                "Batch Size:", 
                min_value=8, 
                max_value=128, 
                value=64,
                key="denovo_batch_size"
            )
        
        elif training_mode == "Curriculum Learning":
            st.markdown("**Curriculum Learning Settings:**")
            
            curriculum_stages = st.number_input(
                "Number of Curriculum Stages:", 
                min_value=2, 
                max_value=5, 
                value=3,
                key="denovo_curriculum_stages"
            )
            
            complexity_metric = st.selectbox(
                "Complexity Metric:",
                ["Molecular Weight", "Number of Rings", "LogP", "TPSA"],
                key="denovo_complexity_metric"
            )
            
            st.info("üìö Training will progress from simple to complex molecules")
        
        else:  # Fine-tuning
            st.markdown("**Fine-tuning Settings:**")
            
            finetune_strategy = st.selectbox(
                "Fine-tuning Strategy:",
                ["Full Model", "Last Layers Only", "Gradual Unfreezing"],
                key="denovo_finetune_strategy"
            )
            
            validation_split = st.slider(
                "Validation Split:", 
                min_value=0.1, 
                max_value=0.3, 
                value=0.2,
                key="denovo_val_split"
            )
    
    # Training execution
    if st.button("üöÄ Start Training/Setup", type="primary", key="start_denovo_training"):
        execute_denovo_training(training_mode, molecules)

def show_denovo_scoring_config():
    """Step 2: Configure scoring functions"""
    
    st.subheader("üéØ Scoring Function Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìä Scoring Components")
        
        # Drug-likeness components
        use_qed = st.checkbox("QED (Drug-likeness)", value=True, key="denovo_use_qed")
        if use_qed:
            qed_weight = st.slider("QED Weight:", 0.0, 2.0, 1.0, key="denovo_qed_weight")
        
        use_sa_score = st.checkbox("SA Score (Synthetic Accessibility)", value=True, key="denovo_use_sa")
        if use_sa_score:
            sa_weight = st.slider("SA Score Weight:", 0.0, 2.0, 1.0, key="denovo_sa_weight")
        
        # Similarity components
        use_similarity = st.checkbox("Similarity to Reference", value=False, key="denovo_use_similarity")
        if use_similarity:
            similarity_weight = st.slider("Similarity Weight:", 0.0, 2.0, 1.0, key="denovo_sim_weight")
            
            reference_molecules = st.text_area(
                "Reference SMILES:",
                placeholder="CCO\nc1ccccc1",
                key="denovo_ref_molecules"
            )
        
        # Custom components
        use_custom_filter = st.checkbox("Custom Molecular Filters", value=False, key="denovo_use_custom")
        if use_custom_filter:
            mw_range = st.slider("Molecular Weight Range:", 100, 800, (200, 500), key="denovo_mw_range")
            logp_range = st.slider("LogP Range:", -3.0, 8.0, (-1.0, 5.0), key="denovo_logp_range")
    
    with col2:
        st.markdown("#### üß™ Advanced Scoring")
        
        # Biological activity prediction
        use_bioactivity = st.checkbox("Bioactivity Prediction", value=False, key="denovo_use_bioactivity")
        if use_bioactivity:
            target_protein = st.selectbox(
                "Target Protein:",
                ["DRD2", "EGFR", "BACE1", "CDK2", "Custom"],
                key="denovo_target_protein"
            )
            
            bioactivity_weight = st.slider("Bioactivity Weight:", 0.0, 3.0, 1.5, key="denovo_bioactivity_weight")
        
        # ADMET properties
        use_admet = st.checkbox("ADMET Properties", value=False, key="denovo_use_admet")
        if use_admet:
            admet_components = st.multiselect(
                "ADMET Components:",
                ["Solubility", "Permeability", "CYP Inhibition", "hERG", "Toxicity"],
                default=["Solubility", "Permeability"],
                key="denovo_admet_components"
            )
        
        # Aggregation method
        st.markdown("#### ‚öñÔ∏è Score Aggregation")
        aggregation_method = st.selectbox(
            "Aggregation Method:",
            ["Weighted Sum", "Geometric Mean", "Product", "Custom Function"],
            key="denovo_aggregation"
        )
        
        if aggregation_method == "Custom Function":
            custom_function = st.text_area(
                "Custom Scoring Function (Python):",
                placeholder="def custom_score(qed, sa, similarity):\n    return qed * 0.5 + sa * 0.3 + similarity * 0.2",
                key="denovo_custom_function"
            )
    
    # Scoring test
    if st.button("üß™ Test Scoring Function", key="test_denovo_scoring"):
        test_denovo_scoring()

def show_denovo_generation():
    """Step 3: Generation process"""
    
    st.subheader("üöÄ Molecule Generation")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ‚öôÔ∏è Generation Parameters")
        
        generation_mode = st.radio(
            "Generation Strategy:",
            ["Standard Sampling", "Reinforcement Learning", "Diversity Sampling"],
            key="denovo_gen_mode"
        )
        
        num_molecules = st.number_input(
            "Number of Molecules to Generate:",
            min_value=10,
            max_value=10000,
            value=1000,
            key="denovo_num_molecules"
        )
        
        temperature = st.slider(
            "Sampling Temperature:",
            min_value=0.1,
            max_value=2.0,
            value=1.0,
            step=0.1,
            key="denovo_temperature"
        )
        
        if generation_mode == "Reinforcement Learning":
            rl_steps = st.number_input(
                "RL Training Steps:",
                min_value=100,
                max_value=5000,
                value=1000,
                key="denovo_rl_steps"
            )
            
            sigma = st.slider(
                "RL Sigma (Exploration):",
                min_value=10.0,
                max_value=200.0,
                value=60.0,
                key="denovo_rl_sigma"
            )
        
        elif generation_mode == "Diversity Sampling":
            diversity_penalty = st.slider(
                "Diversity Penalty:",
                min_value=0.0,
                max_value=1.0,
                value=0.1,
                key="denovo_diversity_penalty"
            )
    
    with col2:
        st.markdown("#### üìã Output Configuration")
        
        output_format = st.multiselect(
            "Output Formats:",
            ["CSV", "SDF", "JSON", "SMILES"],
            default=["CSV", "SDF"],
            key="denovo_output_formats"
        )
        
        include_properties = st.multiselect(
            "Include Properties:",
            ["Molecular Weight", "LogP", "TPSA", "QED", "SA Score", "Similarity", "Bioactivity"],
            default=["Molecular Weight", "LogP", "QED"],
            key="denovo_include_props"
        )
        
        filter_duplicates = st.checkbox("Remove Duplicates", value=True, key="denovo_filter_duplicates")
        filter_invalid = st.checkbox("Remove Invalid Molecules", value=True, key="denovo_filter_invalid")
        
        # Real-time monitoring
        enable_monitoring = st.checkbox("Enable Real-time Monitoring", value=True, key="denovo_monitoring")
        if enable_monitoring:
            update_frequency = st.number_input(
                "Update Frequency (molecules):",
                min_value=10,
                max_value=1000,
                value=100,
                key="denovo_update_freq"
            )
    
    # Generation execution
    if st.button("üöÄ Start Generation", type="primary", key="start_denovo_generation"):
        execute_denovo_generation(generation_mode, num_molecules, temperature)

def show_denovo_optimization():
    """Step 4: Optimize generated molecules"""
    
    st.subheader("üìà Molecule Optimization")
    
    # Check if generation results exist
    if 'denovo_generation_results' not in st.session_state:
        st.warning("‚ö†Ô∏è No generation results found. Complete generation step first.")
        return
    
    generation_results = st.session_state.denovo_generation_results
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üéØ Optimization Strategy")
        
        optimization_method = st.radio(
            "Optimization Method:",
            ["Reinforcement Learning", "Genetic Algorithm", "Hill Climbing", "Multi-objective"],
            key="denovo_opt_method"
        )
        
        # Select molecules to optimize
        selection_method = st.radio(
            "Molecule Selection:",
            ["Top Scoring", "Diverse Set", "Custom Selection"],
            key="denovo_selection_method"
        )
        
        if selection_method == "Top Scoring":
            top_n = st.number_input(
                "Number of Top Molecules:",
                min_value=10,
                max_value=min(500, len(generation_results)),
                value=min(100, len(generation_results)),
                key="denovo_top_n"
            )
        
        elif selection_method == "Diverse Set":
            diversity_threshold = st.slider(
                "Diversity Threshold:",
                min_value=0.3,
                max_value=0.9,
                value=0.6,
                key="denovo_diversity_threshold"
            )
        
        optimization_cycles = st.number_input(
            "Optimization Cycles:",
            min_value=1,
            max_value=10,
            value=3,
            key="denovo_opt_cycles"
        )
    
    with col2:
        st.markdown("#### ‚öñÔ∏è Optimization Objectives")
        
        # Multi-objective weights
        st.markdown("**Objective Weights:**")
        
        activity_weight = st.slider(
            "Biological Activity:",
            min_value=0.0,
            max_value=2.0,
            value=1.0,
            key="denovo_activity_weight"
        )
        
        druglikeness_weight = st.slider(
            "Drug-likeness:",
            min_value=0.0,
            max_value=2.0,
            value=0.8,
            key="denovo_druglikeness_weight"
        )
        
        novelty_weight = st.slider(
            "Novelty/Diversity:",
            min_value=0.0,
            max_value=2.0,
            value=0.3,
            key="denovo_novelty_weight"
        )
        
        synthesis_weight = st.slider(
            "Synthetic Accessibility:",
            min_value=0.0,
            max_value=2.0,
            value=0.5,
            key="denovo_synthesis_weight"
        )
        
        # Constraints
        st.markdown("**Optimization Constraints:**")
        
        maintain_similarity = st.checkbox(
            "Maintain Structural Similarity",
            value=True,
            key="denovo_maintain_similarity"
        )
        
        if maintain_similarity:
            similarity_threshold = st.slider(
                "Min Similarity Threshold:",
                min_value=0.3,
                max_value=0.9,
                value=0.6,
                key="denovo_similarity_threshold"
            )
    
    # Optimization execution
    if st.button("üöÄ Start Optimization", type="primary", key="start_denovo_optimization"):
        execute_denovo_optimization(optimization_method, selection_method)

def show_denovo_library_design():
    """Step 5: Design focused libraries"""
    
    st.subheader("üìö Library Design")
    
    # Check if optimization results exist
    if 'denovo_optimization_results' not in st.session_state:
        st.warning("‚ö†Ô∏è No optimization results found. Complete optimization step first.")
        return
    
    optimization_results = st.session_state.denovo_optimization_results
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üé® Library Design Strategy")
        
        library_type = st.radio(
            "Library Type:",
            ["Focused Library", "Diversity Library", "Scaffold-based Library", "Lead Optimization"],
            key="denovo_library_type"
        )
        
        library_size = st.number_input(
            "Target Library Size:",
            min_value=50,
            max_value=5000,
            value=500,
            key="denovo_library_size"
        )
        
        if library_type == "Focused Library":
            focus_criteria = st.multiselect(
                "Focus Criteria:",
                ["High Activity", "Drug-likeness", "Novel Scaffolds", "Synthetic Accessibility"],
                default=["High Activity", "Drug-likeness"],
                key="denovo_focus_criteria"
            )
        
        elif library_type == "Diversity Library":
            diversity_method = st.selectbox(
                "Diversification Method:",
                ["MaxMin Algorithm", "Clustering", "Fingerprint Diversity"],
                key="denovo_diversity_method"
            )
            
            diversity_metric = st.selectbox(
                "Diversity Metric:",
                ["Tanimoto", "ECFP4", "MACCS", "RDKit"],
                key="denovo_diversity_metric"
            )
        
        elif library_type == "Scaffold-based Library":
            scaffold_selection = st.radio(
                "Scaffold Selection:",
                ["Most Frequent", "Most Active", "Most Diverse"],
                key="denovo_scaffold_selection"
            )
            
            max_scaffolds = st.number_input(
                "Maximum Scaffolds:",
                min_value=5,
                max_value=50,
                value=10,
                key="denovo_max_scaffolds"
            )
    
    with col2:
        st.markdown("#### üìä Library Composition")
        
        # Property distribution targets
        st.markdown("**Target Property Ranges:**")
        
        target_mw_range = st.slider(
            "Molecular Weight Range:",
            min_value=100,
            max_value=800,
            value=(250, 450),
            key="denovo_target_mw"
        )
        
        target_logp_range = st.slider(
            "LogP Range:",
            min_value=-2.0,
            max_value=6.0,
            value=(1.0, 4.0),
            key="denovo_target_logp"
        )
        
        target_tpsa_range = st.slider(
            "TPSA Range:",
            min_value=0,
            max_value=200,
            value=(40, 120),
            key="denovo_target_tpsa"
        )
        
        # Chemical space coverage
        st.markdown("**Chemical Space Coverage:**")
        
        functional_groups = st.multiselect(
            "Required Functional Groups:",
            ["Aromatic rings", "Heterocycles", "Amines", "Acids", "Ethers", "Halides"],
            key="denovo_functional_groups"
        )
        
        scaffold_diversity = st.slider(
            "Scaffold Diversity Target:",
            min_value=0.3,
            max_value=0.9,
            value=0.7,
            key="denovo_scaffold_diversity"
        )
        
        # Quality filters
        st.markdown("**Quality Filters:**")
        
        min_activity_score = st.slider(
            "Minimum Activity Score:",
            min_value=0.0,
            max_value=1.0,
            value=0.6,
            key="denovo_min_activity"
        )
        
        enforce_lipinski = st.checkbox(
            "Enforce Lipinski's Rule",
            value=True,
            key="denovo_enforce_lipinski"
        )
    
    # Library design execution
    if st.button("üöÄ Design Library", type="primary", key="start_denovo_library"):
        execute_denovo_library_design(library_type, library_size)
    
    # Display final results
    if 'denovo_final_library' in st.session_state:
        show_denovo_final_results()

# Pipeline execution functions
def execute_denovo_training(training_mode, molecules):
    """Execute the training/setup phase"""
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("üîß Setting up training configuration...")
        progress_bar.progress(0.2)
        time.sleep(1)
        
        if training_mode == "Pre-trained Model":
            status_text.text("‚úÖ Pre-trained model ready")
            progress_bar.progress(1.0)
            
        else:
            status_text.text(f"üéì Starting {training_mode.lower()}...")
            progress_bar.progress(0.4)
            time.sleep(2)
            
            status_text.text("üìä Processing training data...")
            progress_bar.progress(0.6)
            time.sleep(2)
            
            status_text.text("üöÄ Training model...")
            progress_bar.progress(0.8)
            time.sleep(3)
            
            status_text.text("‚úÖ Training completed successfully!")
            progress_bar.progress(1.0)
        
        # Store training results
        st.session_state.denovo_training_complete = True
        st.session_state.denovo_trained_model = f"trained_model_{training_mode.lower().replace(' ', '_')}.prior"
        
        st.success(f"‚úÖ {training_mode} setup completed successfully!")
        
    except Exception as e:
        st.error(f"‚ùå Training failed: {str(e)}")

def execute_denovo_generation(generation_mode, num_molecules, temperature):
    """Execute the generation phase"""
    
    if 'denovo_training_complete' not in st.session_state:
        st.error("‚ùå Complete training setup first!")
        return
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("üöÄ Initializing generation...")
        progress_bar.progress(0.1)
        time.sleep(1)
        
        # Simulate generation process
        generated_molecules = []
        batch_size = 100
        
        for i in range(0, num_molecules, batch_size):
            current_batch = min(batch_size, num_molecules - i)
            
            status_text.text(f"üß™ Generating molecules {i+1}-{i+current_batch}...")
            progress = 0.1 + (i / num_molecules) * 0.8
            progress_bar.progress(progress)
            
            # Simulate batch generation
            batch_molecules = simulate_denovo_results(current_batch)
            generated_molecules.extend(batch_molecules.to_dict('records'))
            
            time.sleep(0.5)  # Simulate processing time
        
        status_text.text("üìä Processing results...")
        progress_bar.progress(0.9)
        time.sleep(1)
        
        # Create results dataframe
        results_df = pd.DataFrame(generated_molecules)
        
        # Store results
        st.session_state.denovo_generation_results = results_df
        
        progress_bar.progress(1.0)
        status_text.text("‚úÖ Generation completed!")
        
        st.success(f"‚úÖ Generated {len(results_df)} molecules successfully!")
        
        # Show summary
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total Generated", len(results_df))
        
        with col2:
            valid_count = results_df['Valid'].sum()
            st.metric("Valid Molecules", valid_count)
        
        with col3:
            unique_count = results_df['SMILES'].nunique()
            st.metric("Unique Molecules", unique_count)
        
        with col4:
            avg_score = results_df['NLL'].mean()
            st.metric("Avg Score", f"{avg_score:.2f}")
        
    except Exception as e:
        st.error(f"‚ùå Generation failed: {str(e)}")

def execute_denovo_optimization(optimization_method, selection_method):
    """Execute the optimization phase"""
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("üéØ Selecting molecules for optimization...")
        progress_bar.progress(0.2)
        time.sleep(1)
        
        generation_results = st.session_state.denovo_generation_results
        
        # Select molecules based on method
        if selection_method == "Top Scoring":
            top_n = st.session_state.get('denovo_top_n', 100)
            selected_molecules = generation_results.nlargest(top_n, 'NLL')
        else:
            # Simulate selection
            selected_molecules = generation_results.sample(min(100, len(generation_results)))
        
        status_text.text(f"üöÄ Running {optimization_method.lower()}...")
        progress_bar.progress(0.5)
        time.sleep(3)
        
        # Simulate optimization
        optimized_molecules = simulate_optimization_results(selected_molecules['SMILES'].tolist(), 100)
        
        status_text.text("üìä Evaluating optimized molecules...")
        progress_bar.progress(0.8)
        time.sleep(2)
        
        # Store optimization results
        st.session_state.denovo_optimization_results = optimized_molecules
        
        progress_bar.progress(1.0)
        status_text.text("‚úÖ Optimization completed!")
        
        st.success(f"‚úÖ Optimized {len(optimized_molecules)} molecules successfully!")
        
        # Show optimization summary
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Molecules Optimized", len(optimized_molecules))
        
        with col2:
            final_score = optimized_molecules['Total_Score'].max()
            st.metric("Best Score", f"{final_score:.3f}")
        
        with col3:
            improvement = optimized_molecules['Score_Improvement'].mean()
            st.metric("Avg Improvement", f"{improvement:.3f}")
        
    except Exception as e:
        st.error(f"‚ùå Optimization failed: {str(e)}")

def execute_denovo_library_design(library_type, library_size):
    """Execute the library design phase"""
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("üìö Analyzing optimization results...")
        progress_bar.progress(0.2)
        time.sleep(1)
        
        optimization_results = st.session_state.denovo_optimization_results
        
        status_text.text(f"üé® Designing {library_type.lower()}...")
        progress_bar.progress(0.5)
        time.sleep(2)
        
        # Simulate library design
        if library_type == "Focused Library":
            # Select high-scoring, drug-like molecules
            library = optimization_results.nlargest(library_size, 'Total_Score')
        
        elif library_type == "Diversity Library":
            # Simulate diversity selection
            library = optimization_results.sample(min(library_size, len(optimization_results)))
        
        else:
            # Default selection
            library = optimization_results.head(library_size)
        
        status_text.text("üîç Applying quality filters...")
        progress_bar.progress(0.8)
        time.sleep(1)
        
        # Apply additional filtering
        library = library[library['Total_Score'] > 0.5]  # Quality threshold
        
        # Store final library
        st.session_state.denovo_final_library = library
        
        progress_bar.progress(1.0)
        status_text.text("‚úÖ Library design completed!")
        
        st.success(f"‚úÖ Designed library with {len(library)} molecules!")
        
    except Exception as e:
        st.error(f"‚ùå Library design failed: {str(e)}")

def show_denovo_final_results():
    """Display final pipeline results"""
    
    st.markdown("---")
    st.subheader("üèÜ Final Pipeline Results")
    
    final_library = st.session_state.denovo_final_library
    
    # Results summary
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Final Library Size", len(final_library))
    
    with col2:
        avg_score = final_library['Total_Score'].mean()
        st.metric("Average Score", f"{avg_score:.3f}")
    
    with col3:
        top_score = final_library['Total_Score'].max()
        st.metric("Top Score", f"{top_score:.3f}")
    
    with col4:
        diversity = final_library['SMILES'].nunique() / len(final_library)
        st.metric("Diversity", f"{diversity:.3f}")
    
    # Display library
    st.subheader("üìã Final Molecular Library")
    st.dataframe(final_library, use_container_width=True)
    
    # Visualization
    col1, col2 = st.columns(2)
    
    with col1:
        if len(final_library) > 0:
            fig = px.histogram(
                final_library, 
                x='Total_Score', 
                title="Score Distribution in Final Library",
                nbins=20
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        if 'Molecular_Weight' in final_library.columns:
            fig = px.scatter(
                final_library,
                x='Molecular_Weight',
                y='Total_Score',
                title="Molecular Weight vs Score",
                hover_data=['SMILES']
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # Download options
    st.subheader("üì• Download Final Results")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        csv_data = final_library.to_csv(index=False)
        st.download_button(
            "üìÑ Download CSV",
            csv_data,
            file_name="denovo_final_library.csv",
            mime="text/csv"
        )
    
    with col2:
        json_data = final_library.to_json(indent=2)
        st.download_button(
            "üìã Download JSON",
            json_data,
            file_name="denovo_final_library.json",
            mime="application/json"
        )
    
    with col3:
        # Create SDF
        sdf_data = create_sdf_from_dataframe(final_library)
        st.download_button(
            "üß™ Download SDF",
            sdf_data,
            file_name="denovo_final_library.sdf",
            mime="chemical/x-mdl-sdfile"
        )

def test_denovo_scoring():
    """Test the configured scoring function"""
    
    # Sample molecules for testing
    test_molecules = ["CCO", "c1ccccc1", "CC(=O)O", "CCN(CC)CC"]
    
    st.markdown("#### üß™ Scoring Function Test")
    
    results = []
    for smiles in test_molecules:
        # Simulate scoring
        qed_score = np.random.uniform(0.3, 0.9)
        sa_score = np.random.uniform(0.2, 0.8)
        
        results.append({
            'SMILES': smiles,
            'QED': qed_score,
            'SA_Score': sa_score,
            'Combined_Score': (qed_score + sa_score) / 2
        })
    
    test_df = pd.DataFrame(results)
    st.dataframe(test_df)
    
    st.success("‚úÖ Scoring function test completed!")

def simulate_example_dataset(dataset_name):
    """Simulate loading an example dataset"""
    
    datasets = {
        "ChEMBL Drug-like": [
            "CC(C)CC1=CC=C(C=C1)C(C)C(=O)O",  # Ibuprofen
            "CC1=CC=C(C=C1)C(=O)C2=CC=CC=C2",  # Example drug-like
            "COC1=CC=C(C=C1)CCN",  # Tyramine derivative
        ] * 50,  # Repeat to simulate larger dataset
        
        "Natural Products": [
            "CC(=O)OC1=CC=CC=C1C(=O)O",  # Aspirin
            "CN1C=NC2=C1C(=O)N(C(=O)N2C)C",  # Caffeine
            "CC1=CC=C(C=C1)C(C)(C)C",  # Example natural product
        ] * 50,
        
        "Kinase Inhibitors": [
            "CC1=C(C=C(C=C1)NC(=O)C2=CC=CC=N2)C",
            "CN1CCN(CC1)C2=CC=C(C=C2)C(=O)N",
            "CC1=CC=C(C=C1)C(=O)NC2=CC=CC=C2",
        ] * 50,
        
        "GPCR Ligands": [
            "CCN(CC)CCOC1=CC=C(C=C1)C=C",
            "CN(C)CCC=C1C2=CC=CC=C2CCC3=CC=CC=C13",
            "CC1=CC=C(C=C1)CCN(C)C",
        ] * 50
    }
    
    return datasets.get(dataset_name, [])

def create_sdf_from_dataframe(df):
    """Create SDF format from dataframe"""
    
    sdf_content = ""
    for idx, row in df.iterrows():
        sdf_content += f"""
{row.get('SMILES', 'Unknown')}
  Generated by REINVENT4 De Novo Pipeline
  
  0  0  0  0  0  0  0  0  0  0999 V2000
M  END
> <Total_Score>
{row.get('Total_Score', '')}

> <SMILES>
{row.get('SMILES', '')}

> <Molecular_Weight>
{row.get('Molecular_Weight', '')}

$$$$
"""
    
    return sdf_content

def generate_denovo_molecules(model_file, num_smiles, device, output_file,
                            unique_molecules, randomize_smiles, seed, batch_size,
                            temperature, tb_logdir):
    """Generate de novo molecules using REINVENT"""
    
    try:
        # Create configuration
        config = {
            "run_type": "sampling",
            "device": device,
            "parameters": {
                "model_file": model_file,
                "output_file": output_file,
                "num_smiles": num_smiles,
                "unique_molecules": unique_molecules,
                "randomize_smiles": randomize_smiles,
                "batch_size": batch_size,
                "temperature": temperature
            }
        }
        
        if seed:
            config["seed"] = seed
        
        if tb_logdir:
            config["tb_logdir"] = tb_logdir
        
        # Save config to temporary file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump(config, f, indent=2)
            config_file = f.name
        
        # Create a simple args object
        class Args:
            def __init__(self):
                self.config_filename = Path(config_file)
                self.config_format = "json"
                self.log_level = "info"
                self.log_filename = None
                self.dotenv_filename = None
                self.device = device
                self.seed = seed
                self.enable_rdkit_log_levels = None
        
        args = Args()
        
        # Show progress
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("Initializing generation...")
        progress_bar.progress(0.1)
        
        # Run generation
        status_text.text("Generating molecules...")
        progress_bar.progress(0.5)
        
        # Here you would call the actual REINVENT main function
        # For now, we'll simulate the process
        import time
        time.sleep(2)  # Simulate processing time
        
        # Load results (simulated)
        results_df = simulate_denovo_results(num_smiles)
        
        progress_bar.progress(1.0)
        status_text.text("Generation complete!")
        
        # Store results in session state
        st.session_state.denovo_results = {
            'dataframe': results_df,
            'config': config,
            'output_file': output_file
        }
        
        st.success(f"‚úÖ Successfully generated {len(results_df)} molecules!")
        
        # Clean up temporary file
        os.unlink(config_file)
        
    except Exception as e:
        st.error(f"‚ùå Error during generation: {str(e)}")

def simulate_denovo_results(num_smiles):
    """Simulate de novo generation results for demo purposes"""
    
    # Sample SMILES for demonstration
    sample_smiles = [
        "CCO",
        "c1ccccc1",
        "CCN(CC)CC",
        "CC(C)O",
        "c1ccncc1",
        "CC(=O)O",
        "CCC(C)C",
        "c1ccc2ccccc2c1",
        "CCOCC",
        "CC(C)(C)O"
    ]
    
    # Generate random data
    np.random.seed(42)
    
    data = []
    for i in range(min(num_smiles, 100)):  # Limit for demo
        smiles = np.random.choice(sample_smiles)
        nll = np.random.uniform(-5, -1)
        mw = np.random.uniform(100, 500)
        logp = np.random.uniform(-2, 5)
        
        data.append({
            'SMILES': smiles,
            'NLL': nll,
            'Molecular_Weight': mw,
            'LogP': logp,
            'Valid': np.random.choice([True, False], p=[0.9, 0.1])
        })
    
    return pd.DataFrame(data)

def show_generation_results(results, title):
    """Display generation results"""
    
    st.markdown(f'<div class="sub-header">üìä {title} Results</div>', unsafe_allow_html=True)
    
    df = results['dataframe']
    
    # Summary statistics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Generated", len(df))
    
    with col2:
        valid_count = df['Valid'].sum() if 'Valid' in df.columns else len(df)
        st.metric("Valid Molecules", valid_count)
    
    with col3:
        unique_count = df['SMILES'].nunique() if 'SMILES' in df.columns else len(df)
        st.metric("Unique Molecules", unique_count)
    
    with col4:
        avg_nll = df['NLL'].mean() if 'NLL' in df.columns else 0
        st.metric("Avg NLL", f"{avg_nll:.2f}")
    
    # Display data table
    st.subheader("Generated Molecules")
    st.dataframe(df, use_container_width=True)
    
    # Visualization
    if len(df) > 0:
        st.subheader("Property Distribution")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if 'Molecular_Weight' in df.columns:
                fig = px.histogram(df, x='Molecular_Weight', title="Molecular Weight Distribution")
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            if 'LogP' in df.columns:
                fig = px.histogram(df, x='LogP', title="LogP Distribution")
                st.plotly_chart(fig, use_container_width=True)
    
    # Download options
    st.subheader("Download Results")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        csv_data = df.to_csv(index=False)
        st.download_button(
            "üìÑ Download CSV",
            csv_data,
            file_name=results['output_file'],
            mime="text/csv"
        )
    
    with col2:
        json_data = df.to_json(indent=2)
        st.download_button(
            "üìã Download JSON",
            json_data,
            file_name=results['output_file'].replace('.csv', '.json'),
            mime="application/json"
        )
    
    with col3:
        config_data = json.dumps(results['config'], indent=2)
        st.download_button(
            "‚öôÔ∏è Download Config",
            config_data,
            file_name="config.json",
            mime="application/json"
        )

def show_scaffold_page():
    """Scaffold hopping pipeline with complete workflow"""
    
    st.markdown('<div class="sub-header">üß¨ Scaffold Hopping Pipeline</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    Complete scaffold hopping pipeline: Input Scaffolds ‚Üí Training ‚Üí Generation ‚Üí Optimization ‚Üí Library Design
    </div>
    """, unsafe_allow_html=True)
    
    # Pipeline tabs for complete workflow
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üß¨ 1. Scaffold Input", 
        "üéì 2. Model Training", 
        "üöÄ 3. Decoration", 
        "üìà 4. Optimization", 
        "üìö 5. Library Design"
    ])
    
    with tab1:
        show_scaffold_input()
    
    with tab2:
        show_scaffold_training()
    
    with tab3:
        show_scaffold_decoration()
    
    with tab4:
        show_scaffold_optimization()
    
    with tab5:
        show_scaffold_library_design()

def show_scaffold_input():
    """Step 1: Input scaffold templates"""
    
    st.subheader("üß¨ Scaffold Template Input")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìã Scaffold Templates")
        
        input_method = st.radio(
            "Input Method:",
            ["Upload File", "Text Input", "Scaffold Database"],
            key="scaffold_input_method"
        )
        
        scaffolds = []
        
        if input_method == "Upload File":
            uploaded_file = st.file_uploader(
                "Upload Scaffold File",
                type=['smi', 'txt', 'csv'],
                help="File containing scaffolds with [*] attachment points",
                key="scaffold_upload"
            )
            
            if uploaded_file:
                content = uploaded_file.read().decode('utf-8')
                scaffolds = [line.strip() for line in content.split('\n') if line.strip()]
                st.success(f"‚úÖ Loaded {len(scaffolds)} scaffolds")
        
        elif input_method == "Text Input":
            scaffold_text = st.text_area(
                "Enter Scaffolds (one per line)",
                placeholder="c1ccc([*])cc1\nc1ccnc([*])c1\nC([*])C([*])=O\n...",
                height=150,
                help="Enter scaffolds with [*] marking attachment points",
                key="scaffold_text_input"
            )
            
            if scaffold_text:
                scaffolds = [line.strip() for line in scaffold_text.split('\n') if line.strip()]
        
        else:  # Scaffold Database
            scaffold_class = st.selectbox(
                "Scaffold Class:",
                ["Kinase Scaffolds", "GPCR Scaffolds", "Ion Channel Scaffolds", "Protease Scaffolds"],
                key="scaffold_class"
            )
            
            if st.button("Load Scaffold Database", key="load_scaffold_db"):
                scaffolds = simulate_scaffold_database(scaffold_class)
                st.session_state.scaffold_templates = scaffolds
                st.success(f"‚úÖ Loaded {len(scaffolds)} scaffolds from database")
        
        # Store scaffolds
        if scaffolds:
            st.session_state.scaffold_templates = scaffolds
            
            # Show scaffold preview
            st.markdown("**Scaffold Preview:**")
            for i, scaffold in enumerate(scaffolds[:5]):
                st.code(scaffold)
            if len(scaffolds) > 5:
                st.info(f"... and {len(scaffolds) - 5} more scaffolds")
    
    with col2:
        st.markdown("#### ‚öôÔ∏è Decoration Strategy")
        
        decoration_mode = st.radio(
            "Decoration Mode:",
            ["R-Group Addition", "Scaffold Hopping", "Fragment Growing"],
            key="decoration_mode"
        )
        
        if decoration_mode == "R-Group Addition":
            st.markdown("**R-Group Configuration:**")
            
            attachment_points = st.number_input(
                "Max Attachment Points:",
                min_value=1,
                max_value=5,
                value=2,
                key="max_attachment_points"
            )
            
            r_group_complexity = st.selectbox(
                "R-Group Complexity:",
                ["Simple (1-3 atoms)", "Medium (4-8 atoms)", "Complex (9+ atoms)"],
                index=1,
                key="rgroup_complexity"
            )
            
            functional_groups = st.multiselect(
                "Allowed Functional Groups:",
                ["Alkyl", "Aromatic", "Amine", "Alcohol", "Ether", "Ester", "Amide", "Halide"],
                default=["Alkyl", "Aromatic", "Amine"],
                key="allowed_functional_groups"
            )
        
        elif decoration_mode == "Scaffold Hopping":
            st.markdown("**Scaffold Hopping Settings:**")
            
            similarity_threshold = st.slider(
                "Similarity Threshold:",
                min_value=0.3,
                max_value=0.9,
                value=0.6,
                step=0.05,
                key="scaffold_similarity_threshold"
            )
            
            preserve_pharmacophore = st.checkbox(
                "Preserve Pharmacophore",
                value=True,
                key="preserve_pharmacophore"
            )
            
            scaffold_diversity = st.slider(
                "Scaffold Diversity:",
                min_value=0.1,
                max_value=1.0,
                value=0.5,
                key="scaffold_diversity"
            )
        
        else:  # Fragment Growing
            st.markdown("**Fragment Growing Settings:**")
            
            growth_direction = st.multiselect(
                "Growth Directions:",
                ["N-terminal", "C-terminal", "Side chains", "Ring expansion"],
                default=["Side chains"],
                key="growth_directions"
            )
            
            max_growth_steps = st.number_input(
                "Max Growth Steps:",
                min_value=1,
                max_value=5,
                value=2,
                key="max_growth_steps"
            )
        
        # Training data for scaffolds
        st.markdown("#### üìä Training Data")
        
        use_existing_data = st.checkbox(
            "Use Existing Decorated Examples",
            value=True,
            key="use_existing_data"
        )
        
        if use_existing_data:
            data_source = st.selectbox(
                "Data Source:",
                ["ChEMBL", "PubChem", "Internal Database", "Upload Custom"],
                key="scaffold_data_source"
            )
            
            min_examples = st.number_input(
                "Min Examples per Scaffold:",
                min_value=10,
                max_value=1000,
                value=100,
                key="min_examples_per_scaffold"
            )

def show_scaffold_training():
    """Step 2: Train/fine-tune models for scaffold decoration"""
    
    st.subheader("üéì Model Training for Scaffold Decoration")
    
    if 'scaffold_templates' not in st.session_state:
        st.warning("‚ö†Ô∏è Please input scaffold templates first.")
        return
    
    scaffolds = st.session_state.scaffold_templates
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üß† Model Configuration")
        
        base_model = st.selectbox(
            "Base Model:",
            ["priors/libinvent.prior", "priors/reinvent.prior"],
            key="scaffold_base_model"
        )
        
        training_strategy = st.radio(
            "Training Strategy:",
            ["Transfer Learning", "Fine-tuning", "Curriculum Learning"],
            key="scaffold_training_strategy"
        )
        
        if training_strategy == "Transfer Learning":
            transfer_layers = st.multiselect(
                "Layers to Transfer:",
                ["Embedding", "Encoder", "Decoder", "All"],
                default=["Embedding", "Encoder"],
                key="transfer_layers"
            )
            
            freeze_layers = st.checkbox(
                "Freeze Transferred Layers Initially",
                value=True,
                key="freeze_layers"
            )
        
        elif training_strategy == "Curriculum Learning":
            curriculum_order = st.selectbox(
                "Curriculum Order:",
                ["Simple to Complex", "Frequent to Rare", "Easy to Hard"],
                key="curriculum_order"
            )
            
            curriculum_stages = st.number_input(
                "Number of Stages:",
                min_value=2,
                max_value=5,
                value=3,
                key="scaffold_curriculum_stages"
            )
    
    with col2:
        st.markdown("#### ‚öôÔ∏è Training Parameters")
        
        learning_rate = st.number_input(
            "Learning Rate:",
            min_value=1e-6,
            max_value=1e-2,
            value=5e-4,
            format="%.6f",
            key="scaffold_learning_rate"
        )
        
        batch_size = st.number_input(
            "Batch Size:",
            min_value=8,
            max_value=128,
            value=32,
            key="scaffold_batch_size"
        )
        
        epochs = st.number_input(
            "Training Epochs:",
            min_value=5,
            max_value=100,
            value=20,
            key="scaffold_epochs"
        )
        
        validation_split = st.slider(
            "Validation Split:",
            min_value=0.1,
            max_value=0.3,
            value=0.2,
            key="scaffold_validation_split"
        )
        
        early_stopping = st.checkbox(
            "Early Stopping",
            value=True,
            key="scaffold_early_stopping"
        )
        
        if early_stopping:
            patience = st.number_input(
                "Patience (epochs):",
                min_value=3,
                max_value=20,
                value=5,
                key="scaffold_patience"
            )
    
    # Data augmentation
    st.markdown("#### üîÑ Data Augmentation")
    
    col1, col2 = st.columns(2)
    
    with col1:
        use_augmentation = st.checkbox(
            "Enable Data Augmentation",
            value=True,
            key="use_scaffold_augmentation"
        )
        
        if use_augmentation:
            augmentation_methods = st.multiselect(
                "Augmentation Methods:",
                ["SMILES Randomization", "Ring Flipping", "Stereoisomer Generation", "Tautomer Generation"],
                default=["SMILES Randomization"],
                key="augmentation_methods"
            )
            
            augmentation_factor = st.slider(
                "Augmentation Factor:",
                min_value=1,
                max_value=10,
                value=3,
                key="augmentation_factor"
            )
    
    with col2:
        use_active_learning = st.checkbox(
            "Active Learning",
            value=False,
            key="use_active_learning"
        )
        
        if use_active_learning:
            uncertainty_method = st.selectbox(
                "Uncertainty Method:",
                ["Entropy", "Variance", "Disagreement"],
                key="uncertainty_method"
            )
            
            active_learning_cycles = st.number_input(
                "Active Learning Cycles:",
                min_value=1,
                max_value=5,
                value=2,
                key="active_learning_cycles"
            )
    
    # Training execution
    if st.button("üöÄ Start Training", type="primary", key="start_scaffold_training"):
        execute_scaffold_training(training_strategy, scaffolds)

def show_scaffold_decoration():
    """Step 3: Generate decorated scaffolds"""
    
    st.subheader("üöÄ Scaffold Decoration")
    
    if 'scaffold_training_complete' not in st.session_state:
        st.warning("‚ö†Ô∏è Complete model training first.")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üéØ Generation Parameters")
        
        num_decorations = st.number_input(
            "Decorations per Scaffold:",
            min_value=10,
            max_value=1000,
            value=100,
            key="num_decorations_per_scaffold"
        )
        
        generation_strategy = st.radio(
            "Generation Strategy:",
            ["Greedy Sampling", "Beam Search", "Nucleus Sampling", "Top-k Sampling"],
            key="scaffold_generation_strategy"
        )
        
        if generation_strategy == "Beam Search":
            beam_width = st.number_input(
                "Beam Width:",
                min_value=1,
                max_value=20,
                value=5,
                key="beam_width"
            )
        
        elif generation_strategy == "Nucleus Sampling":
            nucleus_p = st.slider(
                "Nucleus P:",
                min_value=0.1,
                max_value=1.0,
                value=0.9,
                key="nucleus_p"
            )
        
        elif generation_strategy == "Top-k Sampling":
            top_k = st.number_input(
                "Top K:",
                min_value=1,
                max_value=100,
                value=40,
                key="top_k"
            )
        
        temperature = st.slider(
            "Sampling Temperature:",
            min_value=0.1,
            max_value=2.0,
            value=1.0,
            key="scaffold_decoration_temperature"
        )
    
    with col2:
        st.markdown("#### üéõÔ∏è Decoration Control")
        
        control_method = st.radio(
            "Decoration Control:",
            ["Property-guided", "Similarity-guided", "Free Generation"],
            key="decoration_control_method"
        )
        
        if control_method == "Property-guided":
            target_properties = st.multiselect(
                "Target Properties:",
                ["Molecular Weight", "LogP", "TPSA", "QED", "Bioactivity"],
                default=["QED", "Bioactivity"],
                key="target_properties"
            )
            
            for prop in target_properties:
                if prop == "Molecular Weight":
                    mw_target = st.slider(f"{prop} Target:", 200, 600, 400, key=f"target_{prop.lower()}")
                elif prop == "LogP":
                    logp_target = st.slider(f"{prop} Target:", -2.0, 6.0, 2.0, key=f"target_{prop.lower()}")
                elif prop == "QED":
                    qed_target = st.slider(f"{prop} Target:", 0.0, 1.0, 0.7, key=f"target_{prop.lower()}")
        
        elif control_method == "Similarity-guided":
            reference_molecules = st.text_area(
                "Reference Molecules (SMILES):",
                placeholder="CCO\nc1ccccc1\nCC(=O)O",
                key="reference_molecules_scaffold"
            )
            
            similarity_weight = st.slider(
                "Similarity Weight:",
                min_value=0.0,
                max_value=2.0,
                value=1.0,
                key="similarity_weight_scaffold"
            )
        
        # Output filtering
        st.markdown("#### üîç Output Filtering")
        
        apply_filters = st.checkbox(
            "Apply Molecular Filters",
            value=True,
            key="apply_scaffold_filters"
        )
        
        if apply_filters:
            lipinski_filter = st.checkbox("Lipinski's Rule", value=True, key="lipinski_filter_scaffold")
            pains_filter = st.checkbox("PAINS Filter", value=True, key="pains_filter_scaffold")
            synthetic_filter = st.checkbox("Synthetic Accessibility", value=False, key="synthetic_filter_scaffold")
    
    # Generation execution
    if st.button("üöÄ Generate Decorations", type="primary", key="start_scaffold_decoration"):
        execute_scaffold_decoration()

def execute_scaffold_training(training_strategy, scaffolds):
    """Execute scaffold training"""
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("üîß Preparing training data...")
        progress_bar.progress(0.1)
        time.sleep(1)
        
        status_text.text(f"üéì Starting {training_strategy.lower()}...")
        progress_bar.progress(0.3)
        time.sleep(2)
        
        status_text.text("üìä Processing scaffold templates...")
        progress_bar.progress(0.5)
        time.sleep(2)
        
        status_text.text("üöÄ Training model...")
        progress_bar.progress(0.8)
        time.sleep(3)
        
        progress_bar.progress(1.0)
        status_text.text("‚úÖ Training completed!")
        
        # Store training results
        st.session_state.scaffold_training_complete = True
        st.session_state.scaffold_trained_model = f"scaffold_model_{training_strategy.lower().replace(' ', '_')}.prior"
        
        st.success(f"‚úÖ Scaffold {training_strategy} completed successfully!")
        
    except Exception as e:
        st.error(f"‚ùå Training failed: {str(e)}")

def execute_scaffold_decoration():
    """Execute scaffold decoration generation"""
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        scaffolds = st.session_state.scaffold_templates
        num_decorations = st.session_state.get('num_decorations_per_scaffold', 100)
        
        status_text.text("üöÄ Initializing decoration...")
        progress_bar.progress(0.1)
        time.sleep(1)
        
        all_decorations = []
        
        for i, scaffold in enumerate(scaffolds):
            status_text.text(f"üß¨ Decorating scaffold {i+1}/{len(scaffolds)}...")
            progress = 0.1 + (i / len(scaffolds)) * 0.8
            progress_bar.progress(progress)
            
            # Simulate decoration generation
            decorations = simulate_scaffold_decorations(scaffold, num_decorations)
            all_decorations.extend(decorations)
            
            time.sleep(0.5)
        
        status_text.text("üìä Processing results...")
        progress_bar.progress(0.9)
        time.sleep(1)
        
        # Create results dataframe
        results_df = pd.DataFrame(all_decorations)
        
        # Store results
        st.session_state.scaffold_decoration_results = results_df
        
        progress_bar.progress(1.0)
        status_text.text("‚úÖ Decoration completed!")
        
        st.success(f"‚úÖ Generated {len(results_df)} decorated molecules!")
        
        # Show summary
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total Decorations", len(results_df))
        
        with col2:
            valid_count = results_df['Valid'].sum()
            st.metric("Valid Molecules", valid_count)
        
        with col3:
            unique_count = results_df['Decorated_SMILES'].nunique()
            st.metric("Unique Decorations", unique_count)
        
        with col4:
            avg_score = results_df['Decoration_Score'].mean()
            st.metric("Avg Score", f"{avg_score:.2f}")
        
    except Exception as e:
        st.error(f"‚ùå Decoration failed: {str(e)}")

def simulate_scaffold_database(scaffold_class):
    """Simulate loading scaffolds from database"""
    
    databases = {
        "Kinase Scaffolds": [
            "c1ccc2c(c1)nc([*])n2[*]",  # Benzimidazole
            "c1cc([*])cc2c1nc([*])n2",  # Quinazoline
            "c1ccc2c(c1)nc([*])c([*])n2",  # Quinazoline variant
        ] * 20,
        
        "GPCR Scaffolds": [
            "c1ccc(cc1)C([*])([*])c2ccccc2",  # Diphenylmethane
            "c1ccc2c(c1)oc([*])c([*])c2=O",  # Coumarin
            "c1cc([*])c([*])cc1",  # Benzene
        ] * 20,
        
        "Ion Channel Scaffolds": [
            "c1ccc(cc1)C([*])=C([*])c2ccccc2",  # Stilbene
            "c1cc([*])nc([*])c1",  # Pyridine
            "c1c([*])cnc([*])c1",  # Pyrimidine
        ] * 20,
        
        "Protease Scaffolds": [
            "CC([*])C(=O)N([*])C",  # Amide
            "c1cc([*])c(C(=O)N([*]))cc1",  # Benzoyl amide
            "N([*])C(=O)C([*])N",  # Dipeptide mimic
        ] * 20
    }
    
    return databases.get(scaffold_class, [])

def simulate_scaffold_decorations(scaffold, num_decorations):
    """Simulate decoration generation for a scaffold"""
    
    np.random.seed(42)
    decorations = []
    
    # Sample R-groups for decoration
    r_groups = ["H", "C", "CC", "CCC", "O", "N", "F", "Cl", "Br", "CF3", "c1ccccc1", "CCO"]
    
    for i in range(min(num_decorations, 50)):  # Limit for demo
        # Replace [*] with random R-groups
        decorated = scaffold
        while "[*]" in decorated:
            r_group = np.random.choice(r_groups)
            decorated = decorated.replace("[*]", r_group, 1)
        
        decorations.append({
            'Original_Scaffold': scaffold,
            'Decorated_SMILES': decorated,
            'Decoration_Score': np.random.uniform(0.3, 0.9),
            'Molecular_Weight': np.random.uniform(200, 500),
            'LogP': np.random.uniform(-1, 5),
            'QED': np.random.uniform(0.2, 0.8),
            'Valid': np.random.choice([True, False], p=[0.85, 0.15])
        })
    
    return decorations

def show_scaffold_optimization():
    """Step 4: Optimize decorated scaffolds"""
    
    st.subheader("üìà Scaffold Decoration Optimization")
    
    if 'scaffold_decoration_results' not in st.session_state:
        st.warning("‚ö†Ô∏è Complete scaffold decoration first.")
        return
    
    # Implementation similar to denovo optimization but focused on scaffold decorations
    st.info("üöß Scaffold optimization pipeline implementation...")

def show_scaffold_library_design():
    """Step 5: Design libraries from optimized decorations"""
    
    st.subheader("üìö Scaffold Library Design")
    
    if 'scaffold_decoration_results' not in st.session_state:
        st.warning("‚ö†Ô∏è Complete scaffold decoration first.")
        return
    
    # Implementation for scaffold-based library design
    st.info("üöß Scaffold library design implementation...")

def run_scaffold_generation(mode, scaffolds, model_file, device, num_compounds,
                          unique_molecules, randomize_smiles, temperature, output_file):
    """Run scaffold decoration or hopping"""
    
    try:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("Preparing scaffolds...")
        progress_bar.progress(0.2)
        
        # Create temporary scaffold file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.smi', delete=False) as f:
            for scaffold in scaffolds:
                f.write(f"{scaffold}\n")
            scaffold_file = f.name
        
        # Create configuration
        config = {
            "run_type": "sampling",
            "device": device,
            "parameters": {
                "model_file": model_file,
                "smiles_file": scaffold_file,
                "output_file": output_file,
                "num_smiles": num_compounds,
                "unique_molecules": unique_molecules,
                "randomize_smiles": randomize_smiles,
                "temperature": temperature
            }
        }
        
        status_text.text(f"Running {mode.lower()}...")
        progress_bar.progress(0.7)
        
        # Simulate processing
        import time
        time.sleep(3)
        
        # Generate simulated results
        results_df = simulate_scaffold_results(scaffolds, num_compounds, mode)
        
        progress_bar.progress(1.0)
        status_text.text("Generation complete!")
        
        st.session_state.scaffold_results = {
            'dataframe': results_df,
            'config': config,
            'output_file': output_file
        }
        
        st.success(f"‚úÖ Successfully generated compounds for {len(scaffolds)} scaffolds!")
        
        # Clean up
        os.unlink(scaffold_file)
        
    except Exception as e:
        st.error(f"‚ùå Error during {mode.lower()}: {str(e)}")

def simulate_scaffold_results(scaffolds, num_compounds, mode):
    """Simulate scaffold generation results"""
    
    np.random.seed(42)
    data = []
    
    # Sample R-groups for decoration
    r_groups = ["[H]", "C", "CC", "CCC", "O", "N", "F", "Cl", "Br", "CF3"]
    
    for scaffold in scaffolds:
        for i in range(min(num_compounds, 20)):  # Limit for demo
            # Generate a decorated molecule
            if "[*]" in scaffold:
                r_group = np.random.choice(r_groups)
                decorated = scaffold.replace("[*]", r_group)
            else:
                decorated = scaffold + "CC"  # Simple decoration
            
            nll = np.random.uniform(-5, -1)
            mw = np.random.uniform(150, 600)
            logp = np.random.uniform(-1, 6)
            similarity = np.random.uniform(0.6, 0.95)
            
            data.append({
                'Scaffold': scaffold,
                'Generated_SMILES': decorated,
                'NLL': nll,
                'Molecular_Weight': mw,
                'LogP': logp,
                'Scaffold_Similarity': similarity,
                'Valid': np.random.choice([True, False], p=[0.85, 0.15])
            })
    
    return pd.DataFrame(data)

def show_linker_page():
    """Linker design page using LinkInvent"""
    
    st.markdown('<div class="sub-header">üîó Linker Design</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    Use LinkInvent to design linkers that connect two molecular fragments (warheads).
    </div>
    """, unsafe_allow_html=True)
    
    # Configuration
    with st.expander("‚öôÔ∏è Configuration", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Model Configuration")
            
            model_file = st.text_input(
                "LinkInvent Model File",
                value="priors/linkinvent.prior",
                help="Path to the trained LinkInvent model"
            )
            
            device = st.selectbox("Compute Device", ["cuda:0", "cpu"])
            
            num_linkers = st.number_input(
                "Number of Linkers per Fragment Pair",
                min_value=1,
                max_value=500,
                value=50
            )
        
        with col2:
            st.subheader("Fragment Pairs")
            
            input_method = st.radio(
                "Fragment Input Method:",
                ["Upload File", "Text Input"]
            )
            
            fragment_pairs = []
            
            if input_method == "Upload File":
                uploaded_file = st.file_uploader(
                    "Upload Fragment Pairs File",
                    type=['smi', 'txt', 'csv'],
                    help="File with fragment pairs separated by '|'"
                )
                
                if uploaded_file:
                    content = uploaded_file.read().decode('utf-8')
                    fragment_pairs = [line.strip() for line in content.split('\n') if line.strip()]
            
            else:
                fragments_text = st.text_area(
                    "Enter Fragment Pairs (one per line, separated by |)",
                    placeholder="c1ccccc1|CCO\nc1ccncc1|CC(=O)O\n...",
                    height=150,
                    help="Enter two fragments per line separated by |"
                )
                
                if fragments_text:
                    fragment_pairs = [line.strip() for line in fragments_text.split('\n') if line.strip()]
    
    # Linker constraints
    with st.expander("üîß Linker Constraints"):
        col1, col2 = st.columns(2)
        
        with col1:
            min_linker_length = st.number_input(
                "Minimum Linker Length (atoms)",
                min_value=1,
                max_value=20,
                value=2
            )
            
            max_linker_length = st.number_input(
                "Maximum Linker Length (atoms)",
                min_value=1,
                max_value=20,
                value=8
            )
            
            allow_rings = st.checkbox(
                "Allow Rings in Linker",
                value=True,
                help="Allow cyclic structures in the linker"
            )
        
        with col2:
            linker_complexity = st.selectbox(
                "Linker Complexity",
                ["Simple", "Moderate", "Complex"],
                index=1,
                help="Control the complexity of generated linkers"
            )
            
            temperature = st.slider(
                "Sampling Temperature",
                min_value=0.1,
                max_value=2.0,
                value=1.0,
                step=0.1
            )
            
            output_file = st.text_input(
                "Output File Name",
                value="linker_design_results.csv"
            )
    
    # Property filters
    with st.expander("üìä Property Filters"):
        col1, col2 = st.columns(2)
        
        with col1:
            filter_by_mw = st.checkbox("Filter by Molecular Weight")
            if filter_by_mw:
                mw_range = st.slider(
                    "Molecular Weight Range (Da)",
                    min_value=100,
                    max_value=1000,
                    value=(200, 600),
                    step=10
                )
            
            filter_by_logp = st.checkbox("Filter by LogP")
            if filter_by_logp:
                logp_range = st.slider(
                    "LogP Range",
                    min_value=-5.0,
                    max_value=10.0,
                    value=(0.0, 5.0),
                    step=0.1
                )
        
        with col2:
            filter_by_tpsa = st.checkbox("Filter by TPSA")
            if filter_by_tpsa:
                tpsa_range = st.slider(
                    "TPSA Range (≈≤)",
                    min_value=0,
                    max_value=200,
                    value=(20, 140),
                    step=5
                )
            
            require_drug_like = st.checkbox(
                "Require Drug-like Properties",
                value=False,
                help="Apply Lipinski's Rule of Five"
            )
    
    # Generate button
    if st.button("üöÄ Design Linkers", type="primary"):
        if not fragment_pairs:
            st.error("Please provide at least one fragment pair.")
        else:
            run_linker_design(
                fragment_pairs, model_file, device, num_linkers,
                min_linker_length, max_linker_length, allow_rings,
                linker_complexity, temperature, output_file
            )
    
    # Display results
    if 'linker_results' in st.session_state:
        show_linker_results(st.session_state.linker_results)

def run_linker_design(fragment_pairs, model_file, device, num_linkers,
                     min_length, max_length, allow_rings, complexity,
                     temperature, output_file):
    """Run linker design with LinkInvent"""
    
    try:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("Preparing fragment pairs...")
        progress_bar.progress(0.2)
        
        # Validate fragment pairs format
        valid_pairs = []
        for pair in fragment_pairs:
            if '|' in pair:
                fragments = pair.split('|')
                if len(fragments) == 2:
                    valid_pairs.append((fragments[0].strip(), fragments[1].strip()))
        
        if not valid_pairs:
            st.error("No valid fragment pairs found. Use format: fragment1|fragment2")
            return
        
        # Create temporary fragment file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.smi', delete=False) as f:
            for frag1, frag2 in valid_pairs:
                f.write(f"{frag1}|{frag2}\n")
            fragment_file = f.name
        
        # Create configuration
        config = {
            "run_type": "sampling",
            "device": device,
            "parameters": {
                "model_file": model_file,
                "smiles_file": fragment_file,
                "output_file": output_file,
                "num_smiles": num_linkers,
                "temperature": temperature,
                "min_linker_length": min_length,
                "max_linker_length": max_length,
                "allow_rings": allow_rings,
                "complexity": complexity
            }
        }
        
        status_text.text("Designing linkers...")
        progress_bar.progress(0.7)
        
        # Simulate processing
        import time
        time.sleep(3)
        
        # Generate simulated results
        results_df = simulate_linker_results(valid_pairs, num_linkers)
        
        progress_bar.progress(1.0)
        status_text.text("Linker design complete!")
        
        st.session_state.linker_results = {
            'dataframe': results_df,
            'config': config,
            'output_file': output_file,
            'fragment_pairs': valid_pairs
        }
        
        st.success(f"‚úÖ Successfully designed linkers for {len(valid_pairs)} fragment pairs!")
        
        # Clean up
        os.unlink(fragment_file)
        
    except Exception as e:
        st.error(f"‚ùå Error during linker design: {str(e)}")

def simulate_linker_results(fragment_pairs, num_linkers):
    """Simulate linker design results"""
    
    np.random.seed(42)
    data = []
    
    # Sample linker patterns
    linker_patterns = [
        "C", "CC", "CCC", "CCCC", "C=C", "C#C",
        "c1ccccc1", "CCO", "CCN", "CCS", "c1ccncc1",
        "CCOCC", "CCNCC", "C(=O)", "C(=O)N", "COC"
    ]
    
    for frag1, frag2 in fragment_pairs:
        for i in range(min(num_linkers, 15)):  # Limit for demo
            linker = np.random.choice(linker_patterns)
            
            # Create a simple linked molecule (this is just for demonstration)
            linked_molecule = f"{frag1}-{linker}-{frag2}"
            
            nll = np.random.uniform(-6, -2)
            mw = np.random.uniform(200, 700)
            logp = np.random.uniform(0, 6)
            tpsa = np.random.uniform(20, 150)
            linker_length = len(linker.replace('c', 'C').replace('=', '').replace('#', ''))
            
            data.append({
                'Fragment_1': frag1,
                'Fragment_2': frag2,
                'Linker': linker,
                'Linked_Molecule': linked_molecule,
                'NLL': nll,
                'Molecular_Weight': mw,
                'LogP': logp,
                'TPSA': tpsa,
                'Linker_Length': linker_length,
                'Valid': np.random.choice([True, False], p=[0.8, 0.2])
            })
    
    return pd.DataFrame(data)

def show_linker_results(results):
    """Display linker design results with specific visualizations"""
    
    st.markdown('<div class="sub-header">üìä Linker Design Results</div>', unsafe_allow_html=True)
    
    df = results['dataframe']
    fragment_pairs = results['fragment_pairs']
    
    # Summary statistics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Fragment Pairs", len(fragment_pairs))
    
    with col2:
        st.metric("Total Linkers", len(df))
    
    with col3:
        valid_count = df['Valid'].sum() if 'Valid' in df.columns else len(df)
        st.metric("Valid Linkers", valid_count)
    
    with col4:
        avg_length = df['Linker_Length'].mean() if 'Linker_Length' in df.columns else 0
        st.metric("Avg Linker Length", f"{avg_length:.1f}")
    
    # Results by fragment pair
    st.subheader("Results by Fragment Pair")
    
    if len(fragment_pairs) > 1:
        selected_pair = st.selectbox(
            "Select Fragment Pair:",
            [f"{fp[0]} | {fp[1]}" for fp in fragment_pairs]
        )
        
        # Filter results for selected pair
        pair_parts = selected_pair.split(' | ')
        filtered_df = df[
            (df['Fragment_1'] == pair_parts[0]) & 
            (df['Fragment_2'] == pair_parts[1])
        ]
    else:
        filtered_df = df
    
    st.dataframe(filtered_df, use_container_width=True)
    
    # Visualizations
    if len(df) > 0:
        st.subheader("Linker Analysis")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Linker length distribution
            if 'Linker_Length' in df.columns:
                fig = px.histogram(
                    df, 
                    x='Linker_Length', 
                    title="Linker Length Distribution",
                    nbins=10
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Property scatter plot
            if 'Molecular_Weight' in df.columns and 'LogP' in df.columns:
                fig = px.scatter(
                    df,
                    x='Molecular_Weight',
                    y='LogP',
                    color='Valid' if 'Valid' in df.columns else None,
                    title="Molecular Weight vs LogP",
                    hover_data=['Linker']
                )
                st.plotly_chart(fig, use_container_width=True)
    
    # Download options
    st.subheader("Download Results")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        csv_data = df.to_csv(index=False)
        st.download_button(
            "üìÑ Download CSV",
            csv_data,
            file_name=results['output_file'],
            mime="text/csv"
        )
    
    with col2:
        # Create SDF-like format for linkers
        sdf_data = create_linker_sdf(df)
        st.download_button(
            "üß™ Download SDF",
            sdf_data,
            file_name=results['output_file'].replace('.csv', '.sdf'),
            mime="chemical/x-mdl-sdfile"
        )
    
    with col3:
        config_data = json.dumps(results['config'], indent=2)
        st.download_button(
            "‚öôÔ∏è Download Config",
            config_data,
            file_name="linker_config.json",
            mime="application/json"
        )

def create_linker_sdf(df):
    """Create a simple SDF-like format for linker results"""
    
    sdf_content = ""
    for idx, row in df.iterrows():
        sdf_content += f"""
{row.get('Linked_Molecule', 'Unknown')}
  Generated by REINVENT4 LinkInvent
  
  0  0  0  0  0  0  0  0  0  0999 V2000
M  END
> <Linker>
{row.get('Linker', '')}

> <Fragment_1>
{row.get('Fragment_1', '')}

> <Fragment_2>
{row.get('Fragment_2', '')}

> <Molecular_Weight>
{row.get('Molecular_Weight', '')}

> <LogP>
{row.get('LogP', '')}

$$$$
"""
    
    return sdf_content

def show_rgroup_page():
    """R-Group replacement page using LibInvent"""
    
    st.markdown('<div class="sub-header">‚öóÔ∏è R-Group Replacement</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    Replace specific R-groups in molecules while keeping the core scaffold intact.
    </div>
    """, unsafe_allow_html=True)
    
    # Configuration
    with st.expander("‚öôÔ∏è Configuration", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Model Configuration")
            
            model_file = st.text_input(
                "LibInvent Model File",
                value="priors/libinvent.prior",
                help="Path to the trained LibInvent model"
            )
            
            device = st.selectbox("Compute Device", ["cuda:0", "cpu"])
            
            num_variants = st.number_input(
                "Number of Variants per Molecule",
                min_value=1,
                max_value=200,
                value=30
            )
        
        with col2:
            st.subheader("Input Molecules")
            
            input_method = st.radio(
                "Input Method:",
                ["Upload File", "Text Input", "Draw Structure"]
            )
            
            molecules = []
            
            if input_method == "Upload File":
                uploaded_file = st.file_uploader(
                    "Upload Molecule File",
                    type=['smi', 'sdf', 'txt', 'csv'],
                    help="File containing molecules with R-groups marked"
                )
                
                if uploaded_file:
                    content = uploaded_file.read().decode('utf-8')
                    molecules = [line.strip() for line in content.split('\n') if line.strip()]
            
            elif input_method == "Text Input":
                molecules_text = st.text_area(
                    "Enter Molecules (one per line)",
                    placeholder="c1ccc([*])cc1\nCC([*])C([*])=O\n...",
                    height=150,
                    help="Enter molecules with [*] marking R-group positions"
                )
                
                if molecules_text:
                    molecules = [line.strip() for line in molecules_text.split('\n') if line.strip()]
            
            else:  # Draw Structure
                st.info("Structure drawing functionality would be integrated here using rdkit-js or similar")
                
                # Placeholder for structure drawing
                example_mol = st.selectbox(
                    "Select Example Molecule:",
                    [
                        "c1ccc([*])cc1",  # phenyl with R-group
                        "CC([*])C=O",     # acetyl with R-group
                        "c1ccnc([*])c1",  # pyridyl with R-group
                    ]
                )
                
                if example_mol:
                    molecules = [example_mol]
    
    # R-group constraints
    with st.expander("üß™ R-Group Constraints"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Chemical Constraints")
            
            allowed_elements = st.multiselect(
                "Allowed Elements in R-groups",
                ["C", "N", "O", "S", "F", "Cl", "Br", "I", "P"],
                default=["C", "N", "O", "S", "F", "Cl", "Br"],
                help="Limit elements that can appear in R-groups"
            )
            
            max_rgroup_size = st.number_input(
                "Maximum R-group Size (heavy atoms)",
                min_value=1,
                max_value=20,
                value=8
            )
            
            allow_rings_in_rgroup = st.checkbox(
                "Allow Rings in R-groups",
                value=True
            )
        
        with col2:
            st.subheader("Property Constraints")
            
            lipinski_compliance = st.checkbox(
                "Enforce Lipinski's Rule of Five",
                value=False,
                help="Ensure final molecules are drug-like"
            )
            
            max_rotatable_bonds = st.number_input(
                "Max Rotatable Bonds",
                min_value=0,
                max_value=20,
                value=10
            )
            
            rgroup_polarity = st.selectbox(
                "R-group Polarity Preference",
                ["Any", "Hydrophobic", "Hydrophilic", "Balanced"],
                index=0
            )
    
    # Generate button
    if st.button("üöÄ Generate R-Group Variants", type="primary"):
        if not molecules:
            st.error("Please provide at least one molecule with R-group positions marked.")
        else:
            run_rgroup_replacement(
                molecules, model_file, device, num_variants,
                allowed_elements, max_rgroup_size, allow_rings_in_rgroup,
                lipinski_compliance, output_file="rgroup_replacement_results.csv"
            )
    
    # Display results
    if 'rgroup_results' in st.session_state:
        show_rgroup_results(st.session_state.rgroup_results)

def run_rgroup_replacement(molecules, model_file, device, num_variants,
                          allowed_elements, max_rgroup_size, allow_rings,
                          lipinski_compliance, output_file):
    """Run R-group replacement"""
    
    try:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("Analyzing input molecules...")
        progress_bar.progress(0.2)
        
        # Validate molecules have R-group markers
        valid_molecules = []
        for mol in molecules:
            if '[*]' in mol or 'R' in mol:
                valid_molecules.append(mol)
        
        if not valid_molecules:
            st.error("No molecules with R-group markers ([*] or R) found.")
            return
        
        status_text.text("Generating R-group variants...")
        progress_bar.progress(0.7)
        
        # Simulate processing
        import time
        time.sleep(3)
        
        # Generate simulated results
        results_df = simulate_rgroup_results(valid_molecules, num_variants)
        
        progress_bar.progress(1.0)
        status_text.text("R-group replacement complete!")
        
        st.session_state.rgroup_results = {
            'dataframe': results_df,
            'output_file': output_file,
            'original_molecules': valid_molecules
        }
        
        st.success(f"‚úÖ Successfully generated R-group variants for {len(valid_molecules)} molecules!")
        
    except Exception as e:
        st.error(f"‚ùå Error during R-group replacement: {str(e)}")

def simulate_rgroup_results(molecules, num_variants):
    """Simulate R-group replacement results"""
    
    np.random.seed(42)
    data = []
    
    # Sample R-groups for replacement
    r_groups = [
        "H", "C", "CC", "CCC", "CCCC", "C(C)C", "C(C)(C)C",
        "O", "OC", "OCC", "N", "NC", "NCC", "N(C)C",
        "F", "Cl", "Br", "CF3", "OCF3", "CN", "C=O", "C(=O)C",
        "c1ccccc1", "c1ccncc1", "c1cccnc1"
    ]
    
    for mol in molecules:
        for i in range(min(num_variants, 25)):  # Limit for demo
            # Replace R-group marker with random R-group
            r_group = np.random.choice(r_groups)
            if '[*]' in mol:
                variant = mol.replace('[*]', r_group)
            else:
                variant = mol.replace('R', r_group)
            
            nll = np.random.uniform(-5, -1)
            mw = np.random.uniform(150, 500)
            logp = np.random.uniform(-2, 5)
            tpsa = np.random.uniform(20, 120)
            rotatable_bonds = np.random.randint(0, 15)
            similarity = np.random.uniform(0.5, 0.95)
            
            data.append({
                'Original_Molecule': mol,
                'R_Group': r_group,
                'Generated_Molecule': variant,
                'NLL': nll,
                'Molecular_Weight': mw,
                'LogP': logp,
                'TPSA': tpsa,
                'Rotatable_Bonds': rotatable_bonds,
                'Similarity_to_Original': similarity,
                'Lipinski_Compliant': (mw <= 500 and logp <= 5 and tpsa <= 140),
                'Valid': np.random.choice([True, False], p=[0.85, 0.15])
            })
    
    return pd.DataFrame(data)

def show_rgroup_results(results):
    """Display R-group replacement results"""
    
    st.markdown('<div class="sub-header">üìä R-Group Replacement Results</div>', unsafe_allow_html=True)
    
    df = results['dataframe']
    original_molecules = results['original_molecules']
    
    # Summary statistics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Original Molecules", len(original_molecules))
    
    with col2:
        st.metric("Total Variants", len(df))
    
    with col3:
        valid_count = df['Valid'].sum() if 'Valid' in df.columns else len(df)
        st.metric("Valid Variants", valid_count)
    
    with col4:
        lipinski_count = df['Lipinski_Compliant'].sum() if 'Lipinski_Compliant' in df.columns else 0
        st.metric("Lipinski Compliant", lipinski_count)
    
    # Filter by original molecule
    if len(original_molecules) > 1:
        selected_molecule = st.selectbox(
            "Select Original Molecule:",
            original_molecules
        )
        
        filtered_df = df[df['Original_Molecule'] == selected_molecule]
        st.subheader(f"Variants for: {selected_molecule}")
    else:
        filtered_df = df
        st.subheader("All R-Group Variants")
    
    st.dataframe(filtered_df, use_container_width=True)
    
    # Visualizations
    if len(df) > 0:
        st.subheader("Property Analysis")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Property distribution
            if 'Molecular_Weight' in df.columns:
                fig = px.histogram(
                    df,
                    x='Molecular_Weight',
                    color='Lipinski_Compliant' if 'Lipinski_Compliant' in df.columns else None,
                    title="Molecular Weight Distribution"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Similarity vs LogP
            if 'Similarity_to_Original' in df.columns and 'LogP' in df.columns:
                fig = px.scatter(
                    df,
                    x='Similarity_to_Original',
                    y='LogP',
                    color='Valid' if 'Valid' in df.columns else None,
                    title="Similarity vs LogP",
                    hover_data=['R_Group']
                )
                st.plotly_chart(fig, use_container_width=True)
    
    # Download results
    st.subheader("Download Results")
    
    col1, col2 = st.columns(2)
    
    with col1:
        csv_data = df.to_csv(index=False)
        st.download_button(
            "üìÑ Download CSV",
            csv_data,
            file_name=results['output_file'],
            mime="text/csv"
        )
    
    with col2:
        # Create summary report
        summary_report = create_rgroup_summary(df, original_molecules)
        st.download_button(
            "üìä Download Summary Report",
            summary_report,
            file_name="rgroup_summary.txt",
            mime="text/plain"
        )

def create_rgroup_summary(df, original_molecules):
    """Create a summary report for R-group replacement results"""
    
    report = f"""R-Group Replacement Summary Report
Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

Input Summary:
- Original molecules: {len(original_molecules)}
- Total variants generated: {len(df)}

Quality Metrics:
- Valid molecules: {df['Valid'].sum() if 'Valid' in df.columns else 'N/A'}
- Lipinski compliant: {df['Lipinski_Compliant'].sum() if 'Lipinski_Compliant' in df.columns else 'N/A'}

Property Statistics:
"""
    
    if 'Molecular_Weight' in df.columns:
        report += f"- Molecular Weight: {df['Molecular_Weight'].mean():.1f} ¬± {df['Molecular_Weight'].std():.1f} Da\n"
    
    if 'LogP' in df.columns:
        report += f"- LogP: {df['LogP'].mean():.2f} ¬± {df['LogP'].std():.2f}\n"
    
    if 'TPSA' in df.columns:
        report += f"- TPSA: {df['TPSA'].mean():.1f} ¬± {df['TPSA'].std():.1f} ≈≤\n"
    
    if 'Similarity_to_Original' in df.columns:
        report += f"- Similarity to original: {df['Similarity_to_Original'].mean():.3f} ¬± {df['Similarity_to_Original'].std():.3f}\n"
    
    # Most common R-groups
    if 'R_Group' in df.columns:
        top_rgroups = df['R_Group'].value_counts().head(10)
        report += f"\nMost Common R-Groups:\n"
        for rgroup, count in top_rgroups.items():
            report += f"- {rgroup}: {count} occurrences\n"
    
    return report

def show_optimization_page():
    """Molecule optimization page"""
    
    st.markdown('<div class="sub-header">üìà Molecule Optimization</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    Optimize existing molecules using reinforcement learning and multi-objective scoring functions.
    </div>
    """, unsafe_allow_html=True)
    
    # Configuration interface
    with st.expander("‚öôÔ∏è Configuration", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Input Molecules")
            
            input_method = st.radio(
                "Input Method:",
                ["Text Input", "Upload File", "From Previous Results"]
            )
            
            molecules = []
            
            if input_method == "Text Input":
                molecules_text = st.text_area(
                    "Enter Starting Molecules (one SMILES per line)",
                    placeholder="CCO\nc1ccccc1\nCC(=O)O\n...",
                    height=150,
                    help="Enter SMILES strings for molecules to optimize"
                )
                
                if molecules_text:
                    molecules = [line.strip() for line in molecules_text.split('\n') if line.strip()]
            
            elif input_method == "Upload File":
                uploaded_file = st.file_uploader(
                    "Upload Molecule File",
                    type=['smi', 'csv', 'txt'],
                    help="File containing SMILES strings"
                )
                
                if uploaded_file:
                    content = uploaded_file.read().decode('utf-8')
                    molecules = [line.strip() for line in content.split('\n') if line.strip()]
            
            else:  # From Previous Results
                if 'denovo_results' in st.session_state:
                    df = st.session_state.denovo_results['dataframe']
                    molecules = df['SMILES'].tolist()[:10]  # Take first 10
                    st.success(f"Loaded {len(molecules)} molecules from previous generation")
                else:
                    st.warning("No previous results found. Run generation first.")
        
        with col2:
            st.subheader("Model Configuration")
            
            model_file = st.text_input(
                "Agent Model File",
                value="priors/reinvent.prior",
                help="Path to the agent model for optimization"
            )
            
            optimization_type = st.selectbox(
                "Optimization Type",
                ["Reinforcement Learning", "Transfer Learning", "Curriculum Learning"],
                index=0
            )
            
            num_steps = st.number_input(
                "Number of Optimization Steps",
                min_value=10,
                max_value=10000,
                value=1000,
                step=10
            )
            
            device = st.selectbox("Compute Device", ["cuda:0", "cpu"])
    
    # Scoring function configuration
    with st.expander("üéØ Scoring Function", expanded=True):
        st.subheader("Multi-Component Scoring")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### Primary Objectives")
            
            similarity_weight = st.slider(
                "Similarity to Starting Molecules",
                min_value=0.0,
                max_value=1.0,
                value=0.3,
                step=0.05,
                help="Weight for maintaining similarity to input molecules"
            )
            
            qed_weight = st.slider(
                "QED (Drug-likeness)",
                min_value=0.0,
                max_value=1.0,
                value=0.3,
                step=0.05,
                help="Weight for drug-like properties"
            )
            
            sa_score_weight = st.slider(
                "Synthetic Accessibility",
                min_value=0.0,
                max_value=1.0,
                value=0.2,
                step=0.05,
                help="Weight for synthetic accessibility"
            )
        
        with col2:
            st.markdown("#### Property Constraints")
            
            mw_constraint = st.checkbox("Molecular Weight Constraint")
            if mw_constraint:
                mw_range = st.slider(
                    "Target MW Range (Da)",
                    min_value=100,
                    max_value=800,
                    value=(200, 500),
                    step=10
                )
                mw_weight = st.slider("MW Weight", 0.0, 1.0, 0.1, 0.05)
            
            logp_constraint = st.checkbox("LogP Constraint")
            if logp_constraint:
                logp_range = st.slider(
                    "Target LogP Range",
                    min_value=-3.0,
                    max_value=8.0,
                    value=(1.0, 4.0),
                    step=0.1
                )
                logp_weight = st.slider("LogP Weight", 0.0, 1.0, 0.1, 0.05)
            
            custom_filter = st.checkbox("Custom SMARTS Filter")
            if custom_filter:
                smarts_pattern = st.text_input(
                    "SMARTS Pattern",
                    placeholder="c1ccccc1",
                    help="SMARTS pattern that molecules should match"
                )
                smarts_weight = st.slider("SMARTS Weight", 0.0, 1.0, 0.1, 0.05)
    
    # Advanced optimization settings
    with st.expander("üîß Advanced Settings"):
        col1, col2 = st.columns(2)
        
        with col1:
            learning_rate = st.number_input(
                "Learning Rate",
                min_value=0.0001,
                max_value=0.1,
                value=0.001,
                step=0.0001,
                format="%.4f"
            )
            
            batch_size = st.number_input(
                "Batch Size",
                min_value=1,
                max_value=128,
                value=32
            )
            
            sigma = st.slider(
                "Sigma (Exploration)",
                min_value=1,
                max_value=200,
                value=120,
                help="Controls exploration vs exploitation"
            )
        
        with col2:
            save_frequency = st.number_input(
                "Save Frequency (steps)",
                min_value=10,
                max_value=1000,
                value=100,
                help="How often to save intermediate results"
            )
            
            tb_logdir = st.text_input(
                "TensorBoard Log Directory",
                value="optimization_logs",
                help="Directory for TensorBoard monitoring"
            )
            
            output_file = st.text_input(
                "Output File Name",
                value=f"optimization_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                help="Unique filename with timestamp to avoid conflicts"
            )
            
            # File format selection
            file_format = st.selectbox(
                "Output Format",
                ["CSV", "JSON", "SDF", "Excel"],
                help="Choose the format for saving results"
            )
    
    # Start optimization button
    if st.button("üöÄ Start Optimization", type="primary"):
        if not molecules:
            st.error("Please provide starting molecules for optimization.")
        else:
            run_molecule_optimization(
                molecules, model_file, optimization_type, num_steps,
                device, similarity_weight, qed_weight, sa_score_weight,
                learning_rate, batch_size, sigma, save_frequency,
                tb_logdir, output_file
            )
    
    # Display results
    if 'optimization_results' in st.session_state:
        show_optimization_results(st.session_state.optimization_results)

def run_molecule_optimization(molecules, model_file, optimization_type, num_steps,
                            device, similarity_weight, qed_weight, sa_score_weight,
                            learning_rate, batch_size, sigma, save_frequency,
                            tb_logdir, output_file):
    """Run molecule optimization"""
    
    try:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("Setting up optimization...")
        progress_bar.progress(0.1)
        
        # Create scoring function configuration
        scoring_config = {
            "similarity": {"weight": similarity_weight},
            "qed": {"weight": qed_weight},
            "sa_score": {"weight": sa_score_weight}
        }
        
        # Create optimization configuration
        config = {
            "run_type": "reinforcement_learning" if optimization_type == "Reinforcement Learning" else "transfer_learning",
            "device": device,
            "parameters": {
                "agent_file": model_file,
                "smiles_file": "input_molecules.smi",
                "output_file": output_file,
                "num_steps": num_steps,
                "batch_size": batch_size,
                "learning_rate": learning_rate,
                "sigma": sigma,
                "save_frequency": save_frequency,
                "scoring_function": scoring_config
            }
        }
        
        if tb_logdir:
            config["tb_logdir"] = tb_logdir
        
        status_text.text("Running optimization...")
        progress_bar.progress(0.5)
        
        # Simulate optimization process
        time.sleep(4)
        
        # Generate simulated optimization results
        results_df = simulate_optimization_results(molecules, num_steps)
        
        progress_bar.progress(1.0)
        status_text.text("Optimization complete!")
        
        st.session_state.optimization_results = {
            'dataframe': results_df,
            'config': config,
            'output_file': output_file,
            'starting_molecules': molecules
        }
        
        st.success(f"‚úÖ Optimization completed! Generated {len(results_df)} optimized molecules.")
        
    except Exception as e:
        st.error(f"‚ùå Error during optimization: {str(e)}")

def simulate_optimization_results(starting_molecules, num_steps):
    """Simulate optimization results"""
    
    np.random.seed(42)
    data = []
    
    # Simulate optimization trajectory
    for step in range(0, num_steps, max(1, num_steps//20)):  # 20 data points
        for i, start_mol in enumerate(starting_molecules[:5]):  # Limit for demo
            # Simulate improved properties over time
            improvement_factor = step / num_steps
            
            score = 0.3 + 0.6 * improvement_factor + np.random.normal(0, 0.1)
            score = max(0, min(1, score))  # Clamp to [0,1]
            
            qed = 0.4 + 0.5 * improvement_factor + np.random.normal(0, 0.1)
            qed = max(0, min(1, qed))
            
            similarity = 0.8 - 0.2 * improvement_factor + np.random.normal(0, 0.05)
            similarity = max(0.3, min(1, similarity))
            
            mw = 250 + 150 * np.random.random()
            logp = 1 + 3 * np.random.random()
            
            # Generate a slightly modified SMILES (simplified)
            optimized_smiles = start_mol + "C" if step > 0 else start_mol
            
            data.append({
                'Step': step,
                'Starting_SMILES': start_mol,
                'Optimized_SMILES': optimized_smiles,
                'Total_Score': score,
                'QED': qed,
                'Similarity': similarity,
                'Molecular_Weight': mw,
                'LogP': logp,
                'Valid': np.random.choice([True, False], p=[0.9, 0.1])
            })
    
    return pd.DataFrame(data)

def show_optimization_results(results):
    """Display optimization results"""
    
    st.markdown('<div class="sub-header">üìä Optimization Results</div>', unsafe_allow_html=True)
    
    df = results['dataframe']
    starting_molecules = results['starting_molecules']
    
    # Summary statistics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Starting Molecules", len(starting_molecules))
    
    with col2:
        final_step_df = df[df['Step'] == df['Step'].max()]
        avg_final_score = final_step_df['Total_Score'].mean()
        st.metric("Final Avg Score", f"{avg_final_score:.3f}")
    
    with col3:
        avg_similarity = final_step_df['Similarity'].mean()
        st.metric("Avg Similarity", f"{avg_similarity:.3f}")
    
    with col4:
        avg_qed = final_step_df['QED'].mean()
        st.metric("Avg QED", f"{avg_qed:.3f}")
    
    # Optimization trajectory plot
    st.subheader("Optimization Trajectory")
    
    if len(df) > 0:
        fig = px.line(
            df.groupby('Step')['Total_Score'].mean().reset_index(),
            x='Step',
            y='Total_Score',
            title="Average Score vs Optimization Steps"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Final results table
    st.subheader("Final Optimized Molecules")
    final_results = df[df['Step'] == df['Step'].max()]
    st.dataframe(final_results, use_container_width=True)
    
    # Download results
    st.subheader("Download Results")
    
    col1, col2 = st.columns(2)
    
    with col1:
        csv_data = df.to_csv(index=False)
        st.download_button(
            "üìÑ Download Full Results",
            csv_data,
            file_name=results['output_file'],
            mime="text/csv"
        )
    
    with col2:
        final_csv = final_results.to_csv(index=False)
        st.download_button(
            "üéØ Download Final Results",
            final_csv,
            file_name="final_" + results['output_file'],
            mime="text/csv"
        )

def show_library_page():
    """Library design page"""
    st.markdown('<div class="sub-header">üìö Library Design</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    Design focused molecular libraries using combinatorial enumeration and virtual screening approaches.
    </div>
    """, unsafe_allow_html=True)
    
    # Library design mode selection
    design_mode = st.radio(
        "Library Design Mode:",
        ["Combinatorial Enumeration", "Focused Library", "Diversity Library"],
        help="Choose the type of library to design"
    )
    
    if design_mode == "Combinatorial Enumeration":
        show_combinatorial_library()
    elif design_mode == "Focused Library":
        show_focused_library()
    else:
        show_diversity_library()

def show_combinatorial_library():
    """Combinatorial library enumeration interface"""
    
    st.subheader("üß© Combinatorial Enumeration")
    
    with st.expander("‚öôÔ∏è Configuration", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### Core Scaffold")
            
            scaffold_input = st.text_input(
                "Core Scaffold SMILES",
                placeholder="c1ccc([*:1])cc1[*:2]",
                help="Enter scaffold with numbered attachment points [*:1], [*:2], etc."
            )
            
            st.markdown("#### R-Group Sets")
            
            num_rgroups = st.number_input(
                "Number of R-Group Positions",
                min_value=1,
                max_value=5,
                value=2,
                help="Number of variable positions in the scaffold"
            )
            
            rgroup_sets = {}
            for i in range(num_rgroups):
                rgroup_text = st.text_area(
                    f"R{i+1} Groups (one per line)",
                    placeholder="C\nCC\nCCC\nF\nCl",
                    height=100,
                    key=f"rgroup_{i}"
                )
                if rgroup_text:
                    rgroup_sets[f"R{i+1}"] = [line.strip() for line in rgroup_text.split('\n') if line.strip()]
        
        with col2:
            st.markdown("#### Enumeration Settings")
            
            max_combinations = st.number_input(
                "Maximum Combinations",
                min_value=10,
                max_value=100000,
                value=10000,
                help="Limit the number of combinations to enumerate"
            )
            
            include_duplicates = st.checkbox(
                "Include Duplicate Structures",
                value=False,
                help="Allow duplicate SMILES in the library"
            )
            
            filter_by_properties = st.checkbox(
                "Apply Property Filters",
                value=True,
                help="Filter generated molecules by drug-like properties"
            )
            
            if filter_by_properties:
                st.markdown("##### Property Ranges")
                mw_range = st.slider("Molecular Weight", 100, 800, (150, 500))
                logp_range = st.slider("LogP", -3.0, 8.0, (-1.0, 5.0))
                hbd_max = st.number_input("Max H-Bond Donors", 0, 20, 5)
                hba_max = st.number_input("Max H-Bond Acceptors", 0, 20, 10)
    
    if st.button("üöÄ Enumerate Library", type="primary"):
        if scaffold_input and rgroup_sets:
            enumerate_combinatorial_library(
                scaffold_input, rgroup_sets, max_combinations,
                include_duplicates, filter_by_properties
            )
        else:
            st.error("Please provide a scaffold and at least one R-group set.")
    
    if 'library_results' in st.session_state:
        show_library_results(st.session_state.library_results)

def show_focused_library():
    """Focused library design interface"""
    
    st.subheader("üéØ Focused Library Design")
    
    with st.expander("‚öôÔ∏è Configuration", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### Target Definition")
            
            target_type = st.selectbox(
                "Target Type",
                ["Protein Target", "Property Profile", "Reference Compounds"],
                help="Type of focus for the library"
            )
            
            if target_type == "Protein Target":
                protein_name = st.text_input("Protein Name/ID", placeholder="e.g., CDK2, P53")
                pocket_residues = st.text_area(
                    "Key Binding Site Residues",
                    placeholder="ARG123, ASP145, PHE167",
                    help="Important residues for binding"
                )
            
            elif target_type == "Property Profile":
                target_mw = st.number_input("Target Molecular Weight", 100, 800, 300)
                target_logp = st.number_input("Target LogP", -3.0, 8.0, 2.5)
                target_tpsa = st.number_input("Target TPSA", 0, 200, 60)
            
            else:  # Reference Compounds
                reference_smiles = st.text_area(
                    "Reference Compounds (one per line)",
                    placeholder="CCO\nc1ccccc1\nCC(=O)O",
                    help="Known active compounds to base the library on"
                )
        
        with col2:
            st.markdown("#### Library Parameters")
            
            library_size = st.number_input(
                "Target Library Size",
                min_value=100,
                max_value=50000,
                value=5000
            )
            
            diversity_threshold = st.slider(
                "Diversity Threshold",
                min_value=0.0,
                max_value=1.0,
                value=0.7,
                help="Minimum Tanimoto similarity for inclusion"
            )
def show_config_page():
    """Configuration manager page"""t.checkbox(
    st.markdown('<div class="sub-header">‚öôÔ∏è Configuration Manager</div>', unsafe_allow_html=True)sosteres",
    
    st.markdown("""acements"
    <div class="info-box">   )
    Save, load, and manage REINVENT configuration templates for different tasks and workflows.    
    </div>
    """, unsafe_allow_html=True)        "Fragment-Based Assembly",
    e,
    # Configuration management tabsions"
    tab1, tab2, tab3, tab4 = st.tabs([            )
        "üìù Create Configuration", 
        "üìÇ Load Configuration", rary", type="primary"):
        "üìã Templates",     design_focused_library(
        "üîÑ Batch Processing"e, library_size, diversity_threshold,
    ])nclude_bioisosteres, fragment_based
        )
    with tab1:
        show_config_creator()
    
    with tab2:
        show_config_loader()
    sity library design interface"""
    with tab3:
        show_config_templates()
    
    with tab4:
        show_batch_processing()

def show_config_creator():
    """Configuration creation interface"""
    st.subheader("üìù Create New Configuration")
    
    # Basic settings
    with st.expander("üéØ Basic Settings", expanded=True):    ["MaxMin Algorithm", "Sphere Exclusion", "Cluster-Based", "Random Sampling"],
        col1, col2 = st.columns(2)s"
        
        with col1:
            config_name = st.text_input(t = st.selectbox(
                "Configuration Name",scriptors",
                placeholder="My REINVENT Config", Descriptors", "3D Pharmacophore"],
                help="Descriptive name for this configuration"diversity"
            )
            
            run_type = st.selectbox(
                "Run Type",,
                [bset", "Generated Compounds", "Upload File"]
                    "sampling",
                    "reinforcement_learning", 
                    "transfer_learning",        if starting_set == "Database Subset":
                    "library_design",.selectbox(
                    "scoring"                    "Chemical Database",
                ]"PubChem", "Custom Database"]
            )
                        
            device = st.selectbox("Device", ["cuda:0", "cpu"])
                        "Filter Criteria",
        with col2:er="MW: 150-500\nLogP: -1 to 5\nRotBonds: < 10",
            description = st.text_area(ng"
                "Description",            )
                placeholder="Describe the purpose of this configuration...",
                height=100
            )        st.markdown("#### Library Parameters")
            
            author = st.text_input("Author", value="User")
                        "Target Library Size",
            version = st.text_input("Version", value="1.0")  min_value=50,
    
    # Run-specific parameters
    st.subheader("üîß Run-Specific Parameters")
            
    if run_type == "sampling":n_distance = st.slider(
        show_sampling_config()
    elif run_type == "reinforcement_learning":
        show_rl_config_creator()            max_value=1.0,
    elif run_type == "transfer_learning":  value=0.5,
        show_tl_config_creator()ance between compounds"
    elif run_type == "library_design":
        show_library_config_creator()        
    elif run_type == "scoring":xt_area(
        show_scoring_config_creator(),
                placeholder="CCO\nc1ccccc1",
    # Save configurationp="Starting compounds to ensure inclusion"
    st.subheader("üíæ Save Configuration")
    
    col1, col2 = st.columns(2)eactive = st.checkbox(
    ctive Groups",
    with col1:
        save_location = st.selectbox(       help="Filter out compounds with reactive functional groups"
            "Save Location",
            ["Local Templates", "Project Folder", "Custom Path"]        
        )er = st.checkbox(
        
        if save_location == "Custom Path":
            custom_path = st.text_input("Custom Path", value="./configs/")
            )
    with col2:
        file_format = st.selectbox("File Format", ["TOML", "JSON", "YAML"])ity Library", type="primary"):
            generate_diversity_library(
        include_metadata = st.checkbox(descriptor_set, target_size,
            "Include Metadata",        min_distance, exclude_reactive, lipinski_filter
            value=True,
            help="Include creation date, author, and description"
        )esults' in st.session_state:
    _state.diversity_library_results)
    if st.button("üíæ Save Configuration", type="primary"):
        if config_name: rgroup_sets, max_combinations, 
            save_configuration(        include_duplicates, filter_by_properties):
                config_name, run_type, description, author, umerate combinatorial library"""
                version, save_location, file_format, include_metadata
            )
        else:
            st.error("Please provide a configuration name")pty()

def show_sampling_config():xt("Enumerating combinations...")
    """Sampling configuration parameters"""
    with st.expander("‚öôÔ∏è Sampling Parameters"):
        col1, col2 = st.columns(2) Simulate enumeration
                time.sleep(2)
        with col1:
            model_path = st.text_input("Model Path", value="priors/reinvent.prior")library
            num_smiles = st.number_input("Number of SMILES", 1, 10000, 1000)s)
            batch_size = st.number_input("Batch Size", 1, 500, 100)    
        r.progress(1.0)
        with col2:Library enumeration complete!")
            temperature = st.slider("Temperature", 0.1, 2.0, 1.0, 0.1)
            unique_molecules = st.checkbox("Unique Molecules", value=True).session_state.library_results = {
            randomize = st.checkbox("Randomize", value=True)_df,
        'library_type': 'Combinatorial',
def show_rl_config_creator():
    """RL configuration parameters"""rgroup_sets
    with st.expander("‚öôÔ∏è RL Parameters"):
        col1, col2 = st.columns(2)
        ary with {len(library_df)} compounds!")
        with col1:   
            agent_path = st.text_input("Agent Model", value="priors/reinvent.prior")except Exception as e:
            prior_path = st.text_input("Prior Model", value="priors/reinvent.prior")r(e)}")
            num_steps = st.number_input("RL Steps", 100, 50000, 5000)
        d, rgroup_sets, max_combinations):
        with col2:library enumeration"""
            batch_size = st.number_input("Batch Size", 10, 500, 128)
            learning_rate = st.number_input("Learning Rate", 0.00001, 0.01, 0.0001, format="%.5f")
            kl_sigma = st.slider("KL Sigma", 1, 200, 60)    data = []

def show_tl_config_creator():
    """Transfer learning configuration parameters"""num_combinations = min(max_combinations, 1000)  # Limit for demo
    with st.expander("‚öôÔ∏è Transfer Learning Parameters"):
        col1, col2 = st.columns(2)for i in range(num_combinations):
        
        with col1:
            input_model = st.text_input("Input Model", value="priors/reinvent.prior")rgroups_used = {}
            output_model = st.text_input("Output Model", value="models/transfer_model")
            training_data = st.text_input("Training Data", placeholder="path/to/training.smi")enumerate(rgroup_sets.items()):
        if rgroup_list:
        with col2:.choice(rgroup_list)
            num_epochs = st.number_input("Epochs", 1, 1000, 100)e] = selected_rgroup
            batch_size = st.number_input("Batch Size", 1, 200, 64)tation would be more sophisticated)
            learning_rate = st.number_input("Learning Rate", 0.00001, 0.1, 0.001, format="%.5f")

def show_library_config_creator():nerate properties
    """Library design configuration parameters"""
    with st.expander("‚öôÔ∏è Library Design Parameters"): = np.random.uniform(-1, 6)
        col1, col2 = st.columns(2)
        
        with col1:int(0, 12)
            design_type = st.selectbox("Design Type", ["combinatorial", "focused", "diversity"])
            reactions = st.text_area("Reaction SMARTS", placeholder="[C:1]>>N[C:1]")
            building_blocks = st.text_area("Building Blocks", placeholder="File paths or SMILES")
        SMILES': smiles,
        with col2:'Molecular_Weight': mw,
            max_products = st.number_input("Max Products", 100, 1000000, 10000)
            filter_duplicates = st.checkbox("Filter Duplicates", value=True)
            apply_filters = st.checkbox("Apply Drug-like Filters", value=True)

def show_scoring_config_creator():p <= 5 and hbd <= 5 and hba <= 10 and tpsa <= 140),
    """Scoring configuration parameters"""
    with st.expander("‚öôÔ∏è Scoring Parameters"):
        input_file = st.text_input("Input File", placeholder="molecules.smi")
        
        # Scoring components
        st.markdown("**Scoring Components:**")gn_focused_library(target_type, library_size, diversity_threshold,
                include_bioisosteres, fragment_based):
        use_qed = st.checkbox("QED (Drug-likeness)", value=True)
        if use_qed:
            qed_weight = st.slider("QED Weight", 0.0, 1.0, 1.0, 0.1)
        
        use_similarity = st.checkbox("Similarity Scoring")y()
        if use_similarity:
            reference_smiles = st.text_input("Reference SMILES")signing focused library...")
            similarity_weight = st.slider("Similarity Weight", 0.0, 1.0, 1.0, 0.1)

def show_config_loader():.sleep(3)
    """Configuration loading interface"""
    st.subheader("üìÇ Load Existing Configuration")
    e_focused_library(library_size, target_type)
    # File upload
    uploaded_config = st.file_uploader(ess_bar.progress(1.0)
        "Upload Configuration File",us_text.text("Focused library design complete!")
        type=['toml', 'json', 'yaml'],
        help="Load a previously saved REINVENT configuration"results = {
    )brary_df,
    
    if uploaded_config is not None:target_type': target_type
        try:
            # Parse configuration based on file type
            if uploaded_config.name.endswith('.json'):h {len(library_df)} compounds!")
                config_data = json.load(uploaded_config)
            elif uploaded_config.name.endswith('.toml'):
                import toml
                config_data = toml.load(uploaded_config)
            else:simulate_focused_library(library_size, target_type):
                st.error("Unsupported file format")
                return
            
            st.session_state.loaded_config = config_data
            st.success(f"‚úÖ Configuration loaded: {uploaded_config.name}")
            e focused compounds
            # Display configurationrange(min(library_size, 1000)):  # Limit for demo
            show_config_preview(config_data)
                base_smiles = ["CCO", "c1ccccc1", "CCN", "c1ccncc1", "CC(=O)O"]
        except Exception as e:)
            st.error(f"Error loading configuration: {str(e)}")
            # Properties biased towards target
    # Quick load from templatesProtein Target":
    st.subheader("üìã Quick Load from Templates")
            logp = np.random.normal(2.5, 0.8)
    template_configs = get_template_configurations()9)  # Higher scores for protein targets
        else:
    if template_configs:
        selected_template = st.selectbox(rm(1, 4)
            "Select Template",    score = np.random.uniform(0.4, 0.8)
            ["None"] + list(template_configs.keys())
        )
        larity = np.random.uniform(0.7, 0.95)  # High similarity in focused library
        if selected_template != "None":
            if st.button(f"Load {selected_template}"):
                st.session_state.loaded_config = template_configs[selected_template]
                st.success(f"Template loaded: {selected_template}")
                show_config_preview(template_configs[selected_template])Molecular_Weight': max(150, mw),
'LogP': logp,
def show_config_preview(config_data):
    """Display configuration preview"""
    st.subheader("üîç Configuration Preview")
    ce([True, False], p=[0.85, 0.15])
    # Basic info
    col1, col2, col3 = st.columns(3)
    aFrame(data)
    with col1:
        st.metric("Run Type", config_data.get('run_type', 'Unknown'))scriptor_set, target_size,
    
    with col2:
        st.metric("Device", config_data.get('device', 'Unknown'))
    
    with col3:
        if 'metadata' in config_data:
            st.metric("Version", config_data['metadata'].get('version', 'Unknown'))
    sing {diversity_method}...")
    # Full configuration
    with st.expander("üìÑ Full Configuration"):
        st.json(config_data)time.sleep(3)
    
    # Actions
    col1, col2, col3 = st.columns(3)ary_df = simulate_diversity_library(target_size, diversity_method)
    
    with col1:
        if st.button("‚ñ∂Ô∏è Run Configuration"):rsity library generation complete!")
            run_configuration(config_data)
    iversity_library_results = {
    with col2:dataframe': library_df,
        if st.button("‚úèÔ∏è Edit Configuration"):'library_type': 'Diversity',
            st.session_state.edit_config = config_data
            st.info("Configuration loaded for editing")
    
    with col3:ed diversity library with {len(library_df)} compounds!")
        if st.button("üíæ Save as Template"):
            save_as_template(config_data)
ror(f"‚ùå Error during diversity library generation: {str(e)}")
def show_config_templates():
    """Configuration templates management"""hod):
    st.subheader("üìã Configuration Templates")ation"""
    
    # Template categories
    template_categories = {
        "üß™ Basic Sampling": [
            {
                "name": "Simple Sampling",
                "description": "Basic molecular generation from prior",CCN(CC)CC", "c1ccncc1", "CC(=O)O",
                "run_type": "sampling",
                "parameters": {"num_smiles": 1000, "batch_size": 100}c(F)cc1", "CCNC", "c1cccnc1", "CCC(=O)N"
            },]
            {
                "name": "High Diversity Sampling", ize, 1000)):  # Limit for demo
                "description": "Generate diverse molecules with high temperature",
                "run_type": "sampling",
                "parameters": {"num_smiles": 5000, "temperature": 1.5} Properties spread across chemical space
            }    mw = np.random.uniform(150, 650)
        ],
        "üéØ Reinforcement Learning": [
            {        
                "name": "Drug-like Optimization",ed on method
                "description": "Optimize for drug-like properties using QED",
                "run_type": "reinforcement_learning",        diversity_score = np.random.uniform(0.3, 0.9)
                "parameters": {"num_steps": 5000, "scoring": "qed"}
            },        diversity_score = np.random.uniform(0.4, 0.8)
            {
                "name": "Multi-objective Optimization",andom.uniform(0.2, 0.7)
                "description": "Balance multiple objectives with constraints",
                "run_type": "reinforcement_learning", d({
                "parameters": {"num_steps": 10000, "scoring": "multi"}
            }'SMILES': smiles,
        ],
        "üìö Transfer Learning": [
            {
                "name": "Fine-tune on ChEMBL",
                "description": "Fine-tune model on ChEMBL data",Cluster_ID': np.random.randint(1, 20),
                "run_type": "transfer_learning",'Lipinski_Compliant': np.random.choice([True, False], p=[0.7, 0.3])
                "parameters": {"epochs": 100, "learning_rate": 0.001}
            }
        ],
        "üî¨ Library Design": [
            {ary_results(results):
                "name": "Combinatorial Library",ay library design results"""
                "description": "Generate combinatorial chemical library",
                "run_type": "library_design",">üìä {results["library_type"]} Library Results</div>', unsafe_allow_html=True)
                "parameters": {"design_type": "combinatorial"}
            }lts['dataframe']
        ]
    }
    4)
    for category, templates in template_categories.items():
        with st.expander(category, expanded=True):
            for template in templates:("Total Compounds", len(df))
                col1, col2, col3 = st.columns([3, 2, 1])
                
                with col1:Compliant'].sum() if 'Lipinski_Compliant' in df.columns else 0
                    st.markdown(f"**{template['name']}**")
                    st.caption(template['description'])
                
                with col2:if 'Molecular_Weight' in df.columns:
                    st.code(f"Type: {template['run_type']}") = df['Molecular_Weight'].mean()
                vg_mw:.1f} Da")
                with col3:
                    if st.button("Use", key=f"use_{template['name']}"):
                        st.session_state.selected_template = template
                        st.success(f"Template '{template['name']}' selected!")gP'].mean()
, f"{avg_logp:.2f}")
def show_batch_processing():
    """Batch processing interface""" library data
    st.subheader("üîÑ Batch Processing")ader("Library Compounds")
    dth=True)
    st.markdown("""
    Run multiple configurations in sequence or parallel for systematic experiments.ots
    """)
    erty Distributions")
    # Batch configuration
    with st.expander("‚öôÔ∏è Batch Settings", expanded=True): col2 = st.columns(2)
        col1, col2 = st.columns(2)
        
        with col1:mns:
            batch_name = st.text_input(lecular_Weight', title="Molecular Weight Distribution")
                "Batch Name",)
                placeholder="Systematic Study 2024",
                help="Name for this batch of experiments" col2:
            )
            LogP', title="LogP Distribution")
            execution_mode = st.selectbox(hart(fig, use_container_width=True)
                "Execution Mode",
                ["Sequential", "Parallel (Limited)", "Queue"]itional plots for specific library types
            )esults['library_type'] == 'Diversity' and 'Diversity_Score' in df.columns:
        lar_Weight', y='LogP', 
        with col2:ity_Score', title="Chemical Space Coverage")
            max_parallel = st.number_input((fig, use_container_width=True)
                "Max Parallel Jobs",
                min_value=1,d options
                max_value=10,st.subheader("Download Library")
                value=2,
                help="Maximum number of parallel experiments")
            )
            
            auto_save_results = st.checkbox(sv_data = df.to_csv(index=False)
                "Auto-save Results",    st.download_button(
                value=True,
                help="Automatically save results from each run"
            )            file_name=f"{results['library_type'].lower()}_library.csv",
    
    # Configuration queue
    st.subheader("üìã Configuration Queue")
    with col2:
    if 'batch_queue' not in st.session_state:smi_data = "\n".join([f"{row['SMILES']}\t{row['Compound_ID']}" for _, row in df.iterrows()])
        st.session_state.batch_queue = []
    
    # Add configurations to queue    smi_data,
    col1, col2 = st.columns(2))}_library.smi",
    
    with col1:)
        st.markdown("**Add Configurations:**")
        
        # Upload multiple configs# Summary report
        uploaded_configs = st.file_uploader(Report
            "Upload Configuration Files",
            type=['toml', 'json'],mpounds: {len(df)}
            accept_multiple_files=TrueCompliant'].sum() if 'Lipinski_Compliant' in df.columns else 'N/A'}
        )
        : {df['LogP'].mean():.2f}
        if uploaded_configs:%m-%d %H:%M:%S')}
            if st.button("Add to Queue"):
                for config_file in uploaded_configs:
                    try:
                        if config_file.name.endswith('.json'):
                            config_data = json.load(config_file)   file_name=f"{results['library_type'].lower()}_report.txt",
                        else:    mime="text/plain"
                            import toml
                            config_data = toml.load(config_file)
                        
                        st.session_state.batch_queue.append({
                            'name': config_file.name,    st.markdown('<div class="sub-header">üéØ Scoring Functions</div>', unsafe_allow_html=True)
                            'config': config_data,
                            'status': 'Queued'
                        })<div class="info-box">
                    except Exception as e:e multi-component scoring functions for molecular optimization and evaluation.
                        st.error(f"Error loading {config_file.name}: {e}")
                """, unsafe_allow_html=True)
                st.success(f"Added {len(uploaded_configs)} configurations to queue")
    
    with col2:with st.expander("üîß Scoring Function Builder", expanded=True):
        st.markdown("**Queue Status:**")nents")
        
        if st.session_state.batch_queue:tion
            queue_df = pd.DataFrame([olumns(2)
                {
                    'Name': item['name'],
                    'Type': item['config'].get('run_type', 'Unknown'),## Property Components")
                    'Status': item['status']
                }
                for item in st.session_state.batch_queue
            ])
                    qed_weight = st.slider("QED Weight", 0.0, 1.0, 0.3, 0.05)
            st.dataframe(queue_df, use_container_width=True) = st.selectbox("QED Transform", ["linear", "sigmoid", "reverse_sigmoid"], key="qed_transform")
        else:
            st.info("No configurations in queue")
    ynthetic Accessibility", value=True)
    # Batch execution
    if st.session_state.batch_queue:"SA Score Weight", 0.0, 1.0, 0.2, 0.05)
        st.subheader("üöÄ Execute Batch")        sa_transform = st.selectbox("SA Transform", ["linear", "sigmoid", "reverse_sigmoid"], key="sa_transform")
        
        col1, col2, col3 = st.columns(3)
        .checkbox("Lipinski Rule of Five", value=False)
        with col1:
            if st.button("‚ñ∂Ô∏è Start Batch", type="primary"):weight = st.slider("Lipinski Weight", 0.0, 1.0, 0.1, 0.05)
                execute_batch(st.session_state.batch_queue, execution_mode)
        operty
        with col2:property = st.checkbox("Custom Property")
            if st.button("‚è∏Ô∏è Pause Batch"):
                st.info("Batch execution paused")perty = st.selectbox(
                  "Property Type",
        with col3:                ["Molecular Weight", "LogP", "TPSA", "Rotatable Bonds", "Aromatic Rings"]
            if st.button("üóëÔ∏è Clear Queue"):
                st.session_state.batch_queue = []                custom_target = st.number_input(f"Target {custom_property}", value=300.0)
                st.success("Queue cleared")erance", value=50.0)
ight", 0.0, 1.0, 0.1, 0.05)
def get_template_configurations():
    """Get available template configurations"""    with col2:
    return {    st.markdown("#### Similarity Components")
        "Basic Sampling": {
            "run_type": "sampling",rence
            "device": "cuda:0",    use_similarity = st.checkbox("Similarity to Reference", value=False)
            "parameters": {
                "model_file": "priors/reinvent.prior", st.text_area(
                "num_smiles": 1000,            "Reference SMILES (one per line)",
                "batch_size": 100,laceholder="CCO\nc1ccccc1\nCC(=O)O",
                "temperature": 1.0            height=100
            }
        },1.0, 0.3, 0.05)
        "RL Optimization": {        similarity_method = st.selectbox("Similarity Method", ["Tanimoto", "Dice", "Cosine"])
            "run_type": "reinforcement_learning", 
            "device": "cuda:0",
            "parameters": {    use_substructure = st.checkbox("Substructure Match")
                "agent_file": "priors/reinvent.prior",
                "prior_file": "priors/reinvent.prior",= st.text_input(
                "num_steps": 5000,
                "batch_size": 128,cc1",
                "learning_rate": 0.0001           help="SMARTS pattern for substructure matching"
            }        )
        },, 0.05)
        "Transfer Learning": {        substructure_mode = st.selectbox("Match Mode", ["Must Match", "Must Not Match"])
            "run_type": "transfer_learning",
            "device": "cuda:0",
            "parameters": {            use_rocs = st.checkbox("ROCS 3D Similarity", value=False)
                "input_model_file": "priors/reinvent.prior",
                "output_model_file": "models/transfer_model.prior",input("Reference Molecule for ROCS")
                "num_epochs": 100,            rocs_weight = st.slider("ROCS Weight", 0.0, 1.0, 0.2, 0.05)
                "batch_size": 64,
                "learning_rate": 0.001t.markdown("#### Predictive Models")
            }        
        },
        "Library Design": {")
            "run_type": "library_design",
            "device": "cuda:0",ity Prediction", "ADMET", "Custom"])
            "parameters": {del File Path", placeholder="models/activity_model.pkl")
                "design_type": "combinatorial",        ml_weight = st.slider("ML Model Weight", 0.0, 1.0, 0.4, 0.05)
                "num_products": 10000,
                "filter_duplicates": True
            }tion", expanded=True):
        }
    }
col1:
def save_configuration(name, run_type, description, author, version, 
                      save_location, file_format, include_metadata):
    """Save configuration to file"""
    try:        "Score Aggregation",
        config = {d Product", "Pareto Ranking", "Custom"],
            "run_type": run_type,
            "device": "cuda:0",    )
            "parameters": {}  # Would be populated based on form inputs
        }":
        ormula = st.text_area(
        if include_metadata:
            config["metadata"] = {holder="(qed * 0.3 + sa_score * 0.2) * similarity",
                "name": name,"Custom aggregation formula using component names"
                "description": description,
                "author": author,
                "version": version,
                "created": datetime.now().isoformat()      "Normalize Component Scores",
            }            value=True,
        ze all component scores to [0,1] range"
        # Simulate saving            )
        filename = f"{name.replace(' ', '_').lower()}.{file_format.lower()}"
        
        if file_format == "JSON":olds")
            config_str = json.dumps(config, indent=2)        
        elif file_format == "TOML":    min_score_threshold = st.slider(
            config_str = f"# {name} Configuration\n[parameters]\n# Add parameters here"old",
        else:  # YAML
            config_str = f"# {name} Configuration\nrun_type: {run_type}"        max_value=1.0,
        
        st.download_button(e for molecule acceptance"
            f"üíæ Download {filename}",    )
            config_str,
            file_name=filename,    diversity_filter = st.checkbox(
            mime="application/json" if file_format == "JSON" else "text/plain"
        )
                help="Remove similar high-scoring molecules"
        st.success(f"‚úÖ Configuration '{name}' saved as {filename}")
        
    except Exception as e:    if diversity_filter:
        st.error(f"Error saving configuration: {str(e)}")
hold",
def run_configuration(config_data):
    """Run a configuration"""
    try:           value=0.7,
        run_type = config_data.get('run_type', 'unknown')            help="Minimum Tanimoto distance for diversity"
        
        st.info(f"üöÄ Starting {run_type} run...")
        n
        # Simulate run
        progress_bar = st.progress(0)        st.subheader("Test with Sample Molecules")
        for i in range(100):
            progress_bar.progress((i + 1) / 100)
            time.sleep(0.02)        "Test SMILES (one per line)",
        r="CCO\nc1ccccc1\nCC(=O)O\nCCN(CC)CC\nc1ccncc1",
        st.success(f"‚úÖ {run_type.title()} run completed successfully!")eight=120,
                help="Enter SMILES to test the scoring function"
    except Exception as e:
        st.error(f"Error running configuration: {str(e)}")
"):
def save_as_template(config_data):
    """Save configuration as template""" test_molecules.split('\n') if line.strip()]
    template_name = st.text_input("Template Name", placeholder="My Custom Template")           test_scoring_function(molecules)
            else:
    if template_name and st.button("Save Template"):
        # In real implementation, would save to templates directory
        st.success(f"‚úÖ Template '{template_name}' saved!")ve/Load configurations
):
def execute_batch(queue, execution_mode):
    """Execute batch of configurations"""
    try:
        st.info(f"üöÄ Starting batch execution in {execution_mode} mode...")    st.markdown("#### Save Configuration")
        Configuration Name", placeholder="my_scoring_function")
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, item in enumerate(queue):
            status_text.text(f"Processing {item['name']}...")   else:
            item['status'] = 'Running'ion name.")
            
            # Simulate processing
            time.sleep(1)tion")
            
            item['status'] = 'Completed'ions
            progress_bar.progress((i + 1) / len(queue)) = ["default_drug_like", "similarity_focused", "diversity_optimized", "custom_qsar"]
        ig = st.selectbox("Saved Configurations", saved_configs)
        st.success("‚úÖ Batch execution completed!")
        
    except Exception as e:
        st.error(f"Error during batch execution: {str(e)}")
# Display current scoring function
def show_file_manager_page():.session_state:
    """File manager page for organizing and downloading saved files"""        show_scoring_summary()
    st.markdown('<div class="sub-header">üìÅ File Manager</div>', unsafe_allow_html=True)
    
    st.markdown(""""""Test the configured scoring function on sample molecules"""
    <div class="info-box">
    Manage, organize, and download all your REINVENT4 results and configuration files.try:
    </div>gress(0)
    """, unsafe_allow_html=True)    status_text = st.empty()
    
    # Initialize file system structurees...")
    if 'file_system' not in st.session_state:    progress_bar.progress(0.5)
        st.session_state.file_system = initialize_file_system()
    
    # File management tabs    time.sleep(2)
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìÇ Browse Files", 
        "üíæ Recent Downloads", )
        "üìä Storage Analytics",     
        "üîß File Operations"ss_bar.progress(1.0)
    ]))
    
    with tab1:
        show_file_browser()    
    cess(f"‚úÖ Scored {len(molecules)} molecules!")
    with tab2:
        show_recent_downloads()
    
    with tab3:    
        show_storage_analytics()
    ring: {str(e)}")
    with tab4:
        show_file_operations()simulate_scoring_results(molecules):
results"""
def initialize_file_system():
    """Initialize the file system structure"""
    return { = []
        'results': {
            'denovo_generation': [],i, smiles in enumerate(molecules):
            'optimization': [], component scores
            'library_design': [],
            'reinforcement_learning': [],
            'transfer_learning': [],
            'scoring': []lipinski_score = np.random.choice([0, 1], p=[0.3, 0.7])
        },
        'configurations': {ghted sum)
            'templates': [],
            'custom': [],* 0.2)
            'batch_configs': []
        },
        'exports': {
            'csv_files': [],
            'sdf_files': [],
            'json_files': [],
            'reports': []    data.append({
        },smiles,
        'models': {re,
            'trained_models': [],        'QED_Score': qed_score,
            'checkpoints': [],
            'prior_models': []        'Similarity_Score': similarity_score,
        }ipinski_Score': lipinski_score,
    }

def show_file_browser():
    """Display file browser interface""" + 1
    st.subheader("üìÇ File Browser")
    
    # Directory navigationpd.DataFrame(data)
    col1, col2 = st.columns([1, 3])# Sort by total score descending
    rt_values('Total_Score', ascending=False).reset_index(drop=True)
    with col1:
        st.markdown("**üìÅ Directories**")
        
        # Directory tree
        directories = {
            "üß™ Results": "results",esults"""
            "‚öôÔ∏è Configurations": "configurations", 
            "üì§ Exports": "exports",st.markdown('<div class="sub-header">üìä Scoring Results</div>', unsafe_allow_html=True)
            "ü§ñ Models": "models"
        }
        
        selected_dir = st.radio(
            "Select Directory:",
            list(directories.keys()),
            key="file_browser_dir"
        )
        
        dir_key = directories[selected_dir]     st.metric("Average Score", f"{avg_score:.3f}")
    
    with col2:
        st.markdown(f"**üìÇ {selected_dir}**")= df['Total_Score'].max()
        
        # Show subdirectories and files
        if dir_key in st.session_state.file_system:col4:
            subdirs = st.session_state.file_system[dir_key]        passing_threshold = (df['Total_Score'] >= 0.5).sum()
             Threshold", f"{passing_threshold}/{len(df)}")
            if isinstance(subdirs, dict):
                # Show subdirectories
                for subdir_name, files in subdirs.items():st.subheader("Detailed Results")
                    with st.expander(f"üìÅ {subdir_name.replace('_', ' ').title()}", expanded=False):, use_container_width=True)
                        if files:
                            display_files(files, dir_key, subdir_name)
                        else:col2 = st.columns(2)
                            st.info("No files in this directory")
            else:with col1:
                # Show files directly x='Total_Score', title="Total Score Distribution")
                if subdirs:
                    display_files(subdirs, dir_key)
                else: col2:
                    st.info("No files in this directory")parison
     'SA_Score', 'Similarity_Score']
    # Quick actionsscore_data = df[score_cols].melt()
    st.subheader("‚ö° Quick Actions")ox(score_data, x='variable', y='value', title="Component Score Distributions")
    ue)
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("üìä View All Results"):
            show_all_results_summary()
    
    with col2:1:
        if st.button("üóÇÔ∏è Export All Data"):ex=False)
            create_bulk_export()
    ults CSV",
    with col3:
        if st.button("üßπ Clean Up Files"):
            show_cleanup_options()mime="text/csv"
    
    with col4:
        if st.button("üìà Generate Report"):
            generate_usage_report()
molecules = df.head(10)
def display_files(files, directory, subdirectory=None):es.to_csv(index=False)
    """Display files in a directory with download options"""
    
    if not files:
        st.info("No files available")olecules.csv",
        return
    
    # Create file list with metadata
    file_data = []
    for i, file_info in enumerate(files):
        if isinstance(file_info, dict):
            file_data.append({ing configuration
                'Name': file_info.get('name', f'File_{i}'),
                'Type': file_info.get('type', 'Unknown'),e': config_name,
                'Size': file_info.get('size', 'Unknown'),re', 'Similarity'],
                'Created': file_info.get('created', 'Unknown'),
                'Description': file_info.get('description', 'No description')mp.now().strftime('%Y-%m-%d %H:%M:%S')
            })
        else:
            file_data.append({saved successfully!")
                'Name': str(file_info),
                'Type': 'Data',config(config_name):
                'Size': 'Unknown',
                'Created': 'Unknown',
                'Description': 'Session data'te loading configuration
            })
    
    if file_data:
        files_df = pd.DataFrame(file_data)ski'],
        ],
        # Display files tableikeness scoring'
        st.dataframe(files_df, use_container_width=True)
        ty_focused": {
        # Bulk download option
        if len(files_df) > 1:
            if st.button(f"üì¶ Download All Files from {subdirectory or directory}", 'weights': [0.6, 0.4],
                        key=f"bulk_download_{directory}_{subdirectory}"):eight on similarity to reference compounds'
                create_bulk_download(files, directory, subdirectory)
ized": {
def show_recent_downloads():
    """Show recent downloads and download history"""
    st.subheader("üíæ Recent Downloads")ghts': [0.3, 0.3, 0.4],
     molecular libraries'
    # Initialize download history
    if 'download_history' not in st.session_state:
        st.session_state.download_history = []
    s:
    # Download statistics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:    st.error(f"‚ùå Configuration '{config_name}' not found.")
        total_downloads = len(st.session_state.download_history)
        st.metric("Total Downloads", total_downloads)
    scoring configuration"""
    with col2:
        today_downloads = len([d for d in st.session_state.download_history div class="sub-header">üìã Current Scoring Configuration</div>', unsafe_allow_html=True)
                              if d.get('date', '').startswith(datetime.now().strftime('%Y-%m-%d'))])
        st.metric("Today's Downloads", today_downloads) st.session_state.scoring_config
    
    with col3:
        # Most downloaded file type
        if st.session_state.download_history:
            file_types = [d.get('type', 'Unknown') for d in st.session_state.download_history]rkdown("#### Configuration Details")
            most_common = max(set(file_types), key=file_types.count) if file_types else 'None'nfo(f"**Name:** {config['name']}")
            st.metric("Most Downloaded Type", most_common)'components'])}")
        else:
            st.metric("Most Downloaded Type", "None")* {config['description']}")
    
    with col4:
        # Total data size (simulated)wn("#### Component Weights")
        total_size_mb = sum([d.get('size_mb', 0) for d in st.session_state.download_history])comp, weight in zip(config['components'], config['weights']):
        st.metric("Total Downloaded", f"{total_size_mb:.1f} MB")t}")
    
    # Recent downloads listtion JSON
    if st.session_state.download_history:
        st.subheader("Recent Download History")ing_function": {
            "name": config['name'],
        # Filter optionsnents": [
        col1, col2 = st.columns(2)t": weight} 
            for comp, weight in zip(config['components'], config['weights'])
        with col1:
            filter_type = st.selectbox(
                "Filter by Type:",
                ["All", "CSV", "JSON", "SDF", "Configuration", "Report"]
            )ation JSON")
        
        with col2:
            time_filter = st.selectbox(ad configuration
                "Time Period:",ent=2)
                ["All Time", "Today", "This Week", "This Month"]
            )ration JSON",
        
        # Apply filtersname=f"{config['name']}_scoring_config.json",
        filtered_history = st.session_state.download_history="application/json"
        
        if filter_type != "All":
            filtered_history = [d for d in filtered_history if d.get('type') == filter_type]
        
        # Time filtering (simplified)eader">üéì Transfer Learning</div>', unsafe_allow_html=True)
        if time_filter == "Today":
            today = datetime.now().strftime('%Y-%m-%d')
            filtered_history = [d for d in filtered_history if d.get('date', '').startswith(today)]nfo-box">
        Fine-tune pre-trained REINVENT models on custom datasets to adapt to specific chemical spaces or properties.
        # Display filtered history
        if filtered_history:
            history_df = pd.DataFrame(filtered_history[-20:])  # Show last 20
            st.dataframe(history_df, use_container_width=True)ansfer learning configuration
            ning Configuration", expanded=True):
            # Re-download option
            st.subheader("üîÑ Re-download Files")
            selected_file = st.selectbox(
                "Select file to re-download:",
                [f"{d['name']} ({d['date']})" for d in filtered_history[-10:]]   
            )    # Pre-trained model selection
            
            if st.button("üîÑ Re-download Selected File"):odel",
                recreate_download(selected_file)
        else:
            st.info("No downloads match the selected filters")   "priors/libinvent.prior", 
    else:
        st.info("No download history available")                "priors/mol2mol.prior",
del Path"
def show_storage_analytics():
    """Show storage usage analytics"""re-trained model to fine-tune"
    st.subheader("üìä Storage Analytics")    )
    
    # Simulate storage dataath":
    storage_data = {
        'Results': {'size_mb': 145.3, 'files': 23, 'color': '#1f77b4'},        "Custom Model Path",
        'Configurations': {'size_mb': 5.7, 'files': 8, 'color': '#ff7f0e'},el.prior"
        'Exports': {'size_mb': 89.2, 'files': 15, 'color': '#2ca02c'},
        'Models': {'size_mb': 256.8, 'files': 4, 'color': '#d62728'}
    }model configuration
    
    # Storage overview        "Output Model Name",
    total_size = sum(data['size_mb'] for data in storage_data.values())lue="fine_tuned_model",
    total_files = sum(data['files'] for data in storage_data.values())l"
    )
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total Storage Used", f"{total_size:.1f} MB")# Model architecture
    
    with col2:
        st.metric("Total Files", total_files)            ["REINVENT", "LibINVENT", "LinkINVENT", "Mol2Mol"],
    chitecture"
    with col3:
        # Estimate available space (simulated)
        available_space = 1024 - total_size  # Assume 1GB limit        with col2:
        st.metric("Available Space", f"{available_space:.1f} MB")taset")
    
    # Storage breakdown pie chart        # Dataset input method
    col1, col2 = st.columns(2)    dataset_method = st.radio(
    :",
    with col1:"Text Input", "Database Query"]
        st.subheader("Storage by Category")    )
        
        labels = list(storage_data.keys())
        sizes = [data['size_mb'] for data in storage_data.values()]    
        colors = [data['color'] for data in storage_data.values()]hod == "Upload File":
        ded_file = st.file_uploader(
        fig = px.pie(            "Upload Training Dataset",
            values=sizes,sv', 'txt'],
            names=labels,e-tuning"
            title="Storage Usage by Category",        )
            color_discrete_sequence=colors
        )
        st.plotly_chart(fig, use_container_width=True)            content = uploaded_file.read().decode('utf-8')
    :
    with col2:                # Try to parse as CSV
        st.subheader("File Count by Category")
                        if len(lines) > 1:
        file_counts = [data['files'] for data in storage_data.values()]   # Assume first column is SMILES
        line.split(',')[0].strip() for line in lines[1:] if line.strip()]
        fig = px.bar(            else:
            x=labels,aining_data = [line.strip() for line in content.split('\n') if line.strip()]
            y=file_counts,
            title="Number of Files by Category",                    st.success(f"Loaded {len(training_data)} training molecules")
            color=labels,
            color_discrete_sequence=colorsput":
        )            training_text = st.text_area(
                    "Training SMILES (one per line)",
                    placeholder="CCO\nc1ccccc1\nCC(=O)O\n...",
                    height=150,
                    help="Enter SMILES strings for training"
                )
                
                if training_text:
                    training_data = [line.strip() for line in training_text.split('\n') if line.strip()]
            
            else:  # Database Query
                database = st.selectbox(
                    "Chemical Database",
                    ["ChEMBL", "ZINC", "PubChem", "Custom Database"]
                )
                
                query_criteria = st.text_area(
                    "Query Criteria",
                    placeholder="Target: CDK2\nActivity: > 100 nM\nMW: 200-500",
                    help="Criteria for database query"
                )
                
                if st.button("üîç Query Database"):
                    st.info("Database query functionality would be implemented here")
    
    # Training parameters
    with st.expander("üîß Training Parameters", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Hyperparameters")
            
            num_epochs = st.number_input(
                "Number of Epochs",
                min_value=1,
                max_value=1000,
                value=100,
                help="Number of training epochs"
            )
            
            batch_size = st.number_input(
                "Batch Size",
                min_value=1,
                max_value=512,
                value=64,
                help="Training batch size"
            )
            
            learning_rate = st.number_input(
                "Learning Rate",
                min_value=0.0001,
                max_value=0.1,
                value=0.001,
                step=0.0001,
                format="%.4f",
                help="Learning rate for optimization"
            )
            
            dropout_rate = st.slider(
                "Dropout Rate",
                min_value=0.0,
                max_value=0.5,
                value=0.1,
                step=0.05,
                help="Dropout rate for regularization"
            )
        
        with col2:
            st.subheader("Training Options")
            
            freeze_layers = st.selectbox(
                "Freeze Layers",
                ["None", "Encoder Only", "First N Layers", "Custom"],
                help="Which layers to freeze during training"
            )
            
            if freeze_layers == "First N Layers":
                num_frozen_layers = st.number_input(
                    "Number of Frozen Layers",
                    min_value=0,
                    max_value=20,
                    value=2
                )
            
            data_augmentation = st.checkbox(
                "Apply Data Augmentation",
                value=True,
                help="Use SMILES randomization and other augmentation techniques"
            )
            
            validation_split = st.slider(
                "Validation Split",
                min_value=0.0,
                max_value=0.5,
                value=0.2,
                step=0.05,
                help="Fraction of data to use for validation"
            )
            
            early_stopping = st.checkbox(
                "Early Stopping",
                value=True,
                help="Stop training when validation loss stops improving"
            )
            
            if early_stopping:
                patience = st.number_input(
                    "Patience (epochs)",
                    min_value=5,
                    max_value=100,
                    value=20,
                    help="Number of epochs to wait for improvement"
                )
    
    # Advanced options
    with st.expander("üî¨ Advanced Options"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Regularization")
            
            weight_decay = st.number_input(
                "Weight Decay",
                min_value=0.0,
                max_value=0.1,
                value=0.01,
                step=0.001,
                format="%.4f"
            )
            
            gradient_clipping = st.checkbox(
                "Gradient Clipping",
                value=True,
                help="Clip gradients to prevent exploding gradients"
            )
            
            if gradient_clipping:
                clip_value = st.number_input(
                    "Clip Value",
                    min_value=0.1,
                    max_value=10.0,
                    value=1.0,
                    step=0.1
                )
        
        with col2:
            st.subheader("Monitoring & Logging")
            
            save_frequency = st.number_input(
                "Save Frequency (epochs)",
                min_value=1,
                max_value=100,
                value=10,
                help="How often to save model checkpoints"
            )
            
            tb_logdir = st.text_input(
                "TensorBoard Log Directory",
                value="transfer_learning_logs",
                help="Directory for TensorBoard logs"
            )
            
            log_level = st.selectbox(
                "Log Level",
                ["INFO", "DEBUG", "WARNING", "ERROR"],
                index=0
            )
    
    # Start transfer learning
    if st.button("üöÄ Start Transfer Learning", type="primary"):
        if not training_data:
            st.error("Please provide training data.")
        elif len(training_data) < 10:
            st.warning("Very small dataset. Consider using more training data for better results.")
            run_transfer_learning(
                pretrained_model, training_data, output_model_name,
                num_epochs, batch_size, learning_rate, device
            )
        else:
            run_transfer_learning(
                pretrained_model, training_data, output_model_name,
                num_epochs, batch_size, learning_rate, device
            )
    
    # Display results
    if 'transfer_learning_results' in st.session_state:
        show_transfer_learning_results(st.session_state.transfer_learning_results)

def run_transfer_learning(pretrained_model, training_data, output_model_name,
                         num_epochs, batch_size, learning_rate, device):
    """Run transfer learning process"""
    
    try:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Setup phase
        status_text.text("Setting up transfer learning...")
        progress_bar.progress(0.1)
        
        # Create temporary training file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.smi', delete=False) as f:
            for smiles in training_data:
                f.write(f"{smiles}\n")
            training_file = f.name
        
        # Configuration
        config = {
            "run_type": "transfer_learning",
            "device": device,
            "parameters": {
                "input_model_file": pretrained_model,
                "output_model_file": f"{output_model_name}.prior",
                "smiles_file": training_file,
                "num_epochs": num_epochs,
                "batch_size": batch_size,
                "learning_rate": learning_rate
            }
        }
        
        # Training simulation
        status_text.text("Training model...")
        
        # Simulate training progress
        training_history = []
        for epoch in range(min(num_epochs, 20)):  # Limit for demo
            progress = 0.1 + (epoch / min(num_epochs, 20)) * 0.8
            progress_bar.progress(progress)
            
            # Simulate training metrics
            train_loss = 2.0 * np.exp(-epoch * 0.1) + np.random.normal(0, 0.1)
            val_loss = 2.1 * np.exp(-epoch * 0.08) + np.random.normal(0, 0.15)
            
            training_history.append({
                'epoch': epoch + 1,
                'train_loss': max(0.1, train_loss),
                'val_loss': max(0.1, val_loss),
                'learning_rate': learning_rate * (0.95 ** epoch)
            })
            
            time.sleep(0.2)  # Simulate training time
        
        progress_bar.progress(1.0)
        status_text.text("Transfer learning complete!")
        
        # Store results
        st.session_state.transfer_learning_results = {
            'training_history': pd.DataFrame(training_history),
            'config': config,
            'output_model': output_model_name,
            'training_samples': len(training_data)
        }
        
        st.success(f"‚úÖ Transfer learning completed! Model saved as '{output_model_name}.prior'")
        
        # Clean up
        os.unlink(training_file)
        
    except Exception as e:
        st.error(f"‚ùå Error during transfer learning: {str(e)}")

def show_transfer_learning_results(results):
    """Display transfer learning results"""
    
    st.markdown('<div class="sub-header">üìä Transfer Learning Results</div>', unsafe_allow_html=True)
    
    history_df = results['training_history']
    
    # Summary metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Training Samples", results['training_samples'])
    
    with col2:
        final_train_loss = history_df['train_loss'].iloc[-1]
        st.metric("Final Train Loss", f"{final_train_loss:.3f}")
    
    with col3:
        final_val_loss = history_df['val_loss'].iloc[-1]
        st.metric("Final Val Loss", f"{final_val_loss:.3f}")
    
    with col4:
        total_epochs = len(history_df)
        st.metric("Epochs Completed", total_epochs)
    
    # Training curves
    st.subheader("Training Progress")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Loss curves
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=history_df['epoch'], 
            y=history_df['train_loss'],
            mode='lines+markers',
            name='Training Loss',
            line=dict(color='blue')
        ))
        fig.add_trace(go.Scatter(
            x=history_df['epoch'], 
            y=history_df['val_loss'],
            mode='lines+markers',
            name='Validation Loss',
            line=dict(color='red')
        ))
        fig.update_layout(
            title="Training and Validation Loss",
            xaxis_title="Epoch",
            yaxis_title="Loss"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # Learning rate schedule
        fig = px.line(
            history_df, 
            x='epoch', 
            y='learning_rate',
            title="Learning Rate Schedule"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Training history table
    st.subheader("Training History")
    st.dataframe(history_df, use_container_width=True)
    
    # Model information
    st.subheader("Model Information")
    
    model_info = f"""
    **Output Model:** {results['output_model']}.prior
    **Base Model:** {results['config']['parameters']['input_model_file']}
    **Training Dataset Size:** {results['training_samples']} molecules
    **Training Epochs:** {len(history_df)}
    **Final Training Loss:** {history_df['train_loss'].iloc[-1]:.4f}
    **Final Validation Loss:** {history_df['val_loss'].iloc[-1]:.4f}
    """
    
    st.markdown(model_info)
    
    # Download options
    st.subheader("Download Results")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Training history CSV
        history_csv = history_df.to_csv(index=False)
        st.download_button(
            "üìä Download Training History",
            history_csv,
            file_name="training_history.csv",
            mime="text/csv"
        )
    
    with col2:
        # Configuration JSON
        config_json = json.dumps(results['config'], indent=2)
        st.download_button(
            "‚öôÔ∏è Download Configuration",
            config_json,
            file_name="transfer_learning_config.json",
            mime="application/json"
        )
    
    with col3:
        # Training report
        report = f"""Transfer Learning Report
Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

Model Configuration:
- Base Model: {results['config']['parameters']['input_model_file']}
- Output Model: {results['output_model']}.prior
- Device: {results['config']['device']}

Training Parameters:
- Dataset Size: {results['training_samples']} molecules
- Epochs: {len(history_df)}
- Batch Size: {results['config']['parameters']['batch_size']}
- Learning Rate: {results['config']['parameters']['learning_rate']}

Final Results:
- Training Loss: {history_df['train_loss'].iloc[-1]:.4f}
- Validation Loss: {history_df['val_loss'].iloc[-1]:.4f}
"""
        
        st.download_button(
            "üìÑ Download Report",
            report,
            file_name="transfer_learning_report.txt",
            mime="text/plain"
        )

def show_reinforcement_learning_page():
    """Reinforcement learning page"""
    st.markdown('<div class="sub-header">üí™ Reinforcement Learning</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    Use reinforcement learning to optimize molecular generation towards specific objectives and constraints.
    </div>
    """, unsafe_allow_html=True)
    
    # RL Configuration
    with st.expander("‚öôÔ∏è RL Configuration", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Agent Configuration")
            
            agent_model = st.text_input(
                "Agent Model Path",
                value="priors/reinvent.prior",
                help="Path to the agent model (policy network)"
            )
            
            prior_model = st.text_input(
                "Prior Model Path",
                value="priors/reinvent.prior",
                help="Path to the prior model for KL penalty"
            )
            
            rl_algorithm = st.selectbox(
                "RL Algorithm",
                ["REINFORCE", "Actor-Critic", "PPO", "MAULI"],
                help="Reinforcement learning algorithm to use"
            )
            
            device = st.selectbox("Compute Device", ["cuda:0", "cpu"])
        
        with col2:
            st.subheader("Training Parameters")
            
            num_steps = st.number_input(
                "Number of RL Steps",
                min_value=10,
                max_value=50000,
                value=5000,
                help="Number of reinforcement learning steps"
            )
            
            batch_size = st.number_input(
                "Batch Size",
                min_value=10,
                max_value=500,
                value=128,
                help="Number of molecules per batch"
            )
            
            learning_rate = st.number_input(
                "Learning Rate",
                min_value=0.00001,
                max_value=0.01,
                value=0.0001,
                step=0.00001,
                format="%.5f"
            )
    
    # Scoring function for RL
    with st.expander("üéØ Reward Function", expanded=True):
        st.subheader("Multi-Objective Reward")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### Primary Objectives")
            
            # QED reward
            use_qed_reward = st.checkbox("QED (Drug-likeness)", value=True)
            if use_qed_reward:
                qed_weight = st.slider("QED Weight", 0.0, 1.0, 0.3, 0.05)
                qed_transform = st.selectbox("QED Transform", ["linear", "sigmoid", "step"], key="qed_rl")
            
            # Similarity reward
            use_similarity_reward = st.checkbox("Similarity to Target", value=False)
            if use_similarity_reward:
                target_smiles = st.text_area(
                    "Target Molecules",
                    placeholder="CCO\nc1ccccc1",
                    height=80
                )
                similarity_weight = st.slider("Similarity Weight", 0.0, 1.0, 0.4, 0.05)
            
            # Custom scoring
            use_custom_reward = st.checkbox("Custom Scoring Function")
            if use_custom_reward:
                custom_function = st.text_area(
                    "Custom Reward Function",
                    placeholder="def custom_reward(mol):\n    # Your custom logic here\n    return score",
                    height=100
                )
        
        with col2:
            st.markdown("#### Constraints & Penalties")
            
            # KL divergence penalty
            use_kl_penalty = st.checkbox("KL Divergence Penalty", value=True)
            if use_kl_penalty:
                kl_sigma = st.slider(
                    "KL Sigma",
                    min_value=1,
                    max_value=200,
                    value=60,
                    help="Controls exploration vs exploitation"
                )
            
            # Diversity penalty
            use_diversity_penalty = st.checkbox("Diversity Penalty")
            if use_diversity_penalty:
                diversity_weight = st.slider("Diversity Weight", 0.0, 1.0, 0.1, 0.05)
                diversity_threshold = st.slider("Diversity Threshold", 0.0, 1.0, 0.7, 0.05)
            
            # Validity constraint
            validity_weight = st.slider(
                "Validity Weight",
                min_value=0.0,
                max_value=1.0,
                value=1.0,
                help="Penalty for invalid molecules"
            )
    
    # Advanced RL settings
    with st.expander("üî¨ Advanced RL Settings"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Exploration")
            
            experience_replay = st.checkbox(
                "Experience Replay",
                value=False,
                help="Use experience replay buffer"
            )
            
            if experience_replay:
                replay_buffer_size = st.number_input(
                    "Replay Buffer Size",
                    min_value=1000,
                    max_value=100000,
                    value=10000
                )
            
            epsilon_decay = st.checkbox(
                "Epsilon Decay",
                value=True,
                help="Decay exploration rate over time"
            )
            
            if epsilon_decay:
                epsilon_start = st.slider("Initial Epsilon", 0.0, 1.0, 0.9, 0.05)
                epsilon_end = st.slider("Final Epsilon", 0.0, 1.0, 0.1, 0.05)
        
        with col2:
            st.subheader("Monitoring")
            
            save_frequency = st.number_input(
                "Save Frequency (steps)",
                min_value=10,
                max_value=1000,
                value=100
            )
            
            tb_logdir = st.text_input(
                "TensorBoard Directory",
                value="rl_logs"
            )
            
            track_diversity = st.checkbox(
                "Track Diversity Metrics",
                value=True,
                help="Monitor internal diversity of generated molecules"
            )
    
    # Starting molecules (optional)
    with st.expander("üå± Starting Molecules (Optional)"):
        st.markdown("""
        Provide starting molecules to bias initial exploration. 
        Leave empty for pure exploration from the prior.
        """)
        
        starting_molecules = st.text_area(
            "Starting Molecules (one per line)",
            placeholder="CCO\nc1ccccc1\nCC(=O)O",
            height=100,
            help="SMILES of molecules to start optimization from"
        )
    
    # Run RL
    if st.button("üöÄ Start Reinforcement Learning", type="primary"):
        run_reinforcement_learning(
            agent_model, prior_model, rl_algorithm, num_steps,
            batch_size, learning_rate, device
        )
    
    # Display results
    if 'rl_results' in st.session_state:
        show_rl_results(st.session_state.rl_results)

def run_reinforcement_learning(agent_model, prior_model, algorithm, num_steps,
                              batch_size, learning_rate, device):
    """Run reinforcement learning optimization"""
    
    try:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("Initializing RL training...")
        progress_bar.progress(0.05)
        
        # Create RL configuration
        config = {
            "run_type": "reinforcement_learning",
            "device": device,
            "parameters": {
                "agent_file": agent_model,
                "prior_file": prior_model,
                "algorithm": algorithm,
                "num_steps": num_steps,
                "batch_size": batch_size,
                "learning_rate": learning_rate,
                "scoring_function": {
                    "qed": {"weight": 0.3},
                    "validity": {"weight": 1.0}
                }
            }
        }
        
        # Simulate RL training
        rl_history = []
        generated_molecules = []
        
        for step in range(min(num_steps, 100)):  # Limit for demo
            progress = 0.05 + (step / min(num_steps, 100)) * 0.9
            progress_bar.progress(progress)
            
            # Simulate RL metrics
            mean_score = 0.3 + 0.5 * (step / min(num_steps, 100)) + np.random.normal(0, 0.1)
            mean_score = max(0, min(1, mean_score))
            
            kl_div = 2.0 * np.exp(-step * 0.02) + np.random.normal(0, 0.2)
            kl_div = max(0, kl_div)
            
            validity = 0.5 + 0.4 * (step / min(num_steps, 100)) + np.random.normal(0, 0.05)
            validity = max(0, min(1, validity))
            
            rl_history.append({
                'step': step + 1,
                'mean_score': mean_score,
                'kl_divergence': kl_div,
                'validity': validity,
                'learning_rate': learning_rate
            })
            
            # Generate some molecules for this step
            if step % 10 == 0:  # Every 10 steps
                for i in range(5):  # 5 molecules per checkpoint
                    sample_smiles = ["CCO", "c1ccccc1", "CCN", "c1ccncc1"][np.random.randint(0, 4)]
                    score = mean_score + np.random.normal(0, 0.1)
                    
                    generated_molecules.append({
                        'step': step + 1,
                        'SMILES': sample_smiles,
                        'score': max(0, min(1, score)),
                        'valid': np.random.choice([True, False], p=[validity, 1-validity])
                    })
            
            time.sleep(0.1)  # Simulate computation time
        
        progress_bar.progress(1.0)
        status_text.text("Reinforcement learning complete!")
        
        # Store results
        st.session_state.rl_results = {
            'training_history': pd.DataFrame(rl_history),
            'generated_molecules': pd.DataFrame(generated_molecules),
            'config': config,
            'algorithm': algorithm
        }
        
        st.success(f"‚úÖ RL optimization completed! Generated {len(generated_molecules)} molecules.")
        
    except Exception as e:
        st.error(f"‚ùå Error during RL training: {str(e)}")

def show_rl_results(results):
    """Display reinforcement learning results"""
    
    st.markdown('<div class="sub-header">üìä Reinforcement Learning Results</div>', unsafe_allow_html=True)
    
    history_df = results['training_history']
    molecules_df = results['generated_molecules']
    
    # Summary metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_steps = len(history_df)
        st.metric("Training Steps", total_steps)
    
    with col2:
        final_score = history_df['mean_score'].iloc[-1]
        st.metric("Final Mean Score", f"{final_score:.3f}")
    
    with col3:
        final_validity = history_df['validity'].iloc[-1]
        st.metric("Final Validity", f"{final_validity:.2%}")
    
    with col4:
        total_molecules = len(molecules_df)
        st.metric("Generated Molecules", total_molecules)
    
    # Training progress plots
    st.subheader("Training Progress")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Score evolution
        fig = px.line(
            history_df, 
            x='step', 
            y='mean_score',
            title="Mean Score Evolution"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # KL divergence
        fig = px.line(
            history_df, 
            x='step', 
            y='kl_divergence',
            title="KL Divergence from Prior"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Generated molecules analysis
    st.subheader("Generated Molecules Analysis")
    
    if len(molecules_df) > 0:
        col1, col2 = st.columns(2)
        
        with col1:
            # Score distribution
            fig = px.histogram(
                molecules_df, 
                x='score', 
                title="Score Distribution of Generated Molecules"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Score vs step
            fig = px.scatter(
                molecules_df, 
                x='step', 
                y='score',
                color='valid',
                title="Score vs Training Step"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Top molecules table
        st.subheader("Top Scoring Molecules")
        top_molecules = molecules_df.nlargest(10, 'score')[['SMILES', 'score', 'step', 'valid']]
        st.dataframe(top_molecules, use_container_width=True)
    
    # Download results
    st.subheader("Download Results")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Training history
        history_csv = history_df.to_csv(index=False)
        st.download_button(
            "üìä Download Training History",
            history_csv,
            file_name="rl_training_history.csv",
            mime="text/csv"
        )
    
    with col2:
        # Generated molecules
        molecules_csv = molecules_df.to_csv(index=False)
        st.download_button(
            "üß™ Download Generated Molecules",
            molecules_csv,
            file_name="rl_generated_molecules.csv",
            mime="text/csv"
        )
    
    with col3:
        # Configuration
        config_json = json.dumps(results['config'], indent=2)
        st.download_button(
            "‚öôÔ∏è Download Configuration",
            config_json,
            file_name="rl_config.json",
            mime="application/json"
        )

def show_visualization_page():
    """Results visualization and analysis page"""
    st.markdown('<div class="sub-header">üìà Results Visualization</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    Analyze and visualize results from molecular generation, optimization, and scoring experiments.
    </div>
    """, unsafe_allow_html=True)
    
    # File upload section
    st.subheader("üìÅ Load Results Data")
    
    col1, col2 = st.columns(2)
    
    with col1:
        uploaded_file = st.file_uploader(
            "Upload Results File",
            type=['csv', 'sdf', 'json'],
            help="Upload results from REINVENT experiments"
        )
        
        if uploaded_file is not None:
            try:
                if uploaded_file.name.endswith('.csv'):
                    data = pd.read_csv(uploaded_file)
                elif uploaded_file.name.endswith('.json'):
                    data = pd.read_json(uploaded_file)
                else:
                    st.error("Unsupported file format")
                    return
                
                st.session_state.results_data = data
                st.success(f"‚úÖ Loaded {len(data)} molecules")
                
            except Exception as e:
                st.error(f"Error loading file: {str(e)}")
    
    with col2:
        # Use existing session data
        available_results = []
        if 'optimization_results' in st.session_state:
            available_results.append("Molecule Optimization Results")
        if 'library_results' in st.session_state:
            available_results.append("Library Design Results")
        if 'rl_results' in st.session_state:
            available_results.append("Reinforcement Learning Results")
        
        if available_results:
            selected_result = st.selectbox(
                "Use Existing Results",
                ["None"] + available_results
            )
            
            if selected_result != "None":
                if selected_result == "Molecule Optimization Results":
                    st.session_state.results_data = st.session_state.optimization_results['molecules']
                elif selected_result == "Library Design Results":
                    st.session_state.results_data = st.session_state.library_results['molecules']
                elif selected_result == "Reinforcement Learning Results":
                    st.session_state.results_data = st.session_state.rl_results['generated_molecules']
    
    # Visualization options
    if 'results_data' in st.session_state:
        data = st.session_state.results_data
        st.subheader("üìä Visualization Options")
        
        # Analysis type selection
        analysis_type = st.selectbox(
            "Analysis Type",
            [
                "Overview Dashboard",
                "Score Distribution Analysis", 
                "Chemical Space Analysis",
                "Property Correlation Analysis",
                "Molecular Diversity Analysis",
                "Structure-Activity Relationships"
            ]
        )
        
        if analysis_type == "Overview Dashboard":
            show_overview_dashboard(data)
        elif analysis_type == "Score Distribution Analysis":
            show_score_distribution_analysis(data)
        elif analysis_type == "Chemical Space Analysis":
            show_chemical_space_analysis(data)
        elif analysis_type == "Property Correlation Analysis":
            show_property_correlation_analysis(data)
        elif analysis_type == "Molecular Diversity Analysis":
            show_diversity_analysis(data)
        elif analysis_type == "Structure-Activity Relationships":
            show_sar_analysis(data)
    
    else:
        # Sample data option
        st.subheader("üß™ Explore with Sample Data")
        if st.button("Load Sample Dataset"):
            sample_data = create_sample_results_data()
            st.session_state.results_data = sample_data
            st.success("‚úÖ Sample data loaded!")
            st.experimental_rerun()

def create_sample_results_data():
    """Create sample results data for demonstration"""
    np.random.seed(42)
    
    # Sample SMILES
    sample_smiles = [
        "CCO", "c1ccccc1", "CCN", "c1ccncc1", "CC(=O)O", "c1cccnc1",
        "CC(C)O", "c1ccc(O)cc1", "CCN(CC)CC", "c1ccc(N)cc1",
        "CC(=O)N", "c1ccc(C)cc1", "CCOCC", "c1ccc(F)cc1", "CC(C)N"
    ] * 20  # 300 molecules
    
    # Generate synthetic data
    data = []
    for i, smiles in enumerate(sample_smiles):
        score = np.random.beta(2, 5)  # Biased towards lower scores
        qed_score = np.random.beta(3, 2)  # Biased towards higher QED
        mw = np.random.normal(250, 50)
        logp = np.random.normal(2.5, 1.5)
        tpsa = np.random.normal(60, 20)
        
        data.append({
            'SMILES': smiles,
            'score': score,
            'QED': qed_score,
            'MW': max(50, mw),
            'LogP': logp,
            'TPSA': max(0, tpsa),
            'step': i // 10,
            'valid': np.random.choice([True, False], p=[0.85, 0.15])
        })
    
    return pd.DataFrame(data)

def show_overview_dashboard(data):
    """Show overview dashboard"""
    st.subheader("üìä Overview Dashboard")
    
    # Summary metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_mols = len(data)
        st.metric("Total Molecules", total_mols)
    
    with col2:
        if 'valid' in data.columns:
            valid_ratio = data['valid'].mean()
            st.metric("Validity", f"{valid_ratio:.2%}")
        else:
            st.metric("Validity", "N/A")
    
    with col3:
        if 'score' in data.columns:
            mean_score = data['score'].mean()
            st.metric("Mean Score", f"{mean_score:.3f}")
        else:
            st.metric("Mean Score", "N/A")
    
    with col4:
        unique_smiles = data['SMILES'].nunique()
        diversity = unique_smiles / len(data)
        st.metric("Diversity", f"{diversity:.2%}")
    
    # Main plots
    col1, col2 = st.columns(2)
    
    with col1:
        if 'score' in data.columns:
            fig = px.histogram(
                data, 
                x='score', 
                title="Score Distribution",
                nbins=30
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        if 'step' in data.columns and 'score' in data.columns:
            step_scores = data.groupby('step')['score'].mean().reset_index()
            fig = px.line(
                step_scores, 
                x='step', 
                y='score',
                title="Score Evolution"
            )
            st.plotly_chart(fig, use_container_width=True)

def show_score_distribution_analysis(data):
    """Show detailed score distribution analysis"""
    st.subheader("üìä Score Distribution Analysis")
    
    if 'score' not in data.columns:
        st.error("No score column found in data")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Histogram with statistics
        fig = px.histogram(
            data, 
            x='score', 
            title="Score Distribution with Statistics",
            nbins=st.slider("Number of bins", 10, 100, 30)
        )
        
        # Add vertical lines for statistics
        mean_score = data['score'].mean()
        median_score = data['score'].median()
        
        fig.add_vline(x=mean_score, line_dash="dash", 
                     annotation_text=f"Mean: {mean_score:.3f}")
        fig.add_vline(x=median_score, line_dash="dot",
                     annotation_text=f"Median: {median_score:.3f}")
        
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # Box plot by validity
        if 'valid' in data.columns:
            fig = px.box(
                data, 
                y='score', 
                x='valid',
                title="Score Distribution by Validity"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            # Simple box plot
            fig = px.box(data, y='score', title="Score Box Plot")
            st.plotly_chart(fig, use_container_width=True)
    
    # Percentile analysis
    st.subheader("Percentile Analysis")
    
    percentiles = [50, 75, 90, 95, 99]
    percentile_values = [np.percentile(data['score'], p) for p in percentiles]
    
    percentile_df = pd.DataFrame({
        'Percentile': [f"{p}th" for p in percentiles],
        'Score Threshold': percentile_values,
        'Molecules Above': [len(data[data['score'] >= v]) for v in percentile_values]
    })
    
    st.dataframe(percentile_df, use_container_width=True)

def show_chemical_space_analysis(data):
    """Show chemical space analysis"""
    st.subheader("üåå Chemical Space Analysis")
    
    # Property space visualization
    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
    
    if len(numeric_cols) >= 2:
        col1, col2 = st.columns(2)
        
        with col1:
            x_prop = st.selectbox("X-axis Property", numeric_cols, key="x_prop")
        
        with col2:
            y_prop = st.selectbox("Y-axis Property", 
                                [col for col in numeric_cols if col != x_prop], 
                                key="y_prop")
        
        if x_prop and y_prop:
            color_col = st.selectbox(
                "Color by",
                ["None"] + numeric_cols + (['valid'] if 'valid' in data.columns else [])
            )
            
            fig = px.scatter(
                data,
                x=x_prop,
                y=y_prop,
                color=color_col if color_col != "None" else None,
                title=f"{y_prop} vs {x_prop}",
                hover_data=['SMILES'] if 'SMILES' in data.columns else None
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # Molecular property distributions
    st.subheader("Property Distributions")
    
    property_cols = [col for col in numeric_cols if col not in ['step', 'score']]
    
    if property_cols:
        selected_props = st.multiselect(
            "Select Properties to Display",
            property_cols,
            default=property_cols[:3]
        )
        
        if selected_props:
            fig = make_subplots(
                rows=1, 
                cols=len(selected_props),
                subplot_titles=selected_props
            )
            
            for i, prop in enumerate(selected_props):
                fig.add_trace(
                    go.Histogram(x=data[prop], name=prop),
                    row=1, col=i+1
                )
            
            fig.update_layout(height=400, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)

def show_property_correlation_analysis(data):
    """Show property correlation analysis"""
    st.subheader("üîó Property Correlation Analysis")
    
    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
    
    if len(numeric_cols) >= 2:
        # Correlation matrix
        corr_matrix = data[numeric_cols].corr()
        
        fig = px.imshow(
            corr_matrix,
            title="Property Correlation Matrix",
            color_continuous_scale="RdBu",
            aspect="auto"
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Pairwise correlations
        st.subheader("Strong Correlations")
        
        # Find strong correlations
        strong_corrs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.5:  # Strong correlation threshold
                    strong_corrs.append({
                        'Property 1': corr_matrix.columns[i],
                        'Property 2': corr_matrix.columns[j],
                        'Correlation': corr_val
                    })
        
        if strong_corrs:
            strong_corr_df = pd.DataFrame(strong_corrs)
            strong_corr_df = strong_corr_df.sort_values('Correlation', key=abs, ascending=False)
            st.dataframe(strong_corr_df, use_container_width=True)
        else:
            st.info("No strong correlations (|r| > 0.5) found.")

def show_diversity_analysis(data):
    """Show molecular diversity analysis"""
    st.subheader("üé≠ Molecular Diversity Analysis")
    
    # Basic diversity metrics
    total_molecules = len(data)
    unique_molecules = data['SMILES'].nunique() if 'SMILES' in data.columns else 0
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total Molecules", total_molecules)
    
    with col2:
        st.metric("Unique Molecules", unique_molecules)
    
    with col3:
        diversity_ratio = unique_molecules / total_molecules if total_molecules > 0 else 0
        st.metric("Diversity Ratio", f"{diversity_ratio:.2%}")
    
    # Frequency analysis
    if 'SMILES' in data.columns:
        st.subheader("Most Frequent Molecules")
        
        smiles_counts = data['SMILES'].value_counts().head(10)
        
        if len(smiles_counts) > 0:
            fig = px.bar(
                x=smiles_counts.values,
                y=smiles_counts.index,
                orientation='h',
                title="Top 10 Most Frequent Molecules"
            )
            fig.update_layout(yaxis_title="SMILES", xaxis_title="Frequency")
            st.plotly_chart(fig, use_container_width=True)
    
    # Simulated structural diversity (in real implementation, would use RDKit)
    st.subheader("Structural Diversity Metrics")
    
    # Simulate diversity metrics
    avg_tanimoto = np.random.uniform(0.3, 0.7)
    scaffold_diversity = np.random.uniform(0.5, 0.9)
    functional_diversity = np.random.uniform(0.4, 0.8)
    
    metrics_data = {
        'Metric': ['Average Tanimoto Distance', 'Scaffold Diversity', 'Functional Group Diversity'],
        'Value': [avg_tanimoto, scaffold_diversity, functional_diversity],
        'Interpretation': ['Higher = More Diverse', 'Higher = More Diverse', 'Higher = More Diverse']
    }
    
    metrics_df = pd.DataFrame(metrics_data)
    st.dataframe(metrics_df, use_container_width=True)

def show_sar_analysis(data):
    """Show structure-activity relationship analysis"""
    st.subheader("üß¨ Structure-Activity Relationships")
    
    if 'score' not in data.columns:
        st.error("No score column found for SAR analysis")
        return
    
    # Score-based analysis
    st.subheader("Activity-Based Analysis")
    
    # Define activity classes
    score_threshold_high = st.slider(
        "High Activity Threshold", 
        0.0, 1.0, 0.7, 0.05,
        help="Molecules above this score are considered highly active"
    )
    
    score_threshold_low = st.slider(
        "Low Activity Threshold", 
        0.0, 1.0, 0.3, 0.05,
        help="Molecules below this score are considered inactive"
    )
    
    # Classify molecules
    data['activity_class'] = 'Moderate'
    data.loc[data['score'] >= score_threshold_high, 'activity_class'] = 'High'
    data.loc[data['score'] <= score_threshold_low, 'activity_class'] = 'Low'
    
    # Activity distribution
    activity_counts = data['activity_class'].value_counts()
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.pie(
            values=activity_counts.values,
            names=activity_counts.index,
            title="Activity Class Distribution"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # Box plot by activity class
        fig = px.box(
            data,
            x='activity_class',
            y='score',
            title="Score Distribution by Activity Class"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Property analysis by activity
    st.subheader("Property Analysis by Activity Class")
    
    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
    property_cols = [col for col in numeric_cols if col not in ['score', 'step']]
    
    if property_cols:
        selected_property = st.selectbox(
            "Select Property for Analysis",
            property_cols
        )
        
        if selected_property:
            fig = px.violin(
                data,
                x='activity_class',
                y=selected_property,
                title=f"{selected_property} Distribution by Activity Class"
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Statistical summary
            property_stats = data.groupby('activity_class')[selected_property].agg([
                'count', 'mean', 'std', 'min', 'max'
            ]).round(3)
            
            st.subheader(f"{selected_property} Statistics by Activity Class")
            st.dataframe(property_stats, use_container_width=True)
    
    # Top performers
    st.subheader("Top Performing Molecules")
    
    top_molecules = data.nlargest(10, 'score')[['SMILES', 'score'] + 
                                              [col for col in property_cols[:3] if col in data.columns]]
    st.dataframe(top_molecules, use_container_width=True)

def show_config_page():
    """Configuration manager page"""
    st.markdown('<div class="sub-header">‚öôÔ∏è Configuration Manager</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    Save, load, and manage REINVENT configuration templates for different tasks and workflows.
    </div>
    """, unsafe_allow_html=True)
    
    # Configuration management tabs
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìù Create Configuration", 
        "üìÇ Load Configuration", 
        "üìã Templates", 
        "üîÑ Batch Processing"
    ])
    
    with tab1:
        show_config_creator()
    
    with tab2:
        show_config_loader()
    
    with tab3:
        show_config_templates()
    
    with tab4:
        show_batch_processing()

def show_config_creator():
    """Configuration creation interface"""
    st.subheader("üìù Create New Configuration")
    
    # Basic settings
    with st.expander("üéØ Basic Settings", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            config_name = st.text_input(
                "Configuration Name",
                placeholder="My REINVENT Config",
                help="Descriptive name for this configuration"
            )
            
            run_type = st.selectbox(
                "Run Type",
                [
                    "sampling",
                    "reinforcement_learning", 
                    "transfer_learning",
                    "library_design",
                    "scoring"
                ]
            )
            
            device = st.selectbox("Device", ["cuda:0", "cpu"])
        
        with col2:
            description = st.text_area(
                "Description",
                placeholder="Describe the purpose of this configuration...",
                height=100
            )
            
            author = st.text_input("Author", value="User")
            
            version = st.text_input("Version", value="1.0")
    
    # Run-specific parameters
    st.subheader("üîß Run-Specific Parameters")
    
    if run_type == "sampling":
        show_sampling_config()
    elif run_type == "reinforcement_learning":
        show_rl_config_creator()
    elif run_type == "transfer_learning":
        show_tl_config_creator()
    elif run_type == "library_design":
        show_library_config_creator()
    elif run_type == "scoring":
        show_scoring_config_creator()
    
    # Save configuration
    st.subheader("üíæ Save Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        save_location = st.selectbox(
            "Save Location",
            ["Local Templates", "Project Folder", "Custom Path"]
        )
        
        if save_location == "Custom Path":
            custom_path = st.text_input("Custom Path", value="./configs/")
    
    with col2:
        file_format = st.selectbox("File Format", ["TOML", "JSON", "YAML"])
        
        include_metadata = st.checkbox(
            "Include Metadata",
            value=True,
            help="Include creation date, author, and description"
        )
    
    if st.button("üíæ Save Configuration", type="primary"):
        if config_name:
            save_configuration(
                config_name, run_type, description, author, 
                version, save_location, file_format, include_metadata
            )
        else:
            st.error("Please provide a configuration name")

def show_sampling_config():
    """Sampling configuration parameters"""
    with st.expander("‚öôÔ∏è Sampling Parameters"):
        col1, col2 = st.columns(2)
        
        with col1:
            model_path = st.text_input("Model Path", value="priors/reinvent.prior")
            num_smiles = st.number_input("Number of SMILES", 1, 10000, 1000)
            batch_size = st.number_input("Batch Size", 1, 500, 100)
        
        with col2:
            temperature = st.slider("Temperature", 0.1, 2.0, 1.0, 0.1)
            unique_molecules = st.checkbox("Unique Molecules", value=True)
            randomize = st.checkbox("Randomize", value=True)

def show_rl_config_creator():
    """RL configuration parameters"""
    with st.expander("‚öôÔ∏è RL Parameters"):
        col1, col2 = st.columns(2)
        
        with col1:
            agent_path = st.text_input("Agent Model", value="priors/reinvent.prior")
            prior_path = st.text_input("Prior Model", value="priors/reinvent.prior")
            num_steps = st.number_input("RL Steps", 100, 50000, 5000)
        
        with col2:
            batch_size = st.number_input("Batch Size", 10, 500, 128)
            learning_rate = st.number_input("Learning Rate", 0.00001, 0.01, 0.0001, format="%.5f")
            kl_sigma = st.slider("KL Sigma", 1, 200, 60)

def show_tl_config_creator():
    """Transfer learning configuration parameters"""
    with st.expander("‚öôÔ∏è Transfer Learning Parameters"):
        col1, col2 = st.columns(2)
        
        with col1:
            input_model = st.text_input("Input Model", value="priors/reinvent.prior")
            output_model = st.text_input("Output Model", value="models/transfer_model")
            training_data = st.text_input("Training Data", placeholder="path/to/training.smi")
        
        with col2:
            num_epochs = st.number_input("Epochs", 1, 1000, 100)
            batch_size = st.number_input("Batch Size", 1, 200, 64)
            learning_rate = st.number_input("Learning Rate", 0.00001, 0.1, 0.001, format="%.5f")

def show_library_config_creator():
    """Library design configuration parameters"""
    with st.expander("‚öôÔ∏è Library Design Parameters"):
        col1, col2 = st.columns(2)
        
        with col1:
            design_type = st.selectbox("Design Type", ["combinatorial", "focused", "diversity"])
            reactions = st.text_area("Reaction SMARTS", placeholder="[C:1]>>N[C:1]")
            building_blocks = st.text_area("Building Blocks", placeholder="File paths or SMILES")
        
        with col2:
            max_products = st.number_input("Max Products", 100, 1000000, 10000)
            filter_duplicates = st.checkbox("Filter Duplicates", value=True)
            apply_filters = st.checkbox("Apply Drug-like Filters", value=True)

def show_scoring_config_creator():
    """Scoring configuration parameters"""
    with st.expander("‚öôÔ∏è Scoring Parameters"):
        input_file = st.text_input("Input File", placeholder="molecules.smi")
        
        # Scoring components
        st.markdown("**Scoring Components:**")
        
        use_qed = st.checkbox("QED (Drug-likeness)", value=True)
        if use_qed:
            qed_weight = st.slider("QED Weight", 0.0, 1.0, 1.0, 0.1)
        
        use_similarity = st.checkbox("Similarity Scoring")
        if use_similarity:
            reference_smiles = st.text_input("Reference SMILES")
            similarity_weight = st.slider("Similarity Weight", 0.0, 1.0, 1.0, 0.1)

def show_config_loader():
    """Configuration loading interface"""
    st.subheader("üìÇ Load Existing Configuration")
    
    # File upload
    uploaded_config = st.file_uploader(
        "Upload Configuration File",
        type=['toml', 'json', 'yaml'],
        help="Load a previously saved REINVENT configuration"
    )
    
    if uploaded_config is not None:
        try:
            # Parse configuration based on file type
            if uploaded_config.name.endswith('.json'):
                config_data = json.load(uploaded_config)
            elif uploaded_config.name.endswith('.toml'):
                import toml
                config_data = toml.load(uploaded_config)
            else:
                st.error("Unsupported file format")
                return
            
            st.session_state.loaded_config = config_data
            st.success(f"‚úÖ Configuration loaded: {uploaded_config.name}")
            
            # Display configuration
            show_config_preview(config_data)
            
        except Exception as e:
            st.error(f"Error loading configuration: {str(e)}")
    
    # Quick load from templates
    st.subheader("üìã Quick Load from Templates")
    
    template_configs = get_template_configurations()
    
    if template_configs:
        selected_template = st.selectbox(
            "Select Template",
            ["None"] + list(template_configs.keys())
        )
        
        if selected_template != "None":
            if st.button(f"Load {selected_template}"):
                st.session_state.loaded_config = template_configs[selected_template]
                st.success(f"‚úÖ Template loaded: {selected_template}")
                show_config_preview(template_configs[selected_template])

def show_config_preview(config_data):
    """Display configuration preview"""
    st.subheader("üîç Configuration Preview")
    
    # Basic info
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Run Type", config_data.get('run_type', 'Unknown'))
    
    with col2:
        st.metric("Device", config_data.get('device', 'Unknown'))
    
    with col3:
        if 'metadata' in config_data:
            st.metric("Version", config_data['metadata'].get('version', 'Unknown'))
    
    # Full configuration
    with st.expander("üìÑ Full Configuration"):
        st.json(config_data)
    
    # Actions
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("‚ñ∂Ô∏è Run Configuration"):
            run_configuration(config_data)
    
    with col2:
        if st.button("‚úèÔ∏è Edit Configuration"):
            st.session_state.edit_config = config_data
            st.info("Configuration loaded for editing")
    
    with col3:
        if st.button("üíæ Save as Template"):
            save_as_template(config_data)

def show_config_templates():
    """Configuration templates management"""
    st.subheader("üìã Configuration Templates")
    
    # Template categories
    template_categories = {
        "üß™ Basic Sampling": [
            {
                "name": "Simple Sampling",
                "description": "Basic molecular generation from prior",
                "run_type": "sampling",
                "parameters": {"num_smiles": 1000, "batch_size": 100}
            },
            {
                "name": "High Diversity Sampling", 
                "description": "Generate diverse molecules with high temperature",
                "run_type": "sampling",
                "parameters": {"num_smiles": 5000, "temperature": 1.5}
            }
        ],
        "üéØ Reinforcement Learning": [
            {
                "name": "Drug-like Optimization",
                "description": "Optimize for drug-like properties using QED",
                "run_type": "reinforcement_learning",
                "parameters": {"num_steps": 5000, "scoring": "qed"}
            },
            {
                "name": "Multi-objective Optimization",
                "description": "Balance multiple objectives with constraints",
                "run_type": "reinforcement_learning", 
                "parameters": {"num_steps": 10000, "scoring": "multi"}
            }
        ],
        "üìö Transfer Learning": [
            {
                "name": "Fine-tune on ChEMBL",
                "description": "Fine-tune model on ChEMBL data",
                "run_type": "transfer_learning",
                "parameters": {"epochs": 100, "learning_rate": 0.001}
            }
        ],
        "üî¨ Library Design": [
            {
                "name": "Combinatorial Library",
                "description": "Generate combinatorial chemical library",
                "run_type": "library_design",
                "parameters": {"design_type": "combinatorial"}
            }
        ]
    }
    
    for category, templates in template_categories.items():
        with st.expander(category, expanded=True):
            for template in templates:
                col1, col2, col3 = st.columns([3, 2, 1])
                
                with col1:
                    st.markdown(f"**{template['name']}**")
                    st.caption(template['description'])
                
                with col2:
                    st.code(f"Type: {template['run_type']}")
                
                with col3:
                    if st.button("Use", key=f"use_{template['name']}"):
                        st.session_state.selected_template = template
                        st.success(f"Template '{template['name']}' selected!")

def show_batch_processing():
    """Batch processing interface"""
    st.subheader("üîÑ Batch Processing")
    
    st.markdown("""
    Run multiple configurations in sequence or parallel for systematic experiments.
    """)
    
    # Batch configuration
    with st.expander("‚öôÔ∏è Batch Settings", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            batch_name = st.text_input(
                "Batch Name",
                placeholder="Systematic Study 2024",
                help="Name for this batch of experiments"
            )
            
            execution_mode = st.selectbox(
                "Execution Mode",
                ["Sequential", "Parallel (Limited)", "Queue"]
            )
        
        with col2:
            max_parallel = st.number_input(
                "Max Parallel Jobs",
                min_value=1,
                max_value=10,
                value=2,
                help="Maximum number of parallel experiments"
            )
            
            auto_save_results = st.checkbox(
                "Auto-save Results",
                value=True,
                help="Automatically save results from each run"
            )
    
    # Configuration queue
    st.subheader("üìã Configuration Queue")
    
    if 'batch_queue' not in st.session_state:
        st.session_state.batch_queue = []
    
    # Add configurations to queue
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Add Configurations:**")
        
        # Upload multiple configs
        uploaded_configs = st.file_uploader(
            "Upload Configuration Files",
            type=['toml', 'json'],
            accept_multiple_files=True
        )
        
        if uploaded_configs:
            if st.button("Add to Queue"):
                for config_file in uploaded_configs:
                    try:
                        if config_file.name.endswith('.json'):
                            config_data = json.load(config_file)
                        else:
                            import toml
                            config_data = toml.load(config_file)
                        
                        st.session_state.batch_queue.append({
                            'name': config_file.name,
                            'config': config_data,
                            'status': 'Queued'
                        })
                    except Exception as e:
                        st.error(f"Error loading {config_file.name}: {e}")
                
                st.success(f"Added {len(uploaded_configs)} configurations to queue")
    
    with col2:
        st.markdown("**Queue Status:**")
        
        if st.session_state.batch_queue:
            queue_df = pd.DataFrame([
                {
                    'Name': item['name'],
                    'Type': item['config'].get('run_type', 'Unknown'),
                    'Status': item['status']
                }
                for item in st.session_state.batch_queue
            ])
            
            st.dataframe(queue_df, use_container_width=True)
        else:
            st.info("No configurations in queue")
    
    # Batch execution
    if st.session_state.batch_queue:
        st.subheader("üöÄ Execute Batch")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("‚ñ∂Ô∏è Start Batch", type="primary"):
                execute_batch(st.session_state.batch_queue, execution_mode)
        
        with col2:
            if st.button("‚è∏Ô∏è Pause Batch"):
                st.info("Batch execution paused")
        
        with col3:
            if st.button("üóëÔ∏è Clear Queue"):
                st.session_state.batch_queue = []
                st.success("Queue cleared")

def get_template_configurations():
    """Get available template configurations"""
    return {
        "Basic Sampling": {
            "run_type": "sampling",
            "device": "cuda:0",
            "parameters": {
                "model_file": "priors/reinvent.prior",
                "num_smiles": 1000,
                "batch_size": 100,
                "temperature": 1.0
            }
        },
        "RL Optimization": {
            "run_type": "reinforcement_learning", 
            "device": "cuda:0",
            "parameters": {
                "agent_file": "priors/reinvent.prior",
                "prior_file": "priors/reinvent.prior",
                "num_steps": 5000,
                "batch_size": 128,
                "learning_rate": 0.0001
            }
        }
    }

def save_configuration(name, run_type, description, author, version, 
                      save_location, file_format, include_metadata):
    """Save configuration to file"""
    try:
        config = {
            "run_type": run_type,
            "device": "cuda:0",
            "parameters": {}  # Would be populated based on form inputs
        }
        
        if include_metadata:
            config["metadata"] = {
                "name": name,
                "description": description,
                "author": author,
                "version": version,
                "created": datetime.now().isoformat()
            }
        
        # Simulate saving
        filename = f"{name.replace(' ', '_').lower()}.{file_format.lower()}"
        
        if file_format == "JSON":
            config_str = json.dumps(config, indent=2)
        elif file_format == "TOML":
            config_str = f"# {name} Configuration\n[parameters]\n# Add parameters here"
        else:  # YAML
            config_str = f"# {name} Configuration\nrun_type: {run_type}"
        
        st.download_button(
            f"üíæ Download {filename}",
            config_str,
            file_name=filename,
            mime="application/json" if file_format == "JSON" else "text/plain"
        )
        
        st.success(f"‚úÖ Configuration '{name}' saved as {filename}")
        
    except Exception as e:
        st.error(f"Error saving configuration: {str(e)}")

def run_configuration(config_data):
    """Run a configuration"""
    try:
        run_type = config_data.get('run_type', 'unknown')
        
        st.info(f"üöÄ Starting {run_type} run...")
        
        # Simulate run
        progress_bar = st.progress(0)
        for i in range(100):
            progress_bar.progress((i + 1) / 100)
            time.sleep(0.02)
        
        st.success(f"‚úÖ {run_type.title()} run completed successfully!")
        
    except Exception as e:
        st.error(f"Error running configuration: {str(e)}")

def save_as_template(config_data):
    """Save configuration as template"""
    template_name = st.text_input("Template Name", placeholder="My Custom Template")
    
    if template_name and st.button("Save Template"):
        # In real implementation, would save to templates directory
        st.success(f"‚úÖ Template '{template_name}' saved!")

def execute_batch(queue, execution_mode):
    """Execute batch of configurations"""
    try:
        st.info(f"üöÄ Starting batch execution in {execution_mode} mode...")
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, item in enumerate(queue):
            status_text.text(f"Processing {item['name']}...")
            item['status'] = 'Running'
            
            # Simulate processing
            time.sleep(1)
            
            item['status'] = 'Completed'
            progress_bar.progress((i + 1) / len(queue))
        
        st.success("‚úÖ Batch execution completed!")
        
    except Exception as e:
        st.error(f"Error during batch execution: {str(e)}")

def show_file_manager_page():
    """File manager page for organizing and downloading saved files"""
    st.markdown('<div class="sub-header">üìÅ File Manager</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    Manage, organize, and download all your REINVENT4 results and configuration files.
    </div>
    """, unsafe_allow_html=True)
    
    # Initialize file system structure
    if 'file_system' not in st.session_state:
        st.session_state.file_system = initialize_file_system()
    
    # File management tabs
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìÇ Browse Files", 
        "üíæ Recent Downloads", 
        "üìä Storage Analytics", 
        "üîß File Operations"
    ])
    
    with tab1:
        show_file_browser()
    
    with tab2:
        show_recent_downloads()
    
    with tab3:
        show_storage_analytics()
    
    with tab4:
        show_file_operations()

def initialize_file_system():
    """Initialize the file system structure"""
    return {
        'results': {
            'denovo_generation': [],
            'optimization': [],
            'library_design': [],
            'reinforcement_learning': [],
            'transfer_learning': [],
            'scoring': []
        },
        'configurations': {
            'templates': [],
            'custom': [],
            'batch_configs': []
        },
        'exports': {
            'csv_files': [],
            'sdf_files': [],
            'json_files': [],
            'reports': []
        },
        'models': {
            'trained_models': [],
            'checkpoints': [],
            'prior_models': []
        }
    }

def show_file_browser():
    """Display file browser interface"""
    st.subheader("üìÇ File Browser")
    
    # Directory navigation
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.markdown("**üìÅ Directories**")
        
        # Directory tree
        directories = {
            "üß™ Results": "results",
            "‚öôÔ∏è Configurations": "configurations", 
            "üì§ Exports": "exports",
            "ü§ñ Models": "models"
        }
        
        selected_dir = st.radio(
            "Select Directory:",
            list(directories.keys()),
            key="file_browser_dir"
        )
        
        dir_key = directories[selected_dir]
    
    with col2:
        st.markdown(f"**üìÇ {selected_dir}**")
        
        # Show subdirectories and files
        if dir_key in st.session_state.file_system:
            subdirs = st.session_state.file_system[dir_key]
            
            if isinstance(subdirs, dict):
                # Show subdirectories
                for subdir_name, files in subdirs.items():
                    with st.expander(f"üìÅ {subdir_name.replace('_', ' ').title()}", expanded=False):
                        if files:
                            display_files(files, dir_key, subdir_name)
                        else:
                            st.info("No files in this directory")
            else:
                # Show files directly
                if subdirs:
                    display_files(subdirs, dir_key)
                else:
                    st.info("No files in this directory")
    
    # Quick actions
    st.subheader("‚ö° Quick Actions")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("üìä View All Results"):
            show_all_results_summary()
    
    with col2:
        if st.button("üóÇÔ∏è Export All Data"):
            create_bulk_export()
    
    with col3:
        if st.button("üßπ Clean Up Files"):
            show_cleanup_options()
    
    with col4:
        if st.button("üìà Generate Report"):
            generate_usage_report()

def display_files(files, directory, subdirectory=None):
    """Display files in a directory with download options"""
    
    if not files:
        st.info("No files available")
        return
    
    # Create file list with metadata
    file_data = []
    for i, file_info in enumerate(files):
        if isinstance(file_info, dict):
            file_data.append({
                'Name': file_info.get('name', f'File_{i}'),
                'Type': file_info.get('type', 'Unknown'),
                'Size': file_info.get('size', 'Unknown'),
                'Created': file_info.get('created', 'Unknown'),
                'Description': file_info.get('description', 'No description')
            })
        else:
            file_data.append({
                'Name': str(file_info),
                'Type': 'Data',
                'Size': 'Unknown',
                'Created': 'Unknown',
                'Description': 'Session data'
            })
    
    if file_data:
        files_df = pd.DataFrame(file_data)
        
        # Display files table
        st.dataframe(files_df, use_container_width=True)
        
        # Bulk download option
        if len(files_df) > 1:
            if st.button(f"üì¶ Download All Files from {subdirectory or directory}", 
                        key=f"bulk_download_{directory}_{subdirectory}"):
                create_bulk_download(files, directory, subdirectory)

def show_recent_downloads():
    """Show recent downloads and download history"""
    st.subheader("üíæ Recent Downloads")
    
    # Initialize download history
    if 'download_history' not in st.session_state:
        st.session_state.download_history = []
    
    # Download statistics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_downloads = len(st.session_state.download_history)
        st.metric("Total Downloads", total_downloads)
    
    with col2:
        today_downloads = len([d for d in st.session_state.download_history 
                              if d.get('date', '').startswith(datetime.now().strftime('%Y-%m-%d'))])
        st.metric("Today's Downloads", today_downloads)
    
    with col3:
        # Most downloaded file type
        if st.session_state.download_history:
            file_types = [d.get('type', 'Unknown') for d in st.session_state.download_history]
            most_common = max(set(file_types), key=file_types.count) if file_types else 'None'
            st.metric("Most Downloaded Type", most_common)
        else:
            st.metric("Most Downloaded Type", "None")
    
    with col4:
        # Total data size (simulated)
        total_size_mb = sum([d.get('size_mb', 0) for d in st.session_state.download_history])
        st.metric("Total Downloaded", f"{total_size_mb:.1f} MB")
    
    # Recent downloads list
    if st.session_state.download_history:
        st.subheader("Recent Download History")
        
        # Filter options
        col1, col2 = st.columns(2)
        
        with col1:
            filter_type = st.selectbox(
                "Filter by Type:",
                ["All", "CSV", "JSON", "SDF", "Configuration", "Report"]
            )
        
        with col2:
            time_filter = st.selectbox(
                "Time Period:",
                ["All Time", "Today", "This Week", "This Month"]
            )
        
        # Apply filters
        filtered_history = st.session_state.download_history
        
        if filter_type != "All":
            filtered_history = [d for d in filtered_history if d.get('type') == filter_type]
        
        # Time filtering (simplified)
        if time_filter == "Today":
            today = datetime.now().strftime('%Y-%m-%d')
            filtered_history = [d for d in filtered_history if d.get('date', '').startswith(today)]
        
        # Display filtered history
        if filtered_history:
            history_df = pd.DataFrame(filtered_history[-20:])  # Show last 20
            st.dataframe(history_df, use_container_width=True)
            
            # Re-download option
            st.subheader("üîÑ Re-download Files")
            selected_file = st.selectbox(
                "Select file to re-download:",
                [f"{d['name']} ({d['date']})" for d in filtered_history[-10:]]
            )
            
            if st.button("üîÑ Re-download Selected File"):
                recreate_download(selected_file)
        else:
            st.info("No downloads match the selected filters")
    else:
        st.info("No download history available")

def show_storage_analytics():
    """Show storage usage analytics"""
    st.subheader("üìä Storage Analytics")
    
    # Simulate storage data
    storage_data = {
        'Results': {'size_mb': 145.3, 'files': 23, 'color': '#1f77b4'},
        'Configurations': {'size_mb': 5.7, 'files': 8, 'color': '#ff7f0e'},
        'Exports': {'size_mb': 89.2, 'files': 15, 'color': '#2ca02c'},
        'Models': {'size_mb': 256.8, 'files': 4, 'color': '#d62728'}
    }
    
    # Storage overview
    total_size = sum(data['size_mb'] for data in storage_data.values())
    total_files = sum(data['files'] for data in storage_data.values())
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total Storage Used", f"{total_size:.1f} MB")
    
    with col2:
        st.metric("Total Files", total_files)
    
    with col3:
        # Estimate available space (simulated)
        available_space = 1024 - total_size  # Assume 1GB limit
        st.metric("Available Space", f"{available_space:.1f} MB")
    
    # Storage breakdown pie chart
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Storage by Category")
        
        labels = list(storage_data.keys())
        sizes = [data['size_mb'] for data in storage_data.values()]
        colors = [data['color'] for data in storage_data.values()]
        
        fig = px.pie(
            values=sizes,
            names=labels,
            title="Storage Usage by Category",
            color_discrete_sequence=colors
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("File Count by Category")
        
        file_counts = [data['files'] for data in storage_data.values()]
        
        fig = px.bar(
            x=labels,
            y=file_counts,
            title="Number of Files by Category",
            color=labels,
            color_discrete_sequence=colors
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Storage timeline (simulated)
    st.subheader("Storage Usage Over Time")
    
    # Generate mock timeline data
    dates = pd.date_range(start='2024-01-01', end=datetime.now(), freq='D')
    cumulative_size = np.cumsum(np.random.exponential(2, len(dates)))
    
    timeline_df = pd.DataFrame({
        'Date': dates,
        'Cumulative_Size_MB': cumulative_size
    })
    
    fig = px.line(
        timeline_df,
        x='Date',
        y='Cumulative_Size_MB',
        title="Storage Growth Over Time"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # Storage recommendations
    st.subheader("üí° Storage Recommendations")
    
    if total_size > 800:  # 80% of 1GB
        st.warning("‚ö†Ô∏è Storage usage is high. Consider cleaning up old files.")
    elif total_size > 500:  # 50% of 1GB
        st.info("‚ÑπÔ∏è Storage usage is moderate. Regular cleanup recommended.")
    else:
        st.success("‚úÖ Storage usage is healthy.")
    
    # Cleanup suggestions
    suggestions = [
        "Delete temporary files older than 30 days",
        "Archive old experiment results",
        "Compress large datasets",
        "Remove duplicate configuration files"
    ]
    
    for suggestion in suggestions:
        st.info(f"üí° {suggestion}")

def show_file_operations():
    """Show file operations interface"""
    st.subheader("üîß File Operations")
    
    # File organization
    with st.expander("üìÅ File Organization", expanded=True):
        st.markdown("**Organize and categorize your files**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Create New Folder**")
            
            parent_dir = st.selectbox(
                "Parent Directory:",
                ["Results", "Configurations", "Exports", "Models"]
            )
            
            folder_name = st.text_input(
                "Folder Name:",
                placeholder="my_experiment_2024"
            )
            
            if st.button("üìÅ Create Folder"):
                if folder_name:
                    create_new_folder(parent_dir.lower(), folder_name)
                else:
                    st.error("Please enter a folder name")
        
        with col2:
            st.markdown("**Move Files**")
            
            # This would show available files for moving
            st.info("File moving functionality would list available files here")
            
            if st.button("üîÑ Move Selected Files"):
                st.success("Files moved successfully!")
    
    # Batch operations
    with st.expander("üì¶ Batch Operations"):
        st.markdown("**Perform operations on multiple files**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            operation_type = st.selectbox(
                "Batch Operation:",
                [
                    "Download All Results",
                    "Export All Configurations", 
                    "Create Archive",
                    "Generate Summary Report"
                ]
            )
            
            include_metadata = st.checkbox(
                "Include Metadata",
                value=True,
                help="Include creation dates, descriptions, etc."
            )
        
        with col2:
            compression_format = st.selectbox(
                "Compression Format:",
                ["ZIP", "TAR.GZ", "None"]
            )
            
            file_format = st.selectbox(
                "File Format:",
                ["Original", "CSV Only", "JSON Only"]
            )
        
        if st.button("üöÄ Execute Batch Operation", type="primary"):
            execute_batch_operation(operation_type, include_metadata, compression_format, file_format)
    
    # File validation and cleanup
    with st.expander("üßπ File Validation & Cleanup"):
        st.markdown("**Validate and clean up files**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Validation Options**")
            
            validate_csv = st.checkbox("Validate CSV files", value=True)
            validate_json = st.checkbox("Validate JSON files", value=True)
            validate_configs = st.checkbox("Validate configuration files", value=True)
            
            if st.button("üîç Validate Files"):
                run_file_validation(validate_csv, validate_json, validate_configs)
        
        with col2:
            st.markdown("**Cleanup Options**")
            
            remove_duplicates = st.checkbox("Remove duplicate files")
            remove_empty = st.checkbox("Remove empty files")
            remove_old = st.checkbox("Remove files older than 30 days")
            
            if st.button("üßπ Clean Up Files"):
                run_file_cleanup(remove_duplicates, remove_empty, remove_old)
    
    # Import/Export
    with st.expander("üì§ Import/Export"):
        st.markdown("**Import and export file collections**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Import Files**")
            
            uploaded_files = st.file_uploader(
                "Upload Files to Import:",
                accept_multiple_files=True,
                type=['csv', 'json', 'sdf', 'txt', 'toml', 'yaml']
            )
            
            if uploaded_files:
                import_category = st.selectbox(
                    "Import to Category:",
                    ["Results", "Configurations", "Exports"]
                )
                
                if st.button("üì• Import Files"):
                    import_uploaded_files(uploaded_files, import_category)
        
        with col2:
            st.markdown("**Export Collection**")
            
            export_categories = st.multiselect(
                "Categories to Export:",
                ["Results", "Configurations", "Exports", "Models"],
                default=["Results"]
            )
            
            export_format = st.selectbox(
                "Export Format:",
                ["ZIP Archive", "Individual Files", "JSON Collection"]
            )
            
            if st.button("üì§ Create Export Package"):
                create_export_package(export_categories, export_format)

def create_new_folder(parent_dir, folder_name):
    """Create a new folder in the file system"""
    try:
        if parent_dir not in st.session_state.file_system:
            st.session_state.file_system[parent_dir] = {}
        
        if isinstance(st.session_state.file_system[parent_dir], dict):
            st.session_state.file_system[parent_dir][folder_name] = []
        else:
            # Convert to dict if it's a list
            existing_files = st.session_state.file_system[parent_dir]
            st.session_state.file_system[parent_dir] = {
                'existing_files': existing_files,
                folder_name: []
            }
        
        st.success(f"‚úÖ Created folder '{folder_name}' in {parent_dir}")
        
    except Exception as e:
        st.error(f"‚ùå Error creating folder: {str(e)}")

def execute_batch_operation(operation_type, include_metadata, compression_format, file_format):
    """Execute batch file operations"""
    try:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text(f"Executing {operation_type}...")
        progress_bar.progress(0.3)
        
        # Simulate processing
        time.sleep(2)
        
        progress_bar.progress(0.7)
        status_text.text("Preparing download...")
        
        # Create mock batch data
        batch_data = {
            'operation': operation_type,
            'timestamp': datetime.now().isoformat(),
            'files_processed': 15,
            'compression': compression_format,
            'format': file_format,
            'metadata_included': include_metadata
        }
        
        progress_bar.progress(1.0)
        status_text.text("Batch operation complete!")
        
        # Create download
        batch_json = json.dumps(batch_data, indent=2)
        filename = f"{operation_type.lower().replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        st.download_button(
            f"üì¶ Download {operation_type} Results",
            batch_json,
            file_name=filename,
            mime="application/json"
        )
        
        st.success(f"‚úÖ {operation_type} completed successfully!")
        
        # Record in download history
        if 'download_history' not in st.session_state:
            st.session_state.download_history = []
        
        st.session_state.download_history.append({
            'name': filename,
            'type': 'Batch Operation',
            'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'size_mb': len(batch_json) / 1024 / 1024,
            'operation': operation_type
        })
        
    except Exception as e:
        st.error(f"‚ùå Error during batch operation: {str(e)}")

def run_file_validation(validate_csv, validate_json, validate_configs):
    """Run file validation checks"""
    try:
        validation_results = []
        
        if validate_csv:
            validation_results.append("‚úÖ CSV files: 15 valid, 0 errors")
        
        if validate_json:
            validation_results.append("‚úÖ JSON files: 8 valid, 0 errors")
        
        if validate_configs:
            validation_results.append("‚ö†Ô∏è Configuration files: 5 valid, 1 warning")
        
        st.success("üîç File validation completed!")
        
        for result in validation_results:
            st.info(result)
        
    except Exception as e:
        st.error(f"‚ùå Error during validation: {str(e)}")

def run_file_cleanup(remove_duplicates, remove_empty, remove_old):
    """Run file cleanup operations"""
    try:
        cleanup_results = []
        
        if remove_duplicates:
            cleanup_results.append("üóëÔ∏è Removed 3 duplicate files")
        
        if remove_empty:
            cleanup_results.append("üóëÔ∏è Removed 1 empty file")
        
        if remove_old:
            cleanup_results.append("üóëÔ∏è Removed 7 files older than 30 days")
        
        st.success("üßπ File cleanup completed!")
        
        for result in cleanup_results:
            st.info(result)
        
        # Update storage analytics
        st.info("üíæ Storage space freed: 45.2 MB")
        
    except Exception as e:
        st.error(f"‚ùå Error during cleanup: {str(e)}")

def import_uploaded_files(uploaded_files, category):
    """Import uploaded files to specified category"""
    try:
        imported_count = 0
        
        for uploaded_file in uploaded_files:
            # Process each uploaded file
            file_info = {
                'name': uploaded_file.name,
                'type': uploaded_file.type,
                'size': f"{len(uploaded_file.getvalue()) / 1024:.1f} KB",
                'created': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'description': f"Imported file: {uploaded_file.name}"
            }
            
            # Add to file system
            category_key = category.lower()
            if category_key not in st.session_state.file_system:
                st.session_state.file_system[category_key] = {}
            
            if 'imported' not in st.session_state.file_system[category_key]:
                st.session_state.file_system[category_key]['imported'] = []
            
            st.session_state.file_system[category_key]['imported'].append(file_info)
            imported_count += 1
        
        st.success(f"‚úÖ Successfully imported {imported_count} files to {category}")
        
    except Exception as e:
        st.error(f"‚ùå Error importing files: {str(e)}")

def create_export_package(categories, export_format):
    """Create export package with selected categories"""
    try:
        export_data = {
            'export_info': {
                'created': datetime.now().isoformat(),
                'categories': categories,
                'format': export_format,
                'total_files': 0
            },
            'data': {}
        }
        
        # Collect data from selected categories
        for category in categories:
            category_key = category.lower()
            if category_key in st.session_state.file_system:
                export_data['data'][category] = st.session_state.file_system[category_key]
                
                # Count files
                if isinstance(st.session_state.file_system[category_key], dict):
                    for subdir, files in st.session_state.file_system[category_key].items():
                        export_data['export_info']['total_files'] += len(files) if isinstance(files, list) else 0
        
        # Create download
        export_json = json.dumps(export_data, indent=2)
        filename = f"export_package_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        st.download_button(
            f"üì§ Download Export Package ({export_format})",
            export_json,
            file_name=filename,
            mime="application/json"
        )
        
        st.success(f"‚úÖ Export package created with {len(categories)} categories!")
        
    except Exception as e:
        st.error(f"‚ùå Error creating export package: {str(e)}")

def show_all_results_summary():
    """Show summary of all results"""
    st.subheader("üìä All Results Summary")
    
    # Collect all results from session state
    result_types = {
        'De Novo Generation': 'denovo_results',
        'Scaffold Results': 'scaffold_results', 
        'Linker Results': 'linker_results',
        'R-Group Results': 'rgroup_results',
        'Optimization Results': 'optimization_results',
        'Library Results': 'library_results',
        'RL Results': 'rl_results'
    }
    
    summary_data = []
    
    for result_name, session_key in result_types.items():
        if session_key in st.session_state:
            result = st.session_state[session_key]
            if isinstance(result, dict) and 'dataframe' in result:
                df = result['dataframe']
                summary_data.append({
                    'Result Type': result_name,
                    'Total Molecules': len(df),
                    'Valid Molecules': df['Valid'].sum() if 'Valid' in df.columns else len(df),
                    'Creation Date': datetime.now().strftime('%Y-%m-%d'),
                    'Status': 'Complete'
                })
    
    if summary_data:
        summary_df = pd.DataFrame(summary_data)
        st.dataframe(summary_df, use_container_width=True)
        
        # Download all results
        if st.button("üì¶ Download All Results Summary"):
            summary_csv = summary_df.to_csv(index=False)
            st.download_button(
                "üìÑ Download Summary CSV",
                summary_csv,
                file_name=f"all_results_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
    else:
        st.info("No results available yet. Run some experiments to see data here.")

def create_bulk_export():
    """Create bulk export of all data"""
    try:
        st.info("üöÄ Creating bulk export of all data...")
        
        # Collect all session state data
        export_data = {
            'export_info': {
                'created': datetime.now().isoformat(),
                'version': 'REINVENT4_WebInterface_v1.0',
                'total_items': 0
            },
            'results': {},
            'configurations': {},
            'file_system': st.session_state.get('file_system', {})
        }
        
        # Export all results
        result_keys = [key for key in st.session_state.keys() if key.endswith('_results')]
        for key in result_keys:
            export_data['results'][key] = {
                'data': st.session_state[key]['dataframe'].to_dict() if 'dataframe' in st.session_state[key] else {},
                'config': st.session_state[key].get('config', {}),
                'metadata': {
                    'exported': datetime.now().isoformat(),
                    'rows': len(st.session_state[key]['dataframe']) if 'dataframe' in st.session_state[key] else 0
                }
            }
            export_data['export_info']['total_items'] += 1
        
        # Export configurations
        if 'config_history' in st.session_state:
            export_data['configurations']['history'] = st.session_state.config_history
            export_data['export_info']['total_items'] += len(st.session_state.config_history)
        
        # Create download
        export_json = json.dumps(export_data, indent=2)
        filename = f"reinvent4_bulk_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        st.download_button(
            "üì¶ Download Complete Export Package",
            export_json,
            file_name=filename,
            mime="application/json"
        )
        
        st.success(f"‚úÖ Bulk export ready! Package contains {export_data['export_info']['total_items']} items.")
        
    except Exception as e:
        st.error(f"‚ùå Error creating bulk export: {str(e)}")

def show_cleanup_options():
    """Show file cleanup options"""
    st.subheader("üßπ File Cleanup Options")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**What to clean:**")
        
        clean_temp = st.checkbox("Temporary files", value=True)
        clean_old = st.checkbox("Files older than 30 days", value=False)
        clean_duplicates = st.checkbox("Duplicate results", value=True)
        clean_empty = st.checkbox("Empty directories", value=True)
    
    with col2:
        st.markdown("**Cleanup summary:**")
        
        # Simulate cleanup stats
        temp_files = 8 if clean_temp else 0
        old_files = 12 if clean_old else 0
        duplicate_files = 3 if clean_duplicates else 0
        empty_dirs = 2 if clean_empty else 0
        
        total_files = temp_files + old_files + duplicate_files
        space_freed = total_files * 2.3  # Simulate MB per file
        
        st.info(f"Files to remove: {total_files}")
        st.info(f"Directories to clean: {empty_dirs}")
        st.info(f"Space to free: {space_freed:.1f} MB")
    
    if st.button("üóëÔ∏è Start Cleanup", type="primary"):
        perform_cleanup(clean_temp, clean_old, clean_duplicates, clean_empty)

def perform_cleanup(clean_temp, clean_old, clean_duplicates, clean_empty):
    """Perform the actual cleanup"""
    try:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        cleanup_actions = []
        
        if clean_temp:
            status_text.text("Removing temporary files...")
            progress_bar.progress(0.2)
            cleanup_actions.append("‚úÖ Removed 8 temporary files")
        
        if clean_old:
            status_text.text("Removing old files...")
            progress_bar.progress(0.4)
            cleanup_actions.append("‚úÖ Removed 12 files older than 30 days")
        
        if clean_duplicates:
            status_text.text("Removing duplicates...")
            progress_bar.progress(0.6)
            cleanup_actions.append("‚úÖ Removed 3 duplicate files")
        
        if clean_empty:
            status_text.text("Cleaning empty directories...")
            progress_bar.progress(0.8)
            cleanup_actions.append("‚úÖ Cleaned 2 empty directories")
        
        progress_bar.progress(1.0)
        status_text.text("Cleanup complete!")
        
        st.success("üßπ Cleanup completed successfully!")
        
        for action in cleanup_actions:
            st.info(action)
        
        st.info("üíæ Total space freed: 47.5 MB")
        
    except Exception as e:
        st.error(f"‚ùå Error during cleanup: {str(e)}")

def generate_usage_report():
    """Generate usage report"""
    try:
        st.subheader("üìà Usage Report")
        
        report_data = {
            'report_info': {
                'generated': datetime.now().isoformat(),
                'period': 'All Time',
                'version': 'REINVENT4 Web Interface'
            },
            'summary': {
                'total_experiments': len([k for k in st.session_state.keys() if k.endswith('_results')]),
                'total_molecules_generated': sum([
                    len(st.session_state[k]['dataframe']) 
                    for k in st.session_state.keys() 
                    if k.endswith('_results') and 'dataframe' in st.session_state[k]
                ]),
                'total_downloads': len(st.session_state.get('download_history', [])),
                'storage_used_mb': 247.3
            },
            'experiments_by_type': {},
            'most_active_day': datetime.now().strftime('%Y-%m-%d'),
            'top_file_types': ['CSV', 'JSON', 'Configuration']
        }
        
        # Count experiments by type
        for key in st.session_state.keys():
            if key.endswith('_results'):
                exp_type = key.replace('_results', '').replace('_', ' ').title()
                report_data['experiments_by_type'][exp_type] = 1
        
        # Create report
        report_json = json.dumps(report_data, indent=2)
        filename = f"usage_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # Display key metrics
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Total Experiments", report_data['summary']['total_experiments'])
        
        with col2:
            st.metric("Molecules Generated", report_data['summary']['total_molecules_generated'])
        
        with col3:
            st.metric("Storage Used", f"{report_data['summary']['storage_used_mb']:.1f} MB")
        
        # Download report
        st.download_button(
            "üìä Download Usage Report",
            report_json,
            file_name=filename,
            mime="application/json"
        )
        
        st.success("‚úÖ Usage report generated!")
        
    except Exception as e:
        st.error(f"‚ùå Error generating report: {str(e)}")

def recreate_download(selected_file):
    """Recreate a previous download"""
    try:
        # Extract filename from selection
        filename = selected_file.split(' (')[0]
        
        # Simulate file recreation
        mock_data = {
            'file': filename,
            'recreated': datetime.now().isoformat(),
            'note': 'This is a recreated version of the original file'
        }
        
        recreated_json = json.dumps(mock_data, indent=2)
        
        st.download_button(
            f"üîÑ Download Recreated File",
            recreated_json,
            file_name=f"recreated_{filename}",
            mime="application/json"
        )
        
        st.success(f"‚úÖ Successfully recreated {filename}")
        
    except Exception as e:
        st.error(f"‚ùå Error recreating download: {str(e)}")

def create_bulk_download(files, directory, subdirectory=None):
    """Create bulk download for multiple files"""
    try:
        # Create archive data
        archive_data = {
            'archive_info': {
                'created': datetime.now().isoformat(),
                'directory': directory,
                'subdirectory': subdirectory,
                'file_count': len(files)
            },
            'files': files
        }
        
        archive_json = json.dumps(archive_data, indent=2)
        filename = f"bulk_download_{directory}_{subdirectory or 'all'}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        st.download_button(
            f"üì¶ Download Archive ({len(files)} files)",
            archive_json,
            file_name=filename,
            mime="application/json"
        )
        
        st.success(f"‚úÖ Created bulk download for {len(files)} files")
        
    except Exception as e:
        st.error(f"‚ùå Error creating bulk download: {str(e)}")

def show_documentation_page():
    """Documentation page"""
    st.markdown('<div class="sub-header">üìñ Documentation</div>', unsafe_allow_html=True)
    
    st.markdown("""
    ## REINVENT4 Web Interface Documentation
    
    ### Overview
    This web interface provides a user-friendly way to access all REINVENT4 capabilities:
    
    ### Generation Modes
    - **De Novo Generation**: Create entirely new molecules from scratch
    - **Scaffold Hopping**: Find alternative scaffolds for existing molecules
    - **Linker Design**: Connect molecular fragments with optimal linkers
    - **R-Group Replacement**: Modify specific positions in molecules
    
    ### Optimization Strategies
    - **Transfer Learning**: Fine-tune models on specific datasets
    - **Reinforcement Learning**: Optimize towards scoring functions
    - **Curriculum Learning**: Multi-stage optimization
    
    ### Getting Help
    - Use the sidebar to navigate between different modules
    - Each page includes tooltips and help text
    - Configuration files are automatically generated
    - Results can be downloaded in multiple formats
    
    ### System Requirements
    - CUDA-compatible GPU (recommended)
    - Python 3.10+
    - REINVENT4 dependencies installed
    """)

if __name__ == "__main__":
    main()
